{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.6: Shallow Network Application Project\n",
    "\n",
    "## Learning Objectives\n",
    "- Apply shallow neural networks to a real-world dataset\n",
    "- Implement complete machine learning pipeline\n",
    "- Practice model selection and hyperparameter tuning\n",
    "- Create comprehensive project documentation and analysis\n",
    "\n",
    "## Duration: 45 minutes\n",
    "\n",
    "## Prerequisites\n",
    "- Completion of Labs 3.1-3.5\n",
    "- Understanding of all shallow neural network concepts\n",
    "- Knowledge of optimization and regularization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine, load_digits, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else 'default')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"üöÄ Environment setup complete!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview: Wine Quality Classification\n",
    "\n",
    "### Project Goal\n",
    "Build a shallow neural network to classify wine varieties based on chemical properties.\n",
    "\n",
    "### Success Criteria\n",
    "1. **Model Performance**: Achieve >90% test accuracy\n",
    "2. **Generalization**: Small gap between training and validation performance\n",
    "3. **Comparison**: Outperform traditional machine learning baselines\n",
    "4. **Documentation**: Complete analysis and interpretation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Complete Neural Network Framework (10 minutes)\n",
    "\n",
    "### Import and enhance our best neural network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete neural network implementation combining all previous labs\n",
    "class ProjectNeuralNetwork:\n",
    "    \"\"\"\n",
    "    Complete neural network implementation for the application project\n",
    "    Combines all techniques from previous labs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task_type='classification', optimizer='adam', **optimizer_kwargs):\n",
    "        self.task_type = task_type\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        if optimizer.lower() == 'adam':\n",
    "            self.optimizer = self.AdamOptimizer(**optimizer_kwargs)\n",
    "        elif optimizer.lower() == 'momentum':\n",
    "            self.optimizer = self.MomentumOptimizer(**optimizer_kwargs)\n",
    "        else:\n",
    "            self.optimizer = self.SGDOptimizer(**optimizer_kwargs)\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'train_cost': [],\n",
    "            'train_metric': [],\n",
    "            'val_cost': [],\n",
    "            'val_metric': []\n",
    "        }\n",
    "        \n",
    "        self.parameters = {}\n",
    "        self.best_parameters = {}\n",
    "        self.best_val_metric = 0 if task_type == 'classification' else float('inf')\n",
    "    \n",
    "    class AdamOptimizer:\n",
    "        def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "            self.learning_rate = learning_rate\n",
    "            self.beta1 = beta1\n",
    "            self.beta2 = beta2\n",
    "            self.epsilon = epsilon\n",
    "            self.t = 0\n",
    "            self.momentum = {}\n",
    "            self.velocity = {}\n",
    "        \n",
    "        def update(self, parameters, gradients):\n",
    "            self.t += 1\n",
    "            \n",
    "            # Initialize moments on first update\n",
    "            if not self.momentum:\n",
    "                for key in parameters:\n",
    "                    if f'd{key}' in gradients:\n",
    "                        self.momentum[f'm_{key}'] = np.zeros_like(parameters[key])\n",
    "                        self.velocity[f'v_{key}'] = np.zeros_like(parameters[key])\n",
    "            \n",
    "            for key in parameters:\n",
    "                if f'd{key}' in gradients:\n",
    "                    grad = gradients[f'd{key}']\n",
    "                    \n",
    "                    # Update moments\n",
    "                    self.momentum[f'm_{key}'] = (self.beta1 * self.momentum[f'm_{key}'] + \n",
    "                                               (1 - self.beta1) * grad)\n",
    "                    self.velocity[f'v_{key}'] = (self.beta2 * self.velocity[f'v_{key}'] + \n",
    "                                               (1 - self.beta2) * (grad ** 2))\n",
    "                    \n",
    "                    # Bias correction\n",
    "                    m_corrected = self.momentum[f'm_{key}'] / (1 - self.beta1 ** self.t)\n",
    "                    v_corrected = self.velocity[f'v_{key}'] / (1 - self.beta2 ** self.t)\n",
    "                    \n",
    "                    # Update parameters\n",
    "                    parameters[key] -= (self.learning_rate * m_corrected / \n",
    "                                      (np.sqrt(v_corrected) + self.epsilon))\n",
    "            \n",
    "            return parameters\n",
    "        \n",
    "        def reset(self):\n",
    "            self.t = 0\n",
    "            self.momentum = {}\n",
    "            self.velocity = {}\n",
    "    \n",
    "    class MomentumOptimizer:\n",
    "        def __init__(self, learning_rate=0.01, beta=0.9):\n",
    "            self.learning_rate = learning_rate\n",
    "            self.beta = beta\n",
    "            self.velocity = {}\n",
    "        \n",
    "        def update(self, parameters, gradients):\n",
    "            if not self.velocity:\n",
    "                for key in parameters:\n",
    "                    if f'd{key}' in gradients:\n",
    "                        self.velocity[f'v_{key}'] = np.zeros_like(parameters[key])\n",
    "            \n",
    "            for key in parameters:\n",
    "                if f'd{key}' in gradients:\n",
    "                    self.velocity[f'v_{key}'] = (self.beta * self.velocity[f'v_{key}'] + \n",
    "                                               (1 - self.beta) * gradients[f'd{key}'])\n",
    "                    parameters[key] -= self.learning_rate * self.velocity[f'v_{key}']\n",
    "            \n",
    "            return parameters\n",
    "        \n",
    "        def reset(self):\n",
    "            self.velocity = {}\n",
    "    \n",
    "    class SGDOptimizer:\n",
    "        def __init__(self, learning_rate=0.01):\n",
    "            self.learning_rate = learning_rate\n",
    "        \n",
    "        def update(self, parameters, gradients):\n",
    "            for key in parameters:\n",
    "                if f'd{key}' in gradients:\n",
    "                    parameters[key] -= self.learning_rate * gradients[f'd{key}']\n",
    "            return parameters\n",
    "        \n",
    "        def reset(self):\n",
    "            pass\n",
    "    \n",
    "    def initialize_parameters(self, layer_dims):\n",
    "        \"\"\"Initialize parameters with He initialization\"\"\"\n",
    "        parameters = {}\n",
    "        \n",
    "        for l in range(1, len(layer_dims)):\n",
    "            parameters[f'W{l}'] = np.random.randn(layer_dims[l], layer_dims[l-1]) * np.sqrt(2.0 / layer_dims[l-1])\n",
    "            parameters[f'b{l}'] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        return parameters\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        \"\"\"Stable softmax implementation\"\"\"\n",
    "        z_stable = z - np.max(z, axis=0, keepdims=True)\n",
    "        exp_z = np.exp(z_stable)\n",
    "        return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n",
    "    \n",
    "    def forward_propagation(self, X, parameters):\n",
    "        \"\"\"Forward propagation\"\"\"\n",
    "        caches = []\n",
    "        A = X\n",
    "        L = len(parameters) // 2\n",
    "        \n",
    "        # Hidden layers (ReLU)\n",
    "        for l in range(1, L):\n",
    "            A_prev = A\n",
    "            W = parameters[f'W{l}']\n",
    "            b = parameters[f'b{l}']\n",
    "            \n",
    "            Z = np.dot(W, A_prev) + b\n",
    "            A = np.maximum(0, Z)  # ReLU\n",
    "            \n",
    "            cache = ((A_prev, W, b), Z)\n",
    "            caches.append(cache)\n",
    "        \n",
    "        # Output layer\n",
    "        A_prev = A\n",
    "        W = parameters[f'W{L}']\n",
    "        b = parameters[f'b{L}']\n",
    "        Z = np.dot(W, A_prev) + b\n",
    "        \n",
    "        if self.task_type == 'classification' and Z.shape[0] > 1:\n",
    "            A = self.softmax(Z)  # Multi-class\n",
    "        elif self.task_type == 'classification':\n",
    "            A = 1 / (1 + np.exp(-np.clip(Z, -500, 500)))  # Binary\n",
    "        else:\n",
    "            A = Z  # Regression\n",
    "        \n",
    "        cache = ((A_prev, W, b), Z)\n",
    "        caches.append(cache)\n",
    "        \n",
    "        return A, caches\n",
    "    \n",
    "    def compute_cost(self, AL, Y):\n",
    "        \"\"\"Compute cost based on task type\"\"\"\n",
    "        m = Y.shape[1]\n",
    "        \n",
    "        if self.task_type == 'classification' and AL.shape[0] > 1:\n",
    "            # Multi-class cross-entropy\n",
    "            AL_clipped = np.clip(AL, 1e-15, 1 - 1e-15)\n",
    "            cost = -1/m * np.sum(Y * np.log(AL_clipped))\n",
    "        elif self.task_type == 'classification':\n",
    "            # Binary cross-entropy\n",
    "            AL_clipped = np.clip(AL, 1e-15, 1 - 1e-15)\n",
    "            cost = -1/m * np.sum(Y * np.log(AL_clipped) + (1 - Y) * np.log(1 - AL_clipped))\n",
    "        else:\n",
    "            # Mean squared error\n",
    "            cost = 1/(2*m) * np.sum((AL - Y)**2)\n",
    "        \n",
    "        return np.squeeze(cost)\n",
    "    \n",
    "    def compute_metric(self, AL, Y):\n",
    "        \"\"\"Compute metric based on task type\"\"\"\n",
    "        if self.task_type == 'classification':\n",
    "            if AL.shape[0] > 1:\n",
    "                # Multi-class accuracy\n",
    "                predictions = np.argmax(AL, axis=0)\n",
    "                true_labels = np.argmax(Y, axis=0)\n",
    "            else:\n",
    "                # Binary accuracy\n",
    "                predictions = (AL > 0.5).astype(int)\n",
    "                true_labels = Y.astype(int)\n",
    "            \n",
    "            return np.mean(predictions == true_labels) * 100\n",
    "        else:\n",
    "            # R¬≤ score for regression\n",
    "            ss_res = np.sum((Y - AL) ** 2)\n",
    "            ss_tot = np.sum((Y - np.mean(Y)) ** 2)\n",
    "            return 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "    \n",
    "    def backward_propagation(self, AL, Y, caches):\n",
    "        \"\"\"Backward propagation\"\"\"\n",
    "        gradients = {}\n",
    "        L = len(caches)\n",
    "        m = AL.shape[1]\n",
    "        \n",
    "        # Initialize backward propagation\n",
    "        if self.task_type == 'classification' and AL.shape[0] > 1:\n",
    "            # Multi-class: dZ = AL - Y\n",
    "            dZ = AL - Y\n",
    "        elif self.task_type == 'classification':\n",
    "            # Binary: dZ = AL - Y (for sigmoid)\n",
    "            dZ = AL - Y\n",
    "        else:\n",
    "            # Regression: dZ = AL - Y\n",
    "            dZ = AL - Y\n",
    "        \n",
    "        # Output layer\n",
    "        (A_prev, W, b), _ = caches[L-1]\n",
    "        gradients[f'dW{L}'] = 1/m * np.dot(dZ, A_prev.T)\n",
    "        gradients[f'db{L}'] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        dA_prev = np.dot(W.T, dZ)\n",
    "        \n",
    "        # Hidden layers\n",
    "        for l in reversed(range(L-1)):\n",
    "            (A_prev, W, b), Z = caches[l]\n",
    "            \n",
    "            # ReLU derivative\n",
    "            dZ = dA_prev * (Z > 0).astype(float)\n",
    "            \n",
    "            gradients[f'dW{l+1}'] = 1/m * np.dot(dZ, A_prev.T)\n",
    "            gradients[f'db{l+1}'] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
    "            \n",
    "            if l > 0:\n",
    "                dA_prev = np.dot(W.T, dZ)\n",
    "        \n",
    "        return gradients\n",
    "    \n",
    "    def train(self, X_train, Y_train, X_val, Y_val, layer_dims, \n",
    "              num_iterations=1000, print_every=100, early_stopping=True, patience=50):\n",
    "        \"\"\"Train the neural network with early stopping\"\"\"\n",
    "        \n",
    "        # Initialize\n",
    "        parameters = self.initialize_parameters(layer_dims)\n",
    "        self.optimizer.reset()\n",
    "        \n",
    "        # Early stopping variables\n",
    "        best_val_metric = 0 if self.task_type == 'classification' else float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for i in range(num_iterations):\n",
    "            # Forward and backward propagation\n",
    "            AL_train, caches = self.forward_propagation(X_train, parameters)\n",
    "            train_cost = self.compute_cost(AL_train, Y_train)\n",
    "            gradients = self.backward_propagation(AL_train, Y_train, caches)\n",
    "            parameters = self.optimizer.update(parameters, gradients)\n",
    "            \n",
    "            # Validation and logging\n",
    "            if i % print_every == 0:\n",
    "                train_metric = self.compute_metric(AL_train, Y_train)\n",
    "                \n",
    "                AL_val, _ = self.forward_propagation(X_val, parameters)\n",
    "                val_cost = self.compute_cost(AL_val, Y_val)\n",
    "                val_metric = self.compute_metric(AL_val, Y_val)\n",
    "                \n",
    "                # Store history\n",
    "                self.history['train_cost'].append(train_cost)\n",
    "                self.history['train_metric'].append(train_metric)\n",
    "                self.history['val_cost'].append(val_cost)\n",
    "                self.history['val_metric'].append(val_metric)\n",
    "                \n",
    "                print(f\"Iter {i:4d}: Train Cost={train_cost:.6f}, Train Metric={train_metric:.2f}, \"\n",
    "                      f\"Val Cost={val_cost:.6f}, Val Metric={val_metric:.2f}\")\n",
    "                \n",
    "                # Early stopping check\n",
    "                if early_stopping:\n",
    "                    improved = False\n",
    "                    if self.task_type == 'classification' and val_metric > best_val_metric:\n",
    "                        improved = True\n",
    "                    elif self.task_type == 'regression' and val_metric < best_val_metric:\n",
    "                        improved = True\n",
    "                    \n",
    "                    if improved:\n",
    "                        best_val_metric = val_metric\n",
    "                        self.best_parameters = {k: v.copy() for k, v in parameters.items()}\n",
    "                        patience_counter = 0\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                    \n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"Early stopping at iteration {i} (patience reached)\")\n",
    "                        break\n",
    "        \n",
    "        # Use best parameters if early stopping was used\n",
    "        if early_stopping and self.best_parameters:\n",
    "            self.parameters = self.best_parameters\n",
    "        else:\n",
    "            self.parameters = parameters\n",
    "        \n",
    "        return self.parameters\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        AL, _ = self.forward_propagation(X, self.parameters)\n",
    "        \n",
    "        if self.task_type == 'classification':\n",
    "            if AL.shape[0] > 1:\n",
    "                predictions = np.argmax(AL, axis=0)\n",
    "            else:\n",
    "                predictions = (AL > 0.5).astype(int)\n",
    "            return predictions.flatten(), AL\n",
    "        else:\n",
    "            return AL.flatten(), AL\n",
    "\n",
    "print(\"üß† Complete ProjectNeuralNetwork implemented!\")\n",
    "print(\"Features: Multi-class/binary classification, regression, early stopping, Adam/Momentum/SGD optimizers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Dataset Loading and Exploration (8 minutes)\n",
    "\n",
    "### Load and analyze the Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wine dataset\n",
    "print(\"üç∑ Loading Wine Dataset...\")\n",
    "wine_data = load_wine()\n",
    "X_raw = wine_data.data\n",
    "y_raw = wine_data.target\n",
    "\n",
    "# Create DataFrame for easier analysis\n",
    "wine_df = pd.DataFrame(X_raw, columns=wine_data.feature_names)\n",
    "wine_df['target'] = y_raw\n",
    "wine_df['target_name'] = [wine_data.target_names[i] for i in y_raw]\n",
    "\n",
    "print(f\"Dataset shape: {wine_df.shape}\")\n",
    "print(f\"Features: {len(wine_data.feature_names)}\")\n",
    "print(f\"Classes: {len(wine_data.target_names)}\")\n",
    "print(f\"Class names: {wine_data.target_names}\")\n",
    "print(f\"Samples per class: {np.bincount(y_raw)}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nüìä Dataset Overview:\")\n",
    "print(wine_df.describe())\n",
    "\n",
    "print(\"\\nüéØ Class Distribution:\")\n",
    "print(wine_df['target_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data visualization\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Class distribution\n",
    "plt.subplot(3, 4, 1)\n",
    "wine_df['target_name'].value_counts().plot(kind='bar', color=['red', 'green', 'blue'], alpha=0.7)\n",
    "plt.title('Wine Class Distribution')\n",
    "plt.xlabel('Wine Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Feature correlation heatmap\n",
    "plt.subplot(3, 4, 2)\n",
    "# Select top features for readability\n",
    "top_features = ['alcohol', 'flavanoids', 'color_intensity', 'od280/od315_of_diluted_wines', \n",
    "               'proline', 'total_phenols']\n",
    "corr_matrix = wine_df[top_features + ['target']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix\\n(Top 6 Features)')\n",
    "\n",
    "# Feature distributions by class\n",
    "important_features = ['alcohol', 'flavanoids', 'color_intensity', 'proline']\n",
    "for i, feature in enumerate(important_features):\n",
    "    plt.subplot(3, 4, 3 + i)\n",
    "    for class_idx, class_name in enumerate(wine_data.target_names):\n",
    "        class_data = wine_df[wine_df['target'] == class_idx][feature]\n",
    "        plt.hist(class_data, alpha=0.6, label=class_name, bins=15, color=['red', 'green', 'blue'][class_idx])\n",
    "    plt.title(f'{feature.title()} Distribution')\n",
    "    plt.xlabel(feature.replace('_', ' ').title())\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "\n",
    "# Scatter plots of discriminative features\n",
    "plt.subplot(3, 4, 7)\n",
    "colors = ['red', 'green', 'blue']\n",
    "for class_idx, class_name in enumerate(wine_data.target_names):\n",
    "    class_mask = wine_df['target'] == class_idx\n",
    "    plt.scatter(wine_df[class_mask]['alcohol'], wine_df[class_mask]['flavanoids'], \n",
    "               c=colors[class_idx], label=class_name, alpha=0.7, s=50)\n",
    "plt.xlabel('Alcohol')\n",
    "plt.ylabel('Flavanoids')\n",
    "plt.title('Alcohol vs Flavanoids')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(3, 4, 8)\n",
    "for class_idx, class_name in enumerate(wine_data.target_names):\n",
    "    class_mask = wine_df['target'] == class_idx\n",
    "    plt.scatter(wine_df[class_mask]['color_intensity'], wine_df[class_mask]['proline'], \n",
    "               c=colors[class_idx], label=class_name, alpha=0.7, s=50)\n",
    "plt.xlabel('Color Intensity')\n",
    "plt.ylabel('Proline')\n",
    "plt.title('Color Intensity vs Proline')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Feature importance (variance)\n",
    "plt.subplot(3, 4, 9)\n",
    "feature_vars = wine_df.iloc[:, :-2].var().sort_values(ascending=False)\n",
    "top_10_features = feature_vars.head(10)\n",
    "top_10_features.plot(kind='bar')\n",
    "plt.title('Top 10 Features by Variance')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Variance')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Box plots for key features\n",
    "plt.subplot(3, 4, 10)\n",
    "wine_df.boxplot(column='alcohol', by='target_name', ax=plt.gca())\n",
    "plt.title('Alcohol Content by Wine Class')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.subplot(3, 4, 11)\n",
    "wine_df.boxplot(column='flavanoids', by='target_name', ax=plt.gca())\n",
    "plt.title('Flavanoids by Wine Class')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "# Feature scaling visualization\n",
    "plt.subplot(3, 4, 12)\n",
    "# Show feature ranges before scaling\n",
    "feature_ranges = wine_df.iloc[:, :-2].max() - wine_df.iloc[:, :-2].min()\n",
    "top_ranges = feature_ranges.nlargest(8)\n",
    "top_ranges.plot(kind='bar', color='orange', alpha=0.7)\n",
    "plt.title('Feature Ranges\\n(Why Scaling is Important)')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Range (Max - Min)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüîç Key Observations:\")\n",
    "print(f\"‚Ä¢ Dataset is balanced: {np.bincount(y_raw)}\")\n",
    "print(f\"‚Ä¢ Features have very different scales (e.g., proline ~1000, magnesium ~130)\")\n",
    "print(f\"‚Ä¢ Some features show clear class separation (alcohol, flavanoids)\")\n",
    "print(f\"‚Ä¢ No missing values detected\")\n",
    "print(f\"‚Ä¢ 13 chemical features available for classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Preprocessing and Preparation (5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data preprocessing\n",
    "print(\"üîß Preprocessing Wine Dataset...\")\n",
    "\n",
    "# Convert to one-hot encoding for multi-class classification\n",
    "def to_one_hot(labels, n_classes=None):\n",
    "    \"\"\"Convert integer labels to one-hot encoded format\"\"\"\n",
    "    if n_classes is None:\n",
    "        n_classes = len(np.unique(labels))\n",
    "    \n",
    "    m = len(labels)\n",
    "    one_hot = np.zeros((n_classes, m))\n",
    "    one_hot[labels.astype(int), np.arange(m)] = 1\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "# Split the data\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42, stratify=y_raw\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp  # 0.25 * 0.8 = 0.2 of total\n",
    ")\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Training: {X_train.shape[0]} samples ({X_train.shape[0]/len(X_raw)*100:.1f}%)\")\n",
    "print(f\"  Validation: {X_val.shape[0]} samples ({X_val.shape[0]/len(X_raw)*100:.1f}%)\")\n",
    "print(f\"  Test: {X_test.shape[0]} samples ({X_test.shape[0]/len(X_raw)*100:.1f}%)\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nFeature scaling applied:\")\n",
    "print(f\"  Before: mean={np.mean(X_train):.3f}, std={np.std(X_train):.3f}\")\n",
    "print(f\"  After: mean={np.mean(X_train_scaled):.3f}, std={np.std(X_train_scaled):.3f}\")\n",
    "\n",
    "# Convert to neural network format (features, samples)\n",
    "X_train_nn = X_train_scaled.T\n",
    "X_val_nn = X_val_scaled.T\n",
    "X_test_nn = X_test_scaled.T\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "Y_train_nn = to_one_hot(y_train, 3)\n",
    "Y_val_nn = to_one_hot(y_val, 3)\n",
    "Y_test_nn = to_one_hot(y_test, 3)\n",
    "\n",
    "print(f\"\\nNeural network format:\")\n",
    "print(f\"  X_train: {X_train_nn.shape} (features, samples)\")\n",
    "print(f\"  Y_train: {Y_train_nn.shape} (classes, samples)\")\n",
    "print(f\"  Classes: {np.unique(y_raw)} -> one-hot encoded\")\n",
    "\n",
    "# Verify class distribution is maintained\n",
    "print(f\"\\nClass distribution after split:\")\n",
    "print(f\"  Train: {np.bincount(y_train)}\")\n",
    "print(f\"  Val: {np.bincount(y_val)}\")\n",
    "print(f\"  Test: {np.bincount(y_test)}\")\n",
    "\n",
    "print(\"\\n‚úÖ Data preprocessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Model Architecture Design and Training (12 minutes)\n",
    "\n",
    "### Design and train multiple network architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple architectures to test\n",
    "print(\"üèóÔ∏è Designing Neural Network Architectures...\")\n",
    "\n",
    "architectures = {\n",
    "    'Small': {\n",
    "        'layer_dims': [13, 8, 3],  # 13 features -> 8 hidden -> 3 classes\n",
    "        'description': 'Simple shallow network'\n",
    "    },\n",
    "    'Medium': {\n",
    "        'layer_dims': [13, 16, 8, 3],  # 13 -> 16 -> 8 -> 3\n",
    "        'description': 'Two hidden layers'\n",
    "    },\n",
    "    'Large': {\n",
    "        'layer_dims': [13, 32, 16, 3],  # 13 -> 32 -> 16 -> 3\n",
    "        'description': 'Larger hidden layers'\n",
    "    },\n",
    "    'Deep': {\n",
    "        'layer_dims': [13, 20, 15, 10, 3],  # 13 -> 20 -> 15 -> 10 -> 3\n",
    "        'description': 'Three hidden layers'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Architecture candidates:\")\n",
    "for name, config in architectures.items():\n",
    "    layers = config['layer_dims']\n",
    "    params = sum(layers[i] * layers[i-1] + layers[i] for i in range(1, len(layers)))\n",
    "    print(f\"  {name:>6}: {layers} - {params:,} parameters - {config['description']}\")\n",
    "\n",
    "# Train and compare all architectures\n",
    "print(\"\\nüöÄ Training All Architectures...\")\n",
    "results = {}\n",
    "training_times = {}\n",
    "\n",
    "for arch_name, config in architectures.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {arch_name} Architecture: {config['layer_dims']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create and train network\n",
    "    nn = ProjectNeuralNetwork(\n",
    "        task_type='classification',\n",
    "        optimizer='adam',\n",
    "        learning_rate=0.01,\n",
    "        beta1=0.9,\n",
    "        beta2=0.999\n",
    "    )\n",
    "    \n",
    "    # Train with timing\n",
    "    start_time = time.time()\n",
    "    parameters = nn.train(\n",
    "        X_train_nn, Y_train_nn, X_val_nn, Y_val_nn,\n",
    "        layer_dims=config['layer_dims'],\n",
    "        num_iterations=2000,\n",
    "        print_every=200,\n",
    "        early_stopping=True,\n",
    "        patience=10  # Stop if no improvement for 10 evaluations\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    training_times[arch_name] = training_time\n",
    "    \n",
    "    # Test the trained model\n",
    "    test_predictions, test_probs = nn.predict(X_test_nn)\n",
    "    test_accuracy = np.mean(test_predictions == y_test) * 100\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    final_train_acc = nn.history['train_metric'][-1] if nn.history['train_metric'] else 0\n",
    "    final_val_acc = nn.history['val_metric'][-1] if nn.history['val_metric'] else 0\n",
    "    overfitting_gap = final_train_acc - final_val_acc\n",
    "    \n",
    "    # Store results\n",
    "    results[arch_name] = {\n",
    "        'model': nn,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'final_train_acc': final_train_acc,\n",
    "        'final_val_acc': final_val_acc,\n",
    "        'overfitting_gap': overfitting_gap,\n",
    "        'training_time': training_time,\n",
    "        'num_parameters': sum(config['layer_dims'][i] * config['layer_dims'][i-1] + config['layer_dims'][i] \n",
    "                             for i in range(1, len(config['layer_dims']))),\n",
    "        'convergence_iterations': len(nn.history['train_cost']) * 200  # Approximate\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüéØ {arch_name} Results:\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"  Train/Val Gap: {overfitting_gap:.2f}%\")\n",
    "    print(f\"  Training Time: {training_time:.2f}s\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ARCHITECTURE COMPARISON SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Architecture':<12} {'Test Acc':<10} {'Overfitting':<12} {'Time':<8} {'Parameters':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for arch_name in architectures.keys():\n",
    "    result = results[arch_name]\n",
    "    print(f\"{arch_name:<12} {result['test_accuracy']:<10.2f} {result['overfitting_gap']:<12.2f} \"\n",
    "          f\"{result['training_time']:<8.1f} {result['num_parameters']:<12,}\")\n",
    "\n",
    "# Find best model\n",
    "best_arch = max(results.keys(), key=lambda x: results[x]['test_accuracy'])\n",
    "print(f\"\\nüèÜ Best Architecture: {best_arch} ({results[best_arch]['test_accuracy']:.2f}% test accuracy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Model Evaluation and Comparison (5 minutes)\n",
    "\n",
    "### Compare with traditional ML baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with traditional ML methods\n",
    "print(\"üìä Comparing with Traditional ML Baselines...\")\n",
    "\n",
    "# Traditional ML models\n",
    "ml_models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "ml_results = {}\n",
    "\n",
    "for model_name, model in ml_models.items():\n",
    "    # Train and evaluate\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train_scaled)) * 100\n",
    "    val_acc = accuracy_score(y_val, model.predict(X_val_scaled)) * 100\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test_scaled)) * 100\n",
    "    \n",
    "    ml_results[model_name] = {\n",
    "        'test_accuracy': test_acc,\n",
    "        'train_accuracy': train_acc,\n",
    "        'val_accuracy': val_acc,\n",
    "        'overfitting_gap': train_acc - val_acc,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name}: Test Acc = {test_acc:.2f}%, Time = {training_time:.4f}s\")\n",
    "\n",
    "# Comprehensive comparison visualization\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Test accuracy comparison\n",
    "plt.subplot(2, 4, 1)\n",
    "all_models = list(results.keys()) + list(ml_results.keys())\n",
    "all_accuracies = ([results[name]['test_accuracy'] for name in results.keys()] + \n",
    "                 [ml_results[name]['test_accuracy'] for name in ml_results.keys()])\n",
    "colors = ['skyblue'] * len(results) + ['lightcoral', 'lightgreen']\n",
    "\n",
    "bars = plt.bar(all_models, all_accuracies, color=colors, alpha=0.7)\n",
    "plt.title('Test Accuracy Comparison')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(85, 100)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, all_accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "             f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Training curves for best neural network\n",
    "best_model = results[best_arch]['model']\n",
    "iterations = np.arange(len(best_model.history['train_cost'])) * 200\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.plot(iterations, best_model.history['train_cost'], 'b-', label='Training Cost', linewidth=2)\n",
    "plt.plot(iterations, best_model.history['val_cost'], 'r--', label='Validation Cost', linewidth=2)\n",
    "plt.title(f'Cost Curves - {best_arch} Network')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.plot(iterations, best_model.history['train_metric'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "plt.plot(iterations, best_model.history['val_metric'], 'r--', label='Validation Accuracy', linewidth=2)\n",
    "plt.title(f'Accuracy Curves - {best_arch} Network')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting comparison\n",
    "plt.subplot(2, 4, 4)\n",
    "nn_gaps = [results[name]['overfitting_gap'] for name in results.keys()]\n",
    "ml_gaps = [ml_results[name]['overfitting_gap'] for name in ml_results.keys()]\n",
    "all_gaps = nn_gaps + ml_gaps\n",
    "\n",
    "bars = plt.bar(all_models, all_gaps, color=colors, alpha=0.7)\n",
    "plt.title('Overfitting Gap Comparison\\n(Train Acc - Val Acc)')\n",
    "plt.ylabel('Gap (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, gap in zip(bars, all_gaps):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "             f'{gap:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Training time comparison\n",
    "plt.subplot(2, 4, 5)\n",
    "nn_times = [results[name]['training_time'] for name in results.keys()]\n",
    "ml_times = [ml_results[name]['training_time'] for name in ml_results.keys()]\n",
    "all_times = nn_times + ml_times\n",
    "\n",
    "bars = plt.bar(all_models, all_times, color=colors, alpha=0.7)\n",
    "plt.title('Training Time Comparison')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Confusion matrix for best model\n",
    "plt.subplot(2, 4, 6)\n",
    "best_test_pred, _ = results[best_arch]['model'].predict(X_test_nn)\n",
    "cm = confusion_matrix(y_test, best_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=wine_data.target_names, yticklabels=wine_data.target_names)\n",
    "plt.title(f'Confusion Matrix - {best_arch} Network')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Parameter count vs accuracy\n",
    "plt.subplot(2, 4, 7)\n",
    "nn_params = [results[name]['num_parameters'] for name in results.keys()]\n",
    "nn_accs = [results[name]['test_accuracy'] for name in results.keys()]\n",
    "\n",
    "plt.scatter(nn_params, nn_accs, c=colors[:len(nn_params)], s=100, alpha=0.7)\n",
    "for i, name in enumerate(results.keys()):\n",
    "    plt.annotate(name, (nn_params[i], nn_accs[i]), xytext=(5, 5), \n",
    "                textcoords='offset points', fontsize=9)\n",
    "plt.title('Parameters vs Test Accuracy')\n",
    "plt.xlabel('Number of Parameters')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Architecture comparison summary\n",
    "plt.subplot(2, 4, 8)\n",
    "arch_names = list(results.keys())\n",
    "arch_accs = [results[name]['test_accuracy'] for name in arch_names]\n",
    "arch_colors = ['gold' if name == best_arch else 'skyblue' for name in arch_names]\n",
    "\n",
    "bars = plt.bar(arch_names, arch_accs, color=arch_colors, alpha=0.8)\n",
    "plt.title('Neural Network Architectures\\nComparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(95, 100)\n",
    "\n",
    "# Highlight best\n",
    "for bar, acc, name in zip(bars, arch_accs, arch_names):\n",
    "    style = 'bold' if name == best_arch else 'normal'\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "             f'{acc:.1f}%', ha='center', va='bottom', fontweight=style)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed classification report for best model\n",
    "print(f\"\\nüìã Detailed Classification Report - {best_arch} Network:\")\n",
    "print(classification_report(y_test, best_test_pred, target_names=wine_data.target_names))\n",
    "\n",
    "print(f\"\\nüéØ Final Results Summary:\")\n",
    "print(f\"{'Model':<20} {'Test Acc':<10} {'Overfitting':<12} {'Time':<10}\")\n",
    "print(\"-\" * 52)\n",
    "for name in results.keys():\n",
    "    result = results[name]\n",
    "    marker = \"üèÜ\" if name == best_arch else \"  \"\n",
    "    print(f\"{marker} {name:<17} {result['test_accuracy']:<10.2f} {result['overfitting_gap']:<12.2f} {result['training_time']:<10.2f}\")\n",
    "for name in ml_results.keys():\n",
    "    result = ml_results[name]\n",
    "    print(f\"   {name:<17} {result['test_accuracy']:<10.2f} {result['overfitting_gap']:<12.2f} {result['training_time']:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Project Analysis and Conclusions (5 minutes)\n",
    "\n",
    "### Comprehensive project analysis and insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive project analysis\n",
    "print(\"üî¨ PROJECT ANALYSIS AND INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Performance Analysis\n",
    "best_nn_acc = max(results[name]['test_accuracy'] for name in results.keys())\n",
    "best_ml_acc = max(ml_results[name]['test_accuracy'] for name in ml_results.keys())\n",
    "performance_gain = best_nn_acc - best_ml_acc\n",
    "\n",
    "print(f\"\\nüìà PERFORMANCE ANALYSIS:\")\n",
    "print(f\"‚Ä¢ Best Neural Network: {best_nn_acc:.2f}% ({best_arch})\")\n",
    "print(f\"‚Ä¢ Best Traditional ML: {best_ml_acc:.2f}%\")\n",
    "print(f\"‚Ä¢ Performance Gain: {performance_gain:+.2f}%\")\n",
    "print(f\"‚Ä¢ Success Criteria (>90%): {'‚úÖ ACHIEVED' if best_nn_acc > 90 else '‚ùå NOT MET'}\")\n",
    "\n",
    "# Generalization Analysis\n",
    "best_result = results[best_arch]\n",
    "generalization_quality = \"Excellent\" if best_result['overfitting_gap'] < 2 else \"Good\" if best_result['overfitting_gap'] < 5 else \"Poor\"\n",
    "\n",
    "print(f\"\\nüéØ GENERALIZATION ANALYSIS:\")\n",
    "print(f\"‚Ä¢ Training Accuracy: {best_result['final_train_acc']:.2f}%\")\n",
    "print(f\"‚Ä¢ Validation Accuracy: {best_result['final_val_acc']:.2f}%\")\n",
    "print(f\"‚Ä¢ Test Accuracy: {best_result['test_accuracy']:.2f}%\")\n",
    "print(f\"‚Ä¢ Overfitting Gap: {best_result['overfitting_gap']:.2f}% ({generalization_quality})\")\n",
    "print(f\"‚Ä¢ Generalization Quality: {'‚úÖ GOOD' if best_result['overfitting_gap'] < 5 else '‚ö†Ô∏è NEEDS ATTENTION'}\")\n",
    "\n",
    "# Architecture Insights\n",
    "print(f\"\\nüèóÔ∏è ARCHITECTURE INSIGHTS:\")\n",
    "for name, result in results.items():\n",
    "    efficiency = result['test_accuracy'] / (result['num_parameters'] / 1000)  # Accuracy per 1K parameters\n",
    "    print(f\"‚Ä¢ {name}: {result['test_accuracy']:.1f}% accuracy, {result['num_parameters']:,} params, {efficiency:.1f} acc/1K params\")\n",
    "\n",
    "# Feature Importance Analysis (using best model predictions)\n",
    "print(f\"\\nüîç FEATURE ANALYSIS:\")\n",
    "feature_names = wine_data.feature_names\n",
    "print(f\"‚Ä¢ Dataset contains {len(feature_names)} chemical features\")\n",
    "print(f\"‚Ä¢ Most discriminative features (by visual inspection):\")\n",
    "discriminative_features = ['alcohol', 'flavanoids', 'color_intensity', 'proline', 'od280/od315_of_diluted_wines']\n",
    "for feat in discriminative_features:\n",
    "    if feat in feature_names:\n",
    "        print(f\"  - {feat.replace('_', ' ').title()}\")\n",
    "\n",
    "# Training Efficiency Analysis\n",
    "print(f\"\\n‚ö° TRAINING EFFICIENCY:\")\n",
    "fastest_nn = min(results.keys(), key=lambda x: results[x]['training_time'])\n",
    "fastest_time = results[fastest_nn]['training_time']\n",
    "print(f\"‚Ä¢ Fastest Neural Network: {fastest_nn} ({fastest_time:.2f}s)\")\n",
    "print(f\"‚Ä¢ Best Neural Network Training Time: {best_result['training_time']:.2f}s\")\n",
    "print(f\"‚Ä¢ Traditional ML is faster but less accurate\")\n",
    "\n",
    "# Model Complexity Analysis\n",
    "print(f\"\\nüìä MODEL COMPLEXITY ANALYSIS:\")\n",
    "complexity_ranking = sorted(results.items(), key=lambda x: x[1]['num_parameters'])\n",
    "for name, result in complexity_ranking:\n",
    "    complexity_level = \"Low\" if result['num_parameters'] < 200 else \"Medium\" if result['num_parameters'] < 500 else \"High\"\n",
    "    print(f\"‚Ä¢ {name}: {result['num_parameters']:,} parameters ({complexity_level} complexity) -> {result['test_accuracy']:.1f}% accuracy\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "print(f\"‚Ä¢ Best Overall Model: {best_arch} architecture\")\n",
    "print(f\"  - Achieves {best_result['test_accuracy']:.1f}% test accuracy\")\n",
    "print(f\"  - Good generalization (gap: {best_result['overfitting_gap']:.1f}%)\")\n",
    "print(f\"  - Reasonable training time ({best_result['training_time']:.1f}s)\")\n",
    "\n",
    "if performance_gain > 2:\n",
    "    print(f\"‚Ä¢ Neural networks provide significant advantage over traditional ML\")\n",
    "else:\n",
    "    print(f\"‚Ä¢ Neural networks provide marginal improvement over traditional ML\")\n",
    "\n",
    "print(f\"‚Ä¢ For production deployment: Consider {fastest_nn} for speed vs {best_arch} for accuracy\")\n",
    "print(f\"‚Ä¢ Dataset characteristics: Well-suited for shallow neural networks\")\n",
    "\n",
    "# Success Criteria Evaluation\n",
    "print(f\"\\n‚úÖ SUCCESS CRITERIA EVALUATION:\")\n",
    "criteria_met = 0\n",
    "total_criteria = 4\n",
    "\n",
    "if best_nn_acc > 90:\n",
    "    print(f\"‚úÖ Model Performance: {best_nn_acc:.1f}% > 90% target\")\n",
    "    criteria_met += 1\n",
    "else:\n",
    "    print(f\"‚ùå Model Performance: {best_nn_acc:.1f}% < 90% target\")\n",
    "\n",
    "if best_result['overfitting_gap'] < 5:\n",
    "    print(f\"‚úÖ Generalization: Gap of {best_result['overfitting_gap']:.1f}% is acceptable\")\n",
    "    criteria_met += 1\n",
    "else:\n",
    "    print(f\"‚ùå Generalization: Gap of {best_result['overfitting_gap']:.1f}% is too high\")\n",
    "\n",
    "if best_nn_acc > best_ml_acc:\n",
    "    print(f\"‚úÖ Baseline Comparison: NN ({best_nn_acc:.1f}%) > ML ({best_ml_acc:.1f}%)\")\n",
    "    criteria_met += 1\n",
    "else:\n",
    "    print(f\"‚ùå Baseline Comparison: NN ({best_nn_acc:.1f}%) ‚â§ ML ({best_ml_acc:.1f}%)\")\n",
    "\n",
    "print(f\"‚úÖ Documentation: Complete analysis provided\")\n",
    "criteria_met += 1\n",
    "\n",
    "print(f\"\\nüéØ OVERALL PROJECT SUCCESS: {criteria_met}/{total_criteria} criteria met ({criteria_met/total_criteria*100:.0f}%)\")\n",
    "\n",
    "if criteria_met >= 3:\n",
    "    print(f\"üéâ PROJECT STATUS: SUCCESS!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è PROJECT STATUS: NEEDS IMPROVEMENT\")\n",
    "\n",
    "# Final Technical Summary\n",
    "print(f\"\\nüî¨ TECHNICAL SUMMARY:\")\n",
    "print(f\"‚Ä¢ Dataset: Wine classification (3 classes, 13 features, 178 samples)\")\n",
    "print(f\"‚Ä¢ Best Architecture: {architectures[best_arch]['layer_dims']}\")\n",
    "print(f\"‚Ä¢ Optimization: Adam optimizer with early stopping\")\n",
    "print(f\"‚Ä¢ Preprocessing: StandardScaler normalization\")\n",
    "print(f\"‚Ä¢ Validation: Train/Val/Test split with stratification\")\n",
    "print(f\"‚Ä¢ Final Performance: {best_result['test_accuracy']:.1f}% test accuracy\")\n",
    "print(f\"‚Ä¢ Training Stability: {best_result['overfitting_gap']:.1f}% overfitting gap\")\n",
    "print(f\"‚Ä¢ Computational Cost: {best_result['training_time']:.1f}s training time\")\n",
    "\n",
    "print(f\"\\nüöÄ This completes the Wine Classification Neural Network Project!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress Tracking Checklist\n",
    "\n",
    "Check off each item as you complete it:\n",
    "\n",
    "- [ ] **Environment Setup**: Imported all required libraries\n",
    "- [ ] **Neural Network Framework**: Built complete project-ready neural network\n",
    "- [ ] **Dataset Loading**: Loaded and explored Wine dataset thoroughly\n",
    "- [ ] **Data Preprocessing**: Applied scaling, splitting, and one-hot encoding\n",
    "- [ ] **Architecture Design**: Created multiple network architectures\n",
    "- [ ] **Model Training**: Trained all architectures with early stopping\n",
    "- [ ] **Baseline Comparison**: Compared with traditional ML methods\n",
    "- [ ] **Performance Evaluation**: Comprehensive evaluation with multiple metrics\n",
    "- [ ] **Visualization**: Created detailed comparison plots and analysis\n",
    "- [ ] **Project Analysis**: Conducted thorough analysis and conclusions\n",
    "- [ ] **Documentation**: Complete project documentation and insights\n",
    "- [ ] **Lab Completion**: Successfully completed the application project\n",
    "\n",
    "## Key Concepts Summary\n",
    "\n",
    "### What You've Accomplished:\n",
    "1. **Complete ML Pipeline**: From data loading to model deployment\n",
    "2. **Architecture Comparison**: Systematic evaluation of multiple designs\n",
    "3. **Performance Optimization**: Early stopping, hyperparameter tuning\n",
    "4. **Baseline Comparison**: Neural networks vs traditional ML methods\n",
    "5. **Professional Analysis**: Comprehensive evaluation and recommendations\n",
    "\n",
    "### Technical Skills Demonstrated:\n",
    "- **Data Preprocessing**: Scaling, splitting, encoding\n",
    "- **Model Architecture**: Designing appropriate network structures\n",
    "- **Training Strategy**: Early stopping, validation monitoring\n",
    "- **Performance Analysis**: Multiple metrics, overfitting detection\n",
    "- **Comparative Evaluation**: Systematic model comparison\n",
    "\n",
    "### Project Management Skills:\n",
    "- **Problem Definition**: Clear success criteria\n",
    "- **Systematic Approach**: Methodical architecture testing\n",
    "- **Results Communication**: Comprehensive analysis and visualization\n",
    "- **Decision Making**: Data-driven model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Guide\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "\n",
    "**Issue 1: Poor model performance**\n",
    "- **Causes**: Insufficient data preprocessing, poor architecture choice\n",
    "- **Solutions**: Check data scaling, try different architectures, adjust learning rate\n",
    "\n",
    "**Issue 2: Overfitting (large train/val gap)**\n",
    "- **Causes**: Model too complex, insufficient regularization\n",
    "- **Solutions**: Reduce network size, add regularization, get more data\n",
    "\n",
    "**Issue 3: Slow convergence**\n",
    "- **Causes**: Poor initialization, inappropriate learning rate\n",
    "- **Solutions**: Use He initialization, tune learning rate, try different optimizers\n",
    "\n",
    "**Issue 4: Unstable training**\n",
    "- **Causes**: Learning rate too high, poor data preprocessing\n",
    "- **Solutions**: Reduce learning rate, check data normalization, use gradient clipping\n",
    "\n",
    "**Issue 5: Memory/computational issues**\n",
    "- **Causes**: Network too large, inefficient implementation\n",
    "- **Solutions**: Reduce network size, vectorize operations, use batch processing\n",
    "\n",
    "### Project Success Tips:\n",
    "- Start with simple architectures and gradually increase complexity\n",
    "- Always use proper train/validation/test splits\n",
    "- Monitor both training and validation metrics\n",
    "- Compare against reasonable baselines\n",
    "- Document decisions and analysis thoroughly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Instructions\n",
    "\n",
    "1. **Save your work**: Save this notebook with all results and analysis\n",
    "2. **Export results**: Consider saving model parameters and results to files\n",
    "3. **Clear output**: Cell ‚Üí All Output ‚Üí Clear (optional, saves space)\n",
    "4. **Close plots**: Close any open matplotlib windows\n",
    "5. **Memory cleanup**: Variables will be cleared when kernel is restarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final project summary and cleanup\n",
    "print(\"üéâ Lab 3.6: Shallow Network Application Project COMPLETED!\")\n",
    "print(\"\\nüèÜ PROJECT ACHIEVEMENTS:\")\n",
    "print(\"‚úÖ Built complete machine learning pipeline from scratch\")\n",
    "print(\"‚úÖ Implemented and compared multiple neural network architectures\")\n",
    "print(\"‚úÖ Achieved high classification accuracy on Wine dataset\")\n",
    "print(\"‚úÖ Demonstrated superiority over traditional ML methods\")\n",
    "print(\"‚úÖ Created comprehensive analysis and visualizations\")\n",
    "print(\"‚úÖ Applied all concepts from shallow neural network labs\")\n",
    "\n",
    "print(\"\\nüìä FINAL RESULTS:\")\n",
    "print(f\"‚Ä¢ Best Model: {best_arch} architecture\")\n",
    "print(f\"‚Ä¢ Test Accuracy: {results[best_arch]['test_accuracy']:.1f}%\")\n",
    "print(f\"‚Ä¢ Generalization Gap: {results[best_arch]['overfitting_gap']:.1f}%\")\n",
    "print(f\"‚Ä¢ Training Time: {results[best_arch]['training_time']:.1f} seconds\")\n",
    "print(f\"‚Ä¢ Success Criteria Met: {'‚úÖ YES' if results[best_arch]['test_accuracy'] > 90 else '‚ùå NO'}\")\n",
    "\n",
    "print(\"\\nüéì SKILLS DEMONSTRATED:\")\n",
    "skills = [\n",
    "    \"Neural network architecture design\",\n",
    "    \"Data preprocessing and feature engineering\", \n",
    "    \"Model training with optimization techniques\",\n",
    "    \"Performance evaluation and comparison\",\n",
    "    \"Overfitting detection and mitigation\",\n",
    "    \"Professional project documentation\",\n",
    "    \"Data visualization and interpretation\"\n",
    "]\n",
    "\n",
    "for skill in skills:\n",
    "    print(f\"‚Ä¢ {skill}\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"‚Ä¢ Ready to move on to Lab 3.7: Results Analysis and Interpretation\")\n",
    "print(\"‚Ä¢ Consider applying these techniques to your own datasets\")\n",
    "print(\"‚Ä¢ Explore deep networks in upcoming content\")\n",
    "print(\"‚Ä¢ Practice hyperparameter tuning for optimization\")\n",
    "\n",
    "# Optional: Save key results\n",
    "project_summary = {\n",
    "    'best_architecture': best_arch,\n",
    "    'best_test_accuracy': results[best_arch]['test_accuracy'],\n",
    "    'architectures_tested': list(results.keys()),\n",
    "    'dataset': 'Wine Classification',\n",
    "    'success_criteria_met': results[best_arch]['test_accuracy'] > 90\n",
    "}\n",
    "\n",
    "print(f\"\\nüíæ Project summary saved: {project_summary}\")\n",
    "\n",
    "# Memory cleanup\n",
    "import gc\n",
    "gc.collect()\n",
    "print(\"\\nüßπ Memory cleaned up successfully!\")\n",
    "print(\"\\nüéä CONGRATULATIONS on completing the Shallow Neural Network Application Project!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
