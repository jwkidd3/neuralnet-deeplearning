{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.6: Shallow Network Application Project\n",
    "\n",
    "## Learning Objectives\n",
    "- Apply shallow neural networks to a real-world dataset\n",
    "- Implement complete machine learning pipeline\n",
    "- Practice model selection and hyperparameter tuning\n",
    "- Create comprehensive project documentation and analysis\n",
    "\n",
    "## Duration: 45 minutes\n",
    "\n",
    "## Prerequisites\n",
    "- Completion of Labs 3.1-3.5\n",
    "- Understanding of all shallow neural network concepts\n",
    "- Knowledge of optimization and regularization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_wine, load_digits, fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else 'default')\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "\n",
    "print(\"🚀 Environment setup complete!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview: Wine Quality Classification\n",
    "\n",
    "### Project Goal\n",
    "Build a shallow neural network to classify wine varieties based on chemical properties.\n",
    "\n",
    "### Success Criteria\n",
    "1. **Model Performance**: Achieve >90% test accuracy\n",
    "2. **Generalization**: Small gap between training and validation performance\n",
    "3. **Comparison**: Outperform traditional machine learning baselines\n",
    "4. **Documentation**: Complete analysis and interpretation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Complete Neural Network Framework (10 minutes)\n",
    "\n",
    "### Import and enhance our best neural network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete neural network implementation combining all previous labs\n",
    "class ProjectNeuralNetwork:\n",
    "    \"\"\"\n",
    "    Complete neural network implementation for the application project\n",
    "    Combines all techniques from previous labs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, task_type='classification', optimizer='adam', **optimizer_kwargs):\n",
    "        self.task_type = task_type\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        if optimizer.lower() == 'adam':\n",
    "            self.optimizer = self.AdamOptimizer(**optimizer_kwargs)\n",
    "        elif optimizer.lower() == 'momentum':\n",
    "            self.optimizer = self.MomentumOptimizer(**optimizer_kwargs)\n",
    "        else:\n",
    "            self.optimizer = self.SGDOptimizer(**optimizer_kwargs)\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'train_cost': [],\n",
    "            'train_metric': [],\n",
    "            'val_cost': [],\n",
    "            'val_metric': []\n",
    "        }\n",
    "        \n",
    "        self.parameters = {}\n",
    "        self.best_parameters = {}\n",
    "        self.best_val_metric = 0 if task_type == 'classification' else float('inf')\n",
    "    \n",
    "    class AdamOptimizer:\n",
    "        def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "            self.learning_rate = learning_rate\n",
    "            self.beta1 = beta1\n",
    "            self.beta2 = beta2\n",
    "            self.epsilon = epsilon\n",
    "            self.t = 0\n",
    "            self.momentum = {}\n",
    "            self.velocity = {}\n",
    "        \n",
    "        def update(self, parameters, gradients):\n",
    "            self.t += 1\n",
    "            \n",
    "            # Initialize moments on first update\n",
    "            if not self.momentum:\n",
    "                for key in parameters:\n",
    "                    if f'd{key}' in gradients:\n",
    "                        self.momentum[f'm_{key}'] = np.zeros_like(parameters[key])\n",
    "                        self.velocity[f'v_{key}'] = np.zeros_like(parameters[key])\n",
    "            \n",
    "            for key in parameters:\n",
    "                if f'd{key}' in gradients:\n",
    "                    grad = gradients[f'd{key}']\n",
    "                    \n",
    "                    # Update moments\n",
    "                    self.momentum[f'm_{key}'] = (self.beta1 * self.momentum[f'm_{key}'] + \n",
    "                                               (1 - self.beta1) * grad)\n",
    "                    self.velocity[f'v_{key}'] = (self.beta2 * self.velocity[f'v_{key}'] + \n",
    "                                               (1 - self.beta2) * (grad ** 2))\n",
    "                    \n",
    "                    # Bias correction\n",
    "                    m_corrected = self.momentum[f'm_{key}'] / (1 - self.beta1 ** self.t)\n",
    "                    v_corrected = self.velocity[f'v_{key}'] / (1 - self.beta2 ** self.t)\n",
    "                    \n",
    "                    # Update parameters\n",
    "                    parameters[key] -= (self.learning_rate * m_corrected / \n",
    "                                      (np.sqrt(v_corrected) + self.epsilon))\n",
    "            \n",
    "            return parameters\n",
    "        \n",
    "        def reset(self):\n",
    "            self.t = 0\n",
    "            self.momentum = {}\n",
    "            self.velocity = {}\n",
    "    \n",
    "    class MomentumOptimizer:\n",
    "        def __init__(self, learning_rate=0.01, beta=0.9):\n",
    "            self.learning_rate = learning_rate\n",
    "            self.beta = beta\n",
    "            self.velocity = {}\n",
    "        \n",
    "        def update(self, parameters, gradients):\n",
    "            if not self.velocity:\n",
    "                for key in parameters:\n",
    "                    if f'd{key}' in gradients:\n",
    "                        self.velocity[f'v_{key}'] = np.zeros_like(parameters[key])\n",
    "            \n",
    "            for key in parameters:\n",
    "                if f'd{key}' in gradients:\n",
    "                    self.velocity[f'v_{key}'] = (self.beta * self.velocity[f'v_{key}'] + \n",
    "                                               (1 - self.beta) * gradients[f'd{key}'])\n",
    "                    parameters[key] -= self.learning_rate * self.velocity[f'v_{key}']\n",
    "            \n",
    "            return parameters\n",
    "        \n",
    "        def reset(self):\n",
    "            self.velocity = {}\n",
    "    \n",
    "    class SGDOptimizer:\n",
    "        def __init__(self, learning_rate=0.01):\n",
    "            self.learning_rate = learning_rate\n",
    "        \n",
    "        def update(self, parameters, gradients):\n",
    "            for key in parameters:\n",
    "                if f'd{key}' in gradients:\n",
    "                    parameters[key] -= self.learning_rate * gradients[f'd{key}']\n",
    "            return parameters\n",
    "        \n",
    "        def reset(self):\n",
    "            pass\n",
    "    \n",
    "    def initialize_parameters(self, layer_dims):\n",
    "        \"\"\"Initialize parameters with He initialization\"\"\"\n",
    "        parameters = {}\n",
    "        \n",
    "        for l in range(1, len(layer_dims)):\n",
    "            parameters[f'W{l}'] = np.random.randn(layer_dims[l], layer_dims[l-1]) * np.sqrt(2.0 / layer_dims[l-1])\n",
    "            parameters[f'b{l}'] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        return parameters\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        \"\"\"Stable softmax implementation\"\"\"\n",
    "        z_stable = z - np.max(z, axis=0, keepdims=True)\n",
    "        exp_z = np.exp(z_stable)\n",
    "        return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n",
    "    \n",
    "    def forward_propagation(self, X, parameters):\n",
    "        \"\"\"Forward propagation\"\"\"\n",
    "        caches = []\n",
    "        A = X\n",
    "        L = len(parameters) // 2\n",
    "        \n",
    "        # Hidden layers (ReLU)\n",
    "        for l in range(1, L):\n",
    "            A_prev = A\n",
    "            W = parameters[f'W{l}']\n",
    "            b = parameters[f'b{l}']\n",
    "            \n",
    "            Z = np.dot(W, A_prev) + b\n",
    "            A = np.maximum(0, Z)  # ReLU\n",
    "            \n",
    "            cache = ((A_prev, W, b), Z)\n",
    "            caches.append(cache)\n",
    "        \n",
    "        # Output layer\n",
    "        A_prev = A\n",
    "        W = parameters[f'W{L}']\n",
    "        b = parameters[f'b{L}']\n",
    "        Z = np.dot(W, A_prev) + b\n",
    "        \n",
    "        if self.task_type == 'classification' and Z.shape[0] > 1:\n",
    "            A = self.softmax(Z)  # Multi-class\n",
    "        elif self.task_type == 'classification':\n",
    "            A = 1 / (1 + np.exp(-np.clip(Z, -500, 500)))  # Binary\n",
    "        else:\n",
    "            A = Z  # Regression\n",
    "        \n",
    "        cache = ((A_prev, W, b), Z)\n",
    "        caches.append(cache)\n",
    "        \n",
    "        return A, caches\n",
    "    \n",
    "    def compute_cost(self, AL, Y):\n",
    "        \"\"\"Compute cost based on task type\"\"\"\n",
    "        m = Y.shape[1]\n",
    "        \n",
    "        if self.task_type == 'classification' and AL.shape[0] > 1:\n",
    "            # Multi-class cross-entropy\n",
    "            AL_clipped = np.clip(AL, 1e-15, 1 - 1e-15)\n",
    "            cost = -1/m * np.sum(Y * np.log(AL_clipped))\n",
    "        elif self.task_type == 'classification':\n",
    "            # Binary cross-entropy\n",
    "            AL_clipped = np.clip(AL, 1e-15, 1 - 1e-15)\n",
    "            cost = -1/m * np.sum(Y * np.log(AL_clipped) + (1 - Y) * np.log(1 - AL_clipped))\n",
    "        else:\n",
    "            # Mean squared error\n",
    "            cost = 1/(2*m) * np.sum((AL - Y)**2)\n",
    "        \n",
    "        return np.squeeze(cost)\n",
    "    \n",
    "    def compute_metric(self, AL, Y):\n",
    "        \"\"\"Compute metric based on task type\"\"\"\n",
    "        if self.task_type == 'classification':\n",
    "            if AL.shape[0] > 1:\n",
    "                # Multi-class accuracy\n",
    "                predictions = np.argmax(AL, axis=0)\n",
    "                true_labels = np.argmax(Y, axis=0)\n",
    "            else:\n",
    "                # Binary accuracy\n",
    "                predictions = (AL > 0.5).astype(int)\n",
    "                true_labels = Y.astype(int)\n",
    "            \n",
    "            return np.mean(predictions == true_labels) * 100\n",
    "        else:\n",
    "            # R² score for regression\n",
    "            ss_res = np.sum((Y - AL) ** 2)\n",
    "            ss_tot = np.sum((Y - np.mean(Y)) ** 2)\n",
    "            return 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "    \n",
    "    def backward_propagation(self, AL, Y, caches):\n",
    "        \"\"\"Backward propagation\"\"\"\n",
    "        gradients = {}\n",
    "        L = len(caches)\n",
    "        m = AL.shape[1]\n",
    "        \n",
    "        # Initialize backward propagation\n",
    "        if self.task_type == 'classification' and AL.shape[0] > 1:\n",
    "            # Multi-class: dZ = AL - Y\n",
    "            dZ = AL - Y\n",
    "        elif self.task_type == 'classification':\n",
    "            # Binary: dZ = AL - Y (for sigmoid)\n",
    "            dZ = AL - Y\n",
    "        else:\n",
    "            # Regression: dZ = AL - Y\n",
    "            dZ = AL - Y\n",
    "        \n",
    "        # Output layer\n",
    "        (A_prev, W, b), _ = caches[L-1]\n",
    "        gradients[f'dW{L}'] = 1/m * np.dot(dZ, A_prev.T)\n",
    "        gradients[f'db{L}'] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
    "        dA_prev = np.dot(W.T, dZ)\n",
    "        \n",
    "        # Hidden layers\n",
    "        for l in reversed(range(L-1)):\n",
    "            (A_prev, W, b), Z = caches[l]\n",
    "            \n",
    "            # ReLU derivative\n",
    "            dZ = dA_prev * (Z > 0).astype(float)\n",
    "            \n",
    "            gradients[f'dW{l+1}'] = 1/m * np.dot(dZ, A_prev.T)\n",
    "            gradients[f'db{l+1}'] = 1/m * np.sum(dZ, axis=1, keepdims=True)\n",
    "            \n",
    "            if l > 0:\n",
    "                dA_prev = np.dot(W.T, dZ)\n",
    "        \n",
    "        return gradients\n",
    "    \n",
    "    def train(self, X_train, Y_train, X_val, Y_val, layer_dims, \n",
    "              num_iterations=1000, print_every=100, early_stopping=True, patience=50):\n",
    "        \"\"\"Train the neural network with early stopping\"\"\"\n",
    "        \n",
    "        # Initialize\n",
    "        parameters = self.initialize_parameters(layer_dims)\n",
    "        self.optimizer.reset()\n",
    "        \n",
    "        # Early stopping variables\n",
    "        best_val_metric = 0 if self.task_type == 'classification' else float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Training loop\n",
    "        for i in range(num_iterations):\n",
    "            # Forward and backward propagation\n",
    "            AL_train, caches = self.forward_propagation(X_train, parameters)\n",
    "            train_cost = self.compute_cost(AL_train, Y_train)\n",
    "            gradients = self.backward_propagation(AL_train, Y_train, caches)\n",
    "            parameters = self.optimizer.update(parameters, gradients)\n",
    "            \n",
    "            # Validation and logging\n",
    "            if i % print_every == 0:\n",
    "                train_metric = self.compute_metric(AL_train, Y_train)\n",
    "                \n",
    "                AL_val, _ = self.forward_propagation(X_val, parameters)\n",
    "                val_cost = self.compute_cost(AL_val, Y_val)\n",
    "                val_metric = self.compute_metric(AL_val, Y_val)\n",
    "                \n",
    "                # Store history\n",
    "                self.history['train_cost'].append(train_cost)\n",
    "                self.history['train_metric'].append(train_metric)\n",
    "                self.history['val_cost'].append(val_cost)\n",
    "                self.history['val_metric'].append(val_metric)\n",
    "                \n",
    "                print(f\"Iter {i:4d}: Train Cost={train_cost:.6f}, Train Metric={train_metric:.2f}, \"\n",
    "                      f\"Val Cost={val_cost:.6f}, Val Metric={val_metric:.2f}\")\n",
    "                \n",
    "                # Early stopping check\n",
    "                if early_stopping:\n",
    "                    improved = False\n",
    "                    if self.task_type == 'classification' and val_metric > best_val_metric:\n",
    "                        improved = True\n",
    "                    elif self.task_type == 'regression' and val_metric < best_val_metric:\n",
    "                        improved = True\n",
    "                    \n",
    "                    if improved:\n",
    "                        best_val_metric = val_metric\n",
    "                        self.best_parameters = {k: v.copy() for k, v in parameters.items()}\n",
    "                        patience_counter = 0\n",
    "                    else:\n",
    "                        patience_counter += 1\n",
    "                    \n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"Early stopping at iteration {i} (patience reached)\")\n",
    "                        break\n",
    "        \n",
    "        # Use best parameters if early stopping was used\n",
    "        if early_stopping and self.best_parameters:\n",
    "            self.parameters = self.best_parameters\n",
    "        else:\n",
    "            self.parameters = parameters\n",
    "        \n",
    "        return self.parameters\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        AL, _ = self.forward_propagation(X, self.parameters)\n",
    "        \n",
    "        if self.task_type == 'classification':\n",
    "            if AL.shape[0] > 1:\n",
    "                predictions = np.argmax(AL, axis=0)\n",
    "            else:\n",
    "                predictions = (AL > 0.5).astype(int)\n",
    "            return predictions.flatten(), AL\n",
    "        else:\n",
    "            return AL.flatten(), AL\n",
    "\n",
    "print(\"🧠 Complete ProjectNeuralNetwork implemented!\")\n",
    "print(\"Features: Multi-class/binary classification, regression, early stopping, Adam/Momentum/SGD optimizers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Dataset Loading and Exploration (8 minutes)\n",
    "\n",
    "### Load and analyze the Wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wine dataset\n",
    "print(\"🍷 Loading Wine Dataset...\")\n",
    "wine_data = load_wine()\n",
    "X_raw = wine_data.data\n",
    "y_raw = wine_data.target\n",
    "\n",
    "# Create DataFrame for easier analysis\n",
    "wine_df = pd.DataFrame(X_raw, columns=wine_data.feature_names)\n",
    "wine_df['target'] = y_raw\n",
    "wine_df['target_name'] = [wine_data.target_names[i] for i in y_raw]\n",
    "\n",
    "print(f\"Dataset shape: {wine_df.shape}\")\n",
    "print(f\"Features: {len(wine_data.feature_names)}\")\n",
    "print(f\"Classes: {len(wine_data.target_names)}\")\n",
    "print(f\"Class names: {wine_data.target_names}\")\n",
    "print(f\"Samples per class: {np.bincount(y_raw)}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\n📊 Dataset Overview:\")\n",
    "print(wine_df.describe())\n",
    "\n",
    "print(\"\\n🎯 Class Distribution:\")\n",
    "print(wine_df['target_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data visualization\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Class distribution\n",
    "plt.subplot(3, 4, 1)\n",
    "wine_df['target_name'].value_counts().plot(kind='bar', color=['red', 'green', 'blue'], alpha=0.7)\n",
    "plt.title('Wine Class Distribution')\n",
    "plt.xlabel('Wine Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Feature correlation heatmap\n",
    "plt.subplot(3, 4, 2)\n",
    "# Select top features for readability\n",
    "top_features = ['alcohol', 'flavanoids', 'color_intensity', 'od280/od315_of_diluted_wines', \n",
    "               'proline', 'total_phenols']\n",
    "corr_matrix = wine_df[top_features + ['target']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix\\n(Top 6 Features)')\n",
    "\n",
    "# Feature distributions by class\n",
    "important_features = ['alcohol', 'flavanoids', 'color_intensity', 'proline']\n",
    "for i, feature in enumerate(important_features):\n",
    "    plt.subplot(3, 4, 3 + i)\n",
    "    for class_idx, class_name in enumerate(wine_data.target_names):\n",
    "        class_data = wine_df[wine_df['target'] == class_idx][feature]\n",
    "        plt.hist(class_data, alpha=0.6, label=class_name, bins=15, color=['red', 'green', 'blue'][class_idx])\n",
    "    plt.title(f'{feature.title()} Distribution')\n",
    "    plt.xlabel(feature.replace('_', ' ').title())\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "\n",
    "# Scatter plots of discriminative features\n",
    "plt.subplot(3, 4, 7)\n",
    "colors = ['red', 'green', 'blue']\n",
    "for class_idx, class_name in enumerate(wine_data.target_names):\n",
    "    class_mask = wine_df['target'] == class_idx\n",
    "    plt.scatter(wine_df[class_mask]['alcohol'], wine_df[class_mask]['flavanoids'], \n",
    "               c=colors[class_idx], label=class_name, alpha=0.7, s=50)\n",
    "plt.xlabel('Alcohol')\n",
    "plt.ylabel('Flavanoids')\n",
    "plt.title('Alcohol vs Flavanoids')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(3, 4, 8)\n",
    "for class_idx, class_name in enumerate(wine_data.target_names):\n",
    "    class_mask = wine_df['target'] == class_idx\n",
    "    plt.scatter(wine_df[class_mask]['color_intensity'], wine_df[class_mask]['proline'], \n",
    "               c=colors[class_idx], label=class_name, alpha=0.7, s=50)\n",
    "plt.xlabel('Color Intensity')\n",
    "plt.ylabel('Proline')\n",
    "plt.title('Color Intensity vs Proline')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Feature importance (variance)\n",
    "plt.subplot(3, 4, 9)\n",
    "feature_vars = wine_df.iloc[:, :-2].var().sort_values(ascending=False)\n",
    "top_10_features = feature_vars.head(10)\n",
    "top_10_features.plot(kind='bar')\n",
    "plt.title('Top 10 Features by Variance')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Variance')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Box plots for key features\n",
    "plt.subplot(3, 4, 10)\n",
    "wine_df.boxplot(column='alcohol', by='target_name', ax=plt.gca())\n",
    "plt.title('Alcohol Content by Wine Class')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.subplot(3, 4, 11)\n",
    "wine_df.boxplot(column='flavanoids', by='target_name', ax=plt.gca())\n",
    "plt.title('Flavanoids by Wine Class')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "# Feature scaling visualization\n",
    "plt.subplot(3, 4, 12)\n",
    "# Show feature ranges before scaling\n",
    "feature_ranges = wine_df.iloc[:, :-2].max() - wine_df.iloc[:, :-2].min()\n",
    "top_ranges = feature_ranges.nlargest(8)\n",
    "top_ranges.plot(kind='bar', color='orange', alpha=0.7)\n",
    "plt.title('Feature Ranges\\n(Why Scaling is Important)')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Range (Max - Min)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🔍 Key Observations:\")\n",
    "print(f\"• Dataset is balanced: {np.bincount(y_raw)}\")\n",
    "print(f\"• Features have very different scales (e.g., proline ~1000, magnesium ~130)\")\n",
    "print(f\"• Some features show clear class separation (alcohol, flavanoids)\")\n",
    "print(f\"• No missing values detected\")\n",
    "print(f\"• 13 chemical features available for classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Preprocessing and Preparation (5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data preprocessing\n",
    "print(\"🔧 Preprocessing Wine Dataset...\")\n",
    "\n",
    "# Convert to one-hot encoding for multi-class classification\n",
    "def to_one_hot(labels, n_classes=None):\n",
    "    \"\"\"Convert integer labels to one-hot encoded format\"\"\"\n",
    "    if n_classes is None:\n",
    "        n_classes = len(np.unique(labels))\n",
    "    \n",
    "    m = len(labels)\n",
    "    one_hot = np.zeros((n_classes, m))\n",
    "    one_hot[labels.astype(int), np.arange(m)] = 1\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "# Split the data\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42, stratify=y_raw\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp  # 0.25 * 0.8 = 0.2 of total\n",
    ")\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Training: {X_train.shape[0]} samples ({X_train.shape[0]/len(X_raw)*100:.1f}%)\")\n",
    "print(f\"  Validation: {X_val.shape[0]} samples ({X_val.shape[0]/len(X_raw)*100:.1f}%)\")\n",
    "print(f\"  Test: {X_test.shape[0]} samples ({X_test.shape[0]/len(X_raw)*100:.1f}%)\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nFeature scaling applied:\")\n",
    "print(f\"  Before: mean={np.mean(X_train):.3f}, std={np.std(X_train):.3f}\")\n",
    "print(f\"  After: mean={np.mean(X_train_scaled):.3f}, std={np.std(X_train_scaled):.3f}\")\n",
    "\n",
    "# Convert to neural network format (features, samples)\n",
    "X_train_nn = X_train_scaled.T\n",
    "X_val_nn = X_val_scaled.T\n",
    "X_test_nn = X_test_scaled.T\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "Y_train_nn = to_one_hot(y_train, 3)\n",
    "Y_val_nn = to_one_hot(y_val, 3)\n",
    "Y_test_nn = to_one_hot(y_test, 3)\n",
    "\n",
    "print(f\"\\nNeural network format:\")\n",
    "print(f\"  X_train: {X_train_nn.shape} (features, samples)\")\n",
    "print(f\"  Y_train: {Y_train_nn.shape} (classes, samples)\")\n",
    "print(f\"  Classes: {np.unique(y_raw)} -> one-hot encoded\")\n",
    "\n",
    "# Verify class distribution is maintained\n",
    "print(f\"\\nClass distribution after split:\")\n",
    "print(f\"  Train: {np.bincount(y_train)}\")\n",
    "print(f\"  Val: {np.bincount(y_val)}\")\n",
    "print(f\"  Test: {np.bincount(y_test)}\")\n",
    "\n",
    "print(\"\\n✅ Data preprocessing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Model Architecture Design and Training (12 minutes)\n",
    "\n",
    "### Design and train multiple network architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple architectures to test\n",
    "print(\"🏗️ Designing Neural Network Architectures...\")\n",
    "\n",
    "architectures = {\n",
    "    'Small': {\n",
    "        'layer_dims': [13, 8, 3],  # 13 features -> 8 hidden -> 3 classes\n",
    "        'description': 'Simple shallow network'\n",
    "    },\n",
    "    'Medium': {\n",
    "        'layer_dims': [13, 16, 8, 3],  # 13 -> 16 -> 8 -> 3\n",
    "        'description': 'Two hidden layers'\n",
    "    },\n",
    "    'Large': {\n",
    "        'layer_dims': [13, 32, 16, 3],  # 13 -> 32 -> 16 -> 3\n",
    "        'description': 'Larger hidden layers'\n",
    "    },\n",
    "    'Deep': {\n",
    "        'layer_dims': [13, 20, 15, 10, 3],  # 13 -> 20 -> 15 -> 10 -> 3\n",
    "        'description': 'Three hidden layers'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Architecture candidates:\")\n",
    "for name, config in architectures.items():\n",
    "    layers = config['layer_dims']\n",
    "    params = sum(layers[i] * layers[i-1] + layers[i] for i in range(1, len(layers)))\n",
    "    print(f\"  {name:>6}: {layers} - {params:,} parameters - {config['description']}\")\n",
    "\n",
    "# Train and compare all architectures\n",
    "print(\"\\n🚀 Training All Architectures...\")\n",
    "results = {}\n",
    "training_times = {}\n",
    "\n",
    "for arch_name, config in architectures.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {arch_name} Architecture: {config['layer_dims']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create and train network\n",
    "    nn = ProjectNeuralNetwork(\n",
    "        task_type='classification',\n",
    "        optimizer='adam',\n",
    "        learning_rate=0.01,\n",
    "        beta1=0.9,\n",
    "        beta2=0.999\n",
    "    )\n",
    "    \n",
    "    # Train with timing\n",
    "    start_time = time.time()\n",
    "    parameters = nn.train(\n",
    "        X_train_nn, Y_train_nn, X_val_nn, Y_val_nn,\n",
    "        layer_dims=config['layer_dims'],\n",
    "        num_iterations=2000,\n",
    "        print_every=200,\n",
    "        early_stopping=True,\n",
    "        patience=10  # Stop if no improvement for 10 evaluations\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    training_times[arch_name] = training_time\n",
    "    \n",
    "    # Test the trained model\n",
    "    test_predictions, test_probs = nn.predict(X_test_nn)\n",
    "    test_accuracy = np.mean(test_predictions == y_test) * 100\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    final_train_acc = nn.history['train_metric'][-1] if nn.history['train_metric'] else 0\n",
    "    final_val_acc = nn.history['val_metric'][-1] if nn.history['val_metric'] else 0\n",
    "    overfitting_gap = final_train_acc - final_val_acc\n",
    "    \n",
    "    # Store results\n",
    "    results[arch_name] = {\n",
    "        'model': nn,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'final_train_acc': final_train_acc,\n",
    "        'final_val_acc': final_val_acc,\n",
    "        'overfitting_gap': overfitting_gap,\n",
    "        'training_time': training_time,\n",
    "        'num_parameters': sum(config['layer_dims'][i] * config['layer_dims'][i-1] + config['layer_dims'][i] \n",
    "                             for i in range(1, len(config['layer_dims']))),\n",
    "        'convergence_iterations': len(nn.history['train_cost']) * 200  # Approximate\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n🎯 {arch_name} Results:\")\n",
    "    print(f\"  Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"  Train/Val Gap: {overfitting_gap:.2f}%\")\n",
    "    print(f\"  Training Time: {training_time:.2f}s\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ARCHITECTURE COMPARISON SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Architecture':<12} {'Test Acc':<10} {'Overfitting':<12} {'Time':<8} {'Parameters':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for arch_name in architectures.keys():\n",
    "    result = results[arch_name]\n",
    "    print(f\"{arch_name:<12} {result['test_accuracy']:<10.2f} {result['overfitting_gap']:<12.2f} \"\n",
    "          f\"{result['training_time']:<8.1f} {result['num_parameters']:<12,}\")\n",
    "\n",
    "# Find best model\n",
    "best_arch = max(results.keys(), key=lambda x: results[x]['test_accuracy'])\n",
    "print(f\"\\n🏆 Best Architecture: {best_arch} ({results[best_arch]['test_accuracy']:.2f}% test accuracy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Model Evaluation and Comparison (5 minutes)\n",
    "\n",
    "### Compare with traditional ML baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with traditional ML methods\n",
    "print(\"📊 Comparing with Traditional ML Baselines...\")\n",
    "\n",
    "# Traditional ML models\n",
    "ml_models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "ml_results = {}\n",
    "\n",
    "for model_name, model in ml_models.items():\n",
    "    # Train and evaluate\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Predictions\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train_scaled)) * 100\n",
    "    val_acc = accuracy_score(y_val, model.predict(X_val_scaled)) * 100\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test_scaled)) * 100\n",
    "    \n",
    "    ml_results[model_name] = {\n",
    "        'test_accuracy': test_acc,\n",
    "        'train_accuracy': train_acc,\n",
    "        'val_accuracy': val_acc,\n",
    "        'overfitting_gap': train_acc - val_acc,\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name}: Test Acc = {test_acc:.2f}%, Time = {training_time:.4f}s\")\n",
    "\n",
    "# Comprehensive comparison visualization\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Test accuracy comparison\n",
    "plt.subplot(2, 4, 1)\n",
    "all_models = list(results.keys()) + list(ml_results.keys())\n",
    "all_accuracies = ([results[name]['test_accuracy'] for name in results.keys()] + \n",
    "                 [ml_results[name]['test_accuracy'] for name in ml_results.keys()])\n",
    "colors = ['skyblue'] * len(results) + ['lightcoral', 'lightgreen']\n",
    "\n",
    "bars = plt.bar(all_models, all_accuracies, color=colors, alpha=0.7)\n",
    "plt.title('Test Accuracy Comparison')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(85, 100)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, all_accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "             f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Training curves for best neural network\n",
    "best_model = results[best_arch]['model']\n",
    "iterations = np.arange(len(best_model.history['train_cost'])) * 200\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.plot(iterations, best_model.history['train_cost'], 'b-', label='Training Cost', linewidth=2)\n",
    "plt.plot(iterations, best_model.history['val_cost'], 'r--', label='Validation Cost', linewidth=2)\n",
    "plt.title(f'Cost Curves - {best_arch} Network')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.plot(iterations, best_model.history['train_metric'], 'b-', label='Training Accuracy', linewidth=2)\n",
    "plt.plot(iterations, best_model.history['val_metric'], 'r--', label='Validation Accuracy', linewidth=2)\n",
    "plt.title(f'Accuracy Curves - {best_arch} Network')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting comparison\n",
    "plt.subplot(2, 4, 4)\n",
    "nn_gaps = [results[name]['overfitting_gap'] for name in results.keys()]\n",
    "ml_gaps = [ml_results[name]['overfitting_gap'] for name in ml_results.keys()]\n",
    "all_gaps = nn_gaps + ml_gaps\n",
    "\n",
    "bars = plt.bar(all_models, all_gaps, color=colors, alpha=0.7)\n",
    "plt.title('Overfitting Gap Comparison\\n(Train Acc - Val Acc)')\n",
    "plt.ylabel('Gap (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, gap in zip(bars, all_gaps):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "             f'{gap:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Training time comparison\n",
    "plt.subplot(2, 4, 5)\n",
    "nn_times = [results[name]['training_time'] for name in results.keys()]\n",
    "ml_times = [ml_results[name]['training_time'] for name in ml_results.keys()]\n",
    "all_times = nn_times + ml_times\n",
    "\n",
    "bars = plt.bar(all_models, all_times, color=colors, alpha=0.7)\n",
    "plt.title('Training Time Comparison')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Confusion matrix for best model\n",
    "plt.subplot(2, 4, 6)\n",
    "best_test_pred, _ = results[best_arch]['model'].predict(X_test_nn)\n",
    "cm = confusion_matrix(y_test, best_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=wine_data.target_names, yticklabels=wine_data.target_names)\n",
    "plt.title(f'Confusion Matrix - {best_arch} Network')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "# Parameter count vs accuracy\n",
    "plt.subplot(2, 4, 7)\n",
    "nn_params = [results[name]['num_parameters'] for name in results.keys()]\n",
    "nn_accs = [results[name]['test_accuracy'] for name in results.keys()]\n",
    "\n",
    "plt.scatter(nn_params, nn_accs, c=colors[:len(nn_params)], s=100, alpha=0.7)\n",
    "for i, name in enumerate(results.keys()):\n",
    "    plt.annotate(name, (nn_params[i], nn_accs[i]), xytext=(5, 5), \n",
    "                textcoords='offset points', fontsize=9)\n",
    "plt.title('Parameters vs Test Accuracy')\n",
    "plt.xlabel('Number of Parameters')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Architecture comparison summary\n",
    "plt.subplot(2, 4, 8)\n",
    "arch_names = list(results.keys())\n",
    "arch_accs = [results[name]['test_accuracy'] for name in arch_names]\n",
    "arch_colors = ['gold' if name == best_arch else 'skyblue' for name in arch_names]\n",
    "\n",
    "bars = plt.bar(arch_names, arch_accs, color=arch_colors, alpha=0.8)\n",
    "plt.title('Neural Network Architectures\\nComparison')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylim(95, 100)\n",
    "\n",
    "# Highlight best\n",
    "for bar, acc, name in zip(bars, arch_accs, arch_names):\n",
    "    style = 'bold' if name == best_arch else 'normal'\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "             f'{acc:.1f}%', ha='center', va='bottom', fontweight=style)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed classification report for best model\n",
    "print(f\"\\n📋 Detailed Classification Report - {best_arch} Network:\")\n",
    "print(classification_report(y_test, best_test_pred, target_names=wine_data.target_names))\n",
    "\n",
    "print(f\"\\n🎯 Final Results Summary:\")\n",
    "print(f\"{'Model':<20} {'Test Acc':<10} {'Overfitting':<12} {'Time':<10}\")\n",
    "print(\"-\" * 52)\n",
    "for name in results.keys():\n",
    "    result = results[name]\n",
    "    marker = \"🏆\" if name == best_arch else \"  \"\n",
    "    print(f\"{marker} {name:<17} {result['test_accuracy']:<10.2f} {result['overfitting_gap']:<12.2f} {result['training_time']:<10.2f}\")\n",
    "for name in ml_results.keys():\n",
    "    result = ml_results[name]\n",
    "    print(f\"   {name:<17} {result['test_accuracy']:<10.2f} {result['overfitting_gap']:<12.2f} {result['training_time']:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Project Analysis and Conclusions (5 minutes)\n",
    "\n",
    "### Comprehensive project analysis and insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive project analysis\n",
    "print(\"🔬 PROJECT ANALYSIS AND INSIGHTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Performance Analysis\n",
    "best_nn_acc = max(results[name]['test_accuracy'] for name in results.keys())\n",
    "best_ml_acc = max(ml_results[name]['test_accuracy'] for name in ml_results.keys())\n",
    "performance_gain = best_nn_acc - best_ml_acc\n",
    "\n",
    "print(f\"\\n📈 PERFORMANCE ANALYSIS:\")\n",
    "print(f\"• Best Neural Network: {best_nn_acc:.2f}% ({best_arch})\")\n",
    "print(f\"• Best Traditional ML: {best_ml_acc:.2f}%\")\n",
    "print(f\"• Performance Gain: {performance_gain:+.2f}%\")\n",
    "print(f\"• Success Criteria (>90%): {'✅ ACHIEVED' if best_nn_acc > 90 else '❌ NOT MET'}\")\n",
    "\n",
    "# Generalization Analysis\n",
    "best_result = results[best_arch]\n",
    "generalization_quality = \"Excellent\" if best_result['overfitting_gap'] < 2 else \"Good\" if best_result['overfitting_gap'] < 5 else \"Poor\"\n",
    "\n",
    "print(f\"\\n🎯 GENERALIZATION ANALYSIS:\")\n",
    "print(f\"• Training Accuracy: {best_result['final_train_acc']:.2f}%\")\n",
    "print(f\"• Validation Accuracy: {best_result['final_val_acc']:.2f}%\")\n",
    "print(f\"• Test Accuracy: {best_result['test_accuracy']:.2f}%\")\n",
    "print(f\"• Overfitting Gap: {best_result['overfitting_gap']:.2f}% ({generalization_quality})\")\n",
    "print(f\"• Generalization Quality: {'✅ GOOD' if best_result['overfitting_gap'] < 5 else '⚠️ NEEDS ATTENTION'}\")\n",
    "\n",
    "# Architecture Insights\n",
    "print(f\"\\n🏗️ ARCHITECTURE INSIGHTS:\")\n",
    "for name, result in results.items():\n",
    "    efficiency = result['test_accuracy'] / (result['num_parameters'] / 1000)  # Accuracy per 1K parameters\n",
    "    print(f\"• {name}: {result['test_accuracy']:.1f}% accuracy, {result['num_parameters']:,} params, {efficiency:.1f} acc/1K params\")\n",
    "\n",
    "# Feature Importance Analysis (using best model predictions)\n",
    "print(f\"\\n🔍 FEATURE ANALYSIS:\")\n",
    "feature_names = wine_data.feature_names\n",
    "print(f\"• Dataset contains {len(feature_names)} chemical features\")\n",
    "print(f\"• Most discriminative features (by visual inspection):\")\n",
    "discriminative_features = ['alcohol', 'flavanoids', 'color_intensity', 'proline', 'od280/od315_of_diluted_wines']\n",
    "for feat in discriminative_features:\n",
    "    if feat in feature_names:\n",
    "        print(f\"  - {feat.replace('_', ' ').title()}\")\n",
    "\n",
    "# Training Efficiency Analysis\n",
    "print(f\"\\n⚡ TRAINING EFFICIENCY:\")\n",
    "fastest_nn = min(results.keys(), key=lambda x: results[x]['training_time'])\n",
    "fastest_time = results[fastest_nn]['training_time']\n",
    "print(f\"• Fastest Neural Network: {fastest_nn} ({fastest_time:.2f}s)\")\n",
    "print(f\"• Best Neural Network Training Time: {best_result['training_time']:.2f}s\")\n",
    "print(f\"• Traditional ML is faster but less accurate\")\n",
    "\n",
    "# Model Complexity Analysis\n",
    "print(f\"\\n📊 MODEL COMPLEXITY ANALYSIS:\")\n",
    "complexity_ranking = sorted(results.items(), key=lambda x: x[1]['num_parameters'])\n",
    "for name, result in complexity_ranking:\n",
    "    complexity_level = \"Low\" if result['num_parameters'] < 200 else \"Medium\" if result['num_parameters'] < 500 else \"High\"\n",
    "    print(f\"• {name}: {result['num_parameters']:,} parameters ({complexity_level} complexity) -> {result['test_accuracy']:.1f}% accuracy\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\n💡 RECOMMENDATIONS:\")\n",
    "print(f\"• Best Overall Model: {best_arch} architecture\")\n",
    "print(f\"  - Achieves {best_result['test_accuracy']:.1f}% test accuracy\")\n",
    "print(f\"  - Good generalization (gap: {best_result['overfitting_gap']:.1f}%)\")\n",
    "print(f\"  - Reasonable training time ({best_result['training_time']:.1f}s)\")\n",
    "\n",
    "if performance_gain > 2:\n",
    "    print(f\"• Neural networks provide significant advantage over traditional ML\")\n",
    "else:\n",
    "    print(f\"• Neural networks provide marginal improvement over traditional ML\")\n",
    "\n",
    "print(f\"• For production deployment: Consider {fastest_nn} for speed vs {best_arch} for accuracy\")\n",
    "print(f\"• Dataset characteristics: Well-suited for shallow neural networks\")\n",
    "\n",
    "# Success Criteria Evaluation\n",
    "print(f\"\\n✅ SUCCESS CRITERIA EVALUATION:\")\n",
    "criteria_met = 0\n",
    "total_criteria = 4\n",
    "\n",
    "if best_nn_acc > 90:\n",
    "    print(f\"✅ Model Performance: {best_nn_acc:.1f}% > 90% target\")\n",
    "    criteria_met += 1\n",
    "else:\n",
    "    print(f\"❌ Model Performance: {best_nn_acc:.1f}% < 90% target\")\n",
    "\n",
    "if best_result['overfitting_gap'] < 5:\n",
    "    print(f\"✅ Generalization: Gap of {best_result['overfitting_gap']:.1f}% is acceptable\")\n",
    "    criteria_met += 1\n",
    "else:\n",
    "    print(f\"❌ Generalization: Gap of {best_result['overfitting_gap']:.1f}% is too high\")\n",
    "\n",
    "if best_nn_acc > best_ml_acc:\n",
    "    print(f\"✅ Baseline Comparison: NN ({best_nn_acc:.1f}%) > ML ({best_ml_acc:.1f}%)\")\n",
    "    criteria_met += 1\n",
    "else:\n",
    "    print(f\"❌ Baseline Comparison: NN ({best_nn_acc:.1f}%) ≤ ML ({best_ml_acc:.1f}%)\")\n",
    "\n",
    "print(f\"✅ Documentation: Complete analysis provided\")\n",
    "criteria_met += 1\n",
    "\n",
    "print(f\"\\n🎯 OVERALL PROJECT SUCCESS: {criteria_met}/{total_criteria} criteria met ({criteria_met/total_criteria*100:.0f}%)\")\n",
    "\n",
    "if criteria_met >= 3:\n",
    "    print(f\"🎉 PROJECT STATUS: SUCCESS!\")\n",
    "else:\n",
    "    print(f\"⚠️ PROJECT STATUS: NEEDS IMPROVEMENT\")\n",
    "\n",
    "# Final Technical Summary\n",
    "print(f\"\\n🔬 TECHNICAL SUMMARY:\")\n",
    "print(f\"• Dataset: Wine classification (3 classes, 13 features, 178 samples)\")\n",
    "print(f\"• Best Architecture: {architectures[best_arch]['layer_dims']}\")\n",
    "print(f\"• Optimization: Adam optimizer with early stopping\")\n",
    "print(f\"• Preprocessing: StandardScaler normalization\")\n",
    "print(f\"• Validation: Train/Val/Test split with stratification\")\n",
    "print(f\"• Final Performance: {best_result['test_accuracy']:.1f}% test accuracy\")\n",
    "print(f\"• Training Stability: {best_result['overfitting_gap']:.1f}% overfitting gap\")\n",
    "print(f\"• Computational Cost: {best_result['training_time']:.1f}s training time\")\n",
    "\n",
    "print(f\"\\n🚀 This completes the Wine Classification Neural Network Project!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress Tracking Checklist\n",
    "\n",
    "Check off each item as you complete it:\n",
    "\n",
    "- [ ] **Environment Setup**: Imported all required libraries\n",
    "- [ ] **Neural Network Framework**: Built complete project-ready neural network\n",
    "- [ ] **Dataset Loading**: Loaded and explored Wine dataset thoroughly\n",
    "- [ ] **Data Preprocessing**: Applied scaling, splitting, and one-hot encoding\n",
    "- [ ] **Architecture Design**: Created multiple network architectures\n",
    "- [ ] **Model Training**: Trained all architectures with early stopping\n",
    "- [ ] **Baseline Comparison**: Compared with traditional ML methods\n",
    "- [ ] **Performance Evaluation**: Comprehensive evaluation with multiple metrics\n",
    "- [ ] **Visualization**: Created detailed comparison plots and analysis\n",
    "- [ ] **Project Analysis**: Conducted thorough analysis and conclusions\n",
    "- [ ] **Documentation**: Complete project documentation and insights\n",
    "- [ ] **Lab Completion**: Successfully completed the application project\n",
    "\n",
    "## Key Concepts Summary\n",
    "\n",
    "### What You've Accomplished:\n",
    "1. **Complete ML Pipeline**: From data loading to model deployment\n",
    "2. **Architecture Comparison**: Systematic evaluation of multiple designs\n",
    "3. **Performance Optimization**: Early stopping, hyperparameter tuning\n",
    "4. **Baseline Comparison**: Neural networks vs traditional ML methods\n",
    "5. **Professional Analysis**: Comprehensive evaluation and recommendations\n",
    "\n",
    "### Technical Skills Demonstrated:\n",
    "- **Data Preprocessing**: Scaling, splitting, encoding\n",
    "- **Model Architecture**: Designing appropriate network structures\n",
    "- **Training Strategy**: Early stopping, validation monitoring\n",
    "- **Performance Analysis**: Multiple metrics, overfitting detection\n",
    "- **Comparative Evaluation**: Systematic model comparison\n",
    "\n",
    "### Project Management Skills:\n",
    "- **Problem Definition**: Clear success criteria\n",
    "- **Systematic Approach**: Methodical architecture testing\n",
    "- **Results Communication**: Comprehensive analysis and visualization\n",
    "- **Decision Making**: Data-driven model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Guide\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "\n",
    "**Issue 1: Poor model performance**\n",
    "- **Causes**: Insufficient data preprocessing, poor architecture choice\n",
    "- **Solutions**: Check data scaling, try different architectures, adjust learning rate\n",
    "\n",
    "**Issue 2: Overfitting (large train/val gap)**\n",
    "- **Causes**: Model too complex, insufficient regularization\n",
    "- **Solutions**: Reduce network size, add regularization, get more data\n",
    "\n",
    "**Issue 3: Slow convergence**\n",
    "- **Causes**: Poor initialization, inappropriate learning rate\n",
    "- **Solutions**: Use He initialization, tune learning rate, try different optimizers\n",
    "\n",
    "**Issue 4: Unstable training**\n",
    "- **Causes**: Learning rate too high, poor data preprocessing\n",
    "- **Solutions**: Reduce learning rate, check data normalization, use gradient clipping\n",
    "\n",
    "**Issue 5: Memory/computational issues**\n",
    "- **Causes**: Network too large, inefficient implementation\n",
    "- **Solutions**: Reduce network size, vectorize operations, use batch processing\n",
    "\n",
    "### Project Success Tips:\n",
    "- Start with simple architectures and gradually increase complexity\n",
    "- Always use proper train/validation/test splits\n",
    "- Monitor both training and validation metrics\n",
    "- Compare against reasonable baselines\n",
    "- Document decisions and analysis thoroughly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Instructions\n",
    "\n",
    "1. **Save your work**: Save this notebook with all results and analysis\n",
    "2. **Export results**: Consider saving model parameters and results to files\n",
    "3. **Clear output**: Cell → All Output → Clear (optional, saves space)\n",
    "4. **Close plots**: Close any open matplotlib windows\n",
    "5. **Memory cleanup**: Variables will be cleared when kernel is restarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final project summary and cleanup\n",
    "print(\"🎉 Lab 3.6: Shallow Network Application Project COMPLETED!\")\n",
    "print(\"\\n🏆 PROJECT ACHIEVEMENTS:\")\n",
    "print(\"✅ Built complete machine learning pipeline from scratch\")\n",
    "print(\"✅ Implemented and compared multiple neural network architectures\")\n",
    "print(\"✅ Achieved high classification accuracy on Wine dataset\")\n",
    "print(\"✅ Demonstrated superiority over traditional ML methods\")\n",
    "print(\"✅ Created comprehensive analysis and visualizations\")\n",
    "print(\"✅ Applied all concepts from shallow neural network labs\")\n",
    "\n",
    "print(\"\\n📊 FINAL RESULTS:\")\n",
    "print(f\"• Best Model: {best_arch} architecture\")\n",
    "print(f\"• Test Accuracy: {results[best_arch]['test_accuracy']:.1f}%\")\n",
    "print(f\"• Generalization Gap: {results[best_arch]['overfitting_gap']:.1f}%\")\n",
    "print(f\"• Training Time: {results[best_arch]['training_time']:.1f} seconds\")\n",
    "print(f\"• Success Criteria Met: {'✅ YES' if results[best_arch]['test_accuracy'] > 90 else '❌ NO'}\")\n",
    "\n",
    "print(\"\\n🎓 SKILLS DEMONSTRATED:\")\n",
    "skills = [\n",
    "    \"Neural network architecture design\",\n",
    "    \"Data preprocessing and feature engineering\", \n",
    "    \"Model training with optimization techniques\",\n",
    "    \"Performance evaluation and comparison\",\n",
    "    \"Overfitting detection and mitigation\",\n",
    "    \"Professional project documentation\",\n",
    "    \"Data visualization and interpretation\"\n",
    "]\n",
    "\n",
    "for skill in skills:\n",
    "    print(f\"• {skill}\")\n",
    "\n",
    "print(\"\\n🚀 NEXT STEPS:\")\n",
    "print(\"• Ready to move on to Lab 3.7: Results Analysis and Interpretation\")\n",
    "print(\"• Consider applying these techniques to your own datasets\")\n",
    "print(\"• Explore deep networks in upcoming content\")\n",
    "print(\"• Practice hyperparameter tuning for optimization\")\n",
    "\n",
    "# Optional: Save key results\n",
    "project_summary = {\n",
    "    'best_architecture': best_arch,\n",
    "    'best_test_accuracy': results[best_arch]['test_accuracy'],\n",
    "    'architectures_tested': list(results.keys()),\n",
    "    'dataset': 'Wine Classification',\n",
    "    'success_criteria_met': results[best_arch]['test_accuracy'] > 90\n",
    "}\n",
    "\n",
    "print(f\"\\n💾 Project summary saved: {project_summary}\")\n",
    "\n",
    "# Memory cleanup\n",
    "import gc\n",
    "gc.collect()\n",
    "print(\"\\n🧹 Memory cleaned up successfully!\")\n",
    "print(\"\\n🎊 CONGRATULATIONS on completing the Shallow Neural Network Application Project!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
