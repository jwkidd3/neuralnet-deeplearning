{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.6: Model Deployment and Production - From Lab to Real World\n",
    "\n",
    "## Duration: 45 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lab, you will be able to:\n",
    "- Understand the model deployment pipeline\n",
    "- Save and load models in different formats\n",
    "- Convert models for different deployment targets\n",
    "- Create simple web APIs for model inference\n",
    "- Optimize models for production use\n",
    "- Understand monitoring and maintenance considerations\n",
    "\n",
    "## Prerequisites\n",
    "- **Labs 4.1-4.5 completed** (Full TensorFlow journey)\n",
    "- Understanding of neural networks and model training\n",
    "- Basic knowledge of web concepts (helpful but not required)\n",
    "\n",
    "## Key Concepts\n",
    "- **Model Serialization**: Saving trained models for later use\n",
    "- **Model Serving**: Making models available for predictions\n",
    "- **TensorFlow Lite**: Optimized models for mobile and edge devices\n",
    "- **TensorFlow.js**: Running models in web browsers\n",
    "- **Model Optimization**: Making models faster and smaller\n",
    "- **API Design**: Creating interfaces for model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Introduction\n",
    "\n",
    "Let's start by understanding the journey from training to production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab 4.6: Model Deployment and Production\n",
      "==================================================\n",
      "TensorFlow version: 2.20.0\n",
      "\n",
      "🏗️  The ML Pipeline:\n",
      "  1. 📊 Data Collection & Preparation\n",
      "  2. 🧠 Model Training & Validation (Labs 4.1-4.5)\n",
      "  3. 🚀 Model Deployment & Serving ← WE ARE HERE!\n",
      "  4. 📈 Monitoring & Maintenance\n",
      "\n",
      "🎯 Today's Mission:\n",
      "  • Take our trained models to production\n",
      "  • Make them available for real users\n",
      "  • Optimize for speed and efficiency\n",
      "  • Handle real-world challenges\n",
      "\n",
      "🔧 Deployment Options We'll Explore:\n",
      "  1. 💾 Model Saving & Loading (the basics)\n",
      "  2. 🌐 Web API for predictions\n",
      "  3. 📱 Mobile deployment with TensorFlow Lite\n",
      "  4. 🌏 Browser deployment with TensorFlow.js\n",
      "  5. ⚡ Model optimization techniques\n",
      "\n",
      "Available compute devices:\n",
      "  • CPU: /physical_device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Lab 4.6: Model Deployment and Production\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "print(\"\\n🏗️  The ML Pipeline:\")\n",
    "print(\"  1. 📊 Data Collection & Preparation\")\n",
    "print(\"  2. 🧠 Model Training & Validation (Labs 4.1-4.5)\")\n",
    "print(\"  3. 🚀 Model Deployment & Serving ← WE ARE HERE!\")\n",
    "print(\"  4. 📈 Monitoring & Maintenance\")\n",
    "\n",
    "print(\"\\n🎯 Today's Mission:\")\n",
    "print(\"  • Take our trained models to production\")\n",
    "print(\"  • Make them available for real users\")\n",
    "print(\"  • Optimize for speed and efficiency\")\n",
    "print(\"  • Handle real-world challenges\")\n",
    "\n",
    "print(\"\\n🔧 Deployment Options We'll Explore:\")\n",
    "print(\"  1. 💾 Model Saving & Loading (the basics)\")\n",
    "print(\"  2. 🌐 Web API for predictions\")\n",
    "print(\"  3. 📱 Mobile deployment with TensorFlow Lite\")\n",
    "print(\"  4. 🌏 Browser deployment with TensorFlow.js\")\n",
    "print(\"  5. ⚡ Model optimization techniques\")\n",
    "\n",
    "# Check available devices\n",
    "print(f\"\\nAvailable compute devices:\")\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "for device in physical_devices:\n",
    "    print(f\"  • {device.device_type}: {device.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Model Creation and Training - The Foundation\n",
    "\n",
    "First, let's create a model and train it for deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model for deployment...\n",
      "Model parameters: 121,930\n",
      "\n",
      "Training model for deployment (3 epochs)...\n",
      "Epoch 1/3\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7714 - loss: 0.7834 - val_accuracy: 0.8890 - val_loss: 0.3503\n",
      "Epoch 2/3\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9431 - loss: 0.1981 - val_accuracy: 0.9410 - val_loss: 0.1776\n",
      "Epoch 3/3\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9612 - loss: 0.1315 - val_accuracy: 0.9580 - val_loss: 0.1343\n",
      "\n",
      "Model ready for deployment! Accuracy: 0.9660\n"
     ]
    }
   ],
   "source": [
    "# Create and train a simple model for deployment\n",
    "print(\"Creating a model for deployment...\")\n",
    "\n",
    "# Load MNIST for quick training\n",
    "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = keras.datasets.mnist.load_data()\n",
    "X_train_mnist = X_train_mnist.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test_mnist = X_test_mnist.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Build a CNN for digit classification\n",
    "deployment_model = keras.Sequential([\n",
    "    layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "], name='DigitClassifier')\n",
    "\n",
    "deployment_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {deployment_model.count_params():,}\")\n",
    "\n",
    "# Quick training\n",
    "print(\"\\nTraining model for deployment (3 epochs)...\")\n",
    "deployment_model.fit(\n",
    "    X_train_mnist[:10000], y_train_mnist[:10000],\n",
    "    validation_data=(X_test_mnist[:2000], y_test_mnist[:2000]),\n",
    "    epochs=3,\n",
    "    batch_size=128,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_acc = deployment_model.evaluate(X_test_mnist[:1000], y_test_mnist[:1000], verbose=0)\n",
    "print(f\"\\nModel ready for deployment! Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saving Formats for Different Deployments:\n",
      "============================================================\n",
      "\n",
      "1. SavedModel Format (Production Standard):\n",
      "INFO:tensorflow:Assets written to: digit_classifier_savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: digit_classifier_savedmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'digit_classifier_savedmodel'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor_88')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  5320226384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5320223120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5320226576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5320225040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5506402064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5506400528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5506401872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5506401680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to: digit_classifier_savedmodel\n",
      "   • Best for: TensorFlow Serving, Cloud platforms\n",
      "   • Includes: Architecture, weights, training config\n",
      "   • Format: Directory with multiple files\n",
      "   • Contents: ['fingerprint.pb', 'variables', 'saved_model.pb', 'assets']\n",
      "\n",
      "2. Native Keras Format (.keras):\n",
      "✅ Saved to: digit_classifier.keras\n",
      "   • Best for: Keras applications, Python deployment\n",
      "   • Format: Single file with everything included\n",
      "   • Recommended for new projects\n",
      "\n",
      "3. H5 Format (Legacy Keras):\n",
      "✅ Saved to: digit_classifier.h5\n",
      "   • Best for: Legacy systems, backward compatibility\n",
      "   • Format: Single HDF5 file\n",
      "   • Being phased out in favor of .keras format\n",
      "\n",
      "4. Weights Only:\n",
      "✅ Saved to: digit_classifier.weights.h5\n",
      "   • Best for: When you have model architecture separately\n",
      "   • Smaller file size\n",
      "   • Requires model rebuilding\n",
      "   • Note: Filename must end with .weights.h5 in newer Keras\n",
      "\n",
      "📊 File Size Comparison:\n",
      "  SavedModel:     0.06 MB\n",
      "  Keras format:   1.43 MB\n",
      "  H5 format:      1.43 MB\n",
      "  Weights only:   1.43 MB\n",
      "\n",
      "🔄 Testing Model Loading:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded .keras model accuracy: 1.0000\n",
      "❌ Error loading SavedModel: File format not supported: filepath=digit_classifier_savedmodel. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(digit_classifier_savedmodel, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).\n",
      "✅ Loaded H5 model accuracy: 1.0000\n",
      "\n",
      "🔄 Testing Weights-Only Loading:\n",
      "✅ Loaded weights-only model accuracy: 1.0000\n",
      "\n",
      "💡 Format Recommendations:\n",
      "   • Use .keras format for new Keras projects\n",
      "   • Use SavedModel for TensorFlow Serving/production\n",
      "   • Use .h5 only for legacy compatibility\n",
      "   • Use .weights.h5 for custom loading scenarios\n",
      "   • Note: Keras 3+ requires specific file extensions!\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Saving Formats for Different Deployments:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. SavedModel format (TensorFlow Serving, Cloud deployment)\n",
    "print(\"\\n1. SavedModel Format (Production Standard):\")\n",
    "savedmodel_path = 'digit_classifier_savedmodel'\n",
    "deployment_model.export(savedmodel_path)  # Use export() for SavedModel format\n",
    "print(f\"✅ Saved to: {savedmodel_path}\")\n",
    "print(\"   • Best for: TensorFlow Serving, Cloud platforms\")\n",
    "print(\"   • Includes: Architecture, weights, training config\")\n",
    "print(\"   • Format: Directory with multiple files\")\n",
    "\n",
    "# Check what was saved\n",
    "import os\n",
    "if os.path.exists(savedmodel_path):\n",
    "    savedmodel_contents = os.listdir(savedmodel_path)\n",
    "    print(f\"   • Contents: {savedmodel_contents}\")\n",
    "\n",
    "# 2. Native Keras format (New recommended format)\n",
    "print(\"\\n2. Native Keras Format (.keras):\")\n",
    "keras_path = 'digit_classifier.keras'\n",
    "deployment_model.save(keras_path)  # Use .keras extension\n",
    "print(f\"✅ Saved to: {keras_path}\")\n",
    "print(\"   • Best for: Keras applications, Python deployment\")\n",
    "print(\"   • Format: Single file with everything included\")\n",
    "print(\"   • Recommended for new projects\")\n",
    "\n",
    "# 3. H5 format (Traditional Keras format)\n",
    "print(\"\\n3. H5 Format (Legacy Keras):\")\n",
    "h5_path = 'digit_classifier.h5'\n",
    "deployment_model.save(h5_path)  # Use .h5 extension\n",
    "print(f\"✅ Saved to: {h5_path}\")\n",
    "print(\"   • Best for: Legacy systems, backward compatibility\")\n",
    "print(\"   • Format: Single HDF5 file\")\n",
    "print(\"   • Being phased out in favor of .keras format\")\n",
    "\n",
    "# 4. Model weights only (requires specific .weights.h5 extension)\n",
    "print(\"\\n4. Weights Only:\")\n",
    "weights_path = 'digit_classifier.weights.h5'  # Must end with .weights.h5\n",
    "deployment_model.save_weights(weights_path)\n",
    "print(f\"✅ Saved to: {weights_path}\")\n",
    "print(\"   • Best for: When you have model architecture separately\")\n",
    "print(\"   • Smaller file size\")\n",
    "print(\"   • Requires model rebuilding\")\n",
    "print(\"   • Note: Filename must end with .weights.h5 in newer Keras\")\n",
    "\n",
    "# Show file sizes\n",
    "print(\"\\n📊 File Size Comparison:\")\n",
    "def get_size(path):\n",
    "    if os.path.isdir(path):\n",
    "        total_size = sum(os.path.getsize(os.path.join(path, f)) \n",
    "                        for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)))\n",
    "        return total_size / (1024*1024)  # MB\n",
    "    elif os.path.exists(path):\n",
    "        return os.path.getsize(path) / (1024*1024)  # MB\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print(f\"  SavedModel:     {get_size(savedmodel_path):.2f} MB\")\n",
    "print(f\"  Keras format:   {get_size(keras_path):.2f} MB\")\n",
    "print(f\"  H5 format:      {get_size(h5_path):.2f} MB\")\n",
    "print(f\"  Weights only:   {get_size(weights_path):.2f} MB\")\n",
    "\n",
    "# Test loading different formats\n",
    "print(\"\\n🔄 Testing Model Loading:\")\n",
    "\n",
    "# Test loading .keras format (recommended)\n",
    "try:\n",
    "    loaded_keras_model = keras.models.load_model(keras_path)\n",
    "    loaded_keras_acc = loaded_keras_model.evaluate(X_test_mnist[:100], y_test_mnist[:100], verbose=0)[1]\n",
    "    print(f\"✅ Loaded .keras model accuracy: {loaded_keras_acc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading .keras model: {e}\")\n",
    "\n",
    "# Test loading SavedModel format\n",
    "try:\n",
    "    loaded_savedmodel = keras.models.load_model(savedmodel_path)\n",
    "    loaded_savedmodel_acc = loaded_savedmodel.evaluate(X_test_mnist[:100], y_test_mnist[:100], verbose=0)[1]\n",
    "    print(f\"✅ Loaded SavedModel accuracy: {loaded_savedmodel_acc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading SavedModel: {e}\")\n",
    "\n",
    "# Test loading H5 format\n",
    "try:\n",
    "    loaded_h5_model = keras.models.load_model(h5_path)\n",
    "    loaded_h5_acc = loaded_h5_model.evaluate(X_test_mnist[:100], y_test_mnist[:100], verbose=0)[1]\n",
    "    print(f\"✅ Loaded H5 model accuracy: {loaded_h5_acc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading H5 model: {e}\")\n",
    "\n",
    "# Test loading weights (requires model architecture)\n",
    "print(\"\\n🔄 Testing Weights-Only Loading:\")\n",
    "try:\n",
    "    # Create a new model with same architecture\n",
    "    weights_test_model = keras.Sequential([\n",
    "        layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, activation='relu'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ], name='WeightsTestModel')\n",
    "    \n",
    "    # Load the weights\n",
    "    weights_test_model.load_weights(weights_path)\n",
    "    \n",
    "    # Compile (required for evaluation)\n",
    "    weights_test_model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    weights_acc = weights_test_model.evaluate(X_test_mnist[:100], y_test_mnist[:100], verbose=0)[1]\n",
    "    print(f\"✅ Loaded weights-only model accuracy: {weights_acc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading weights: {e}\")\n",
    "\n",
    "print(\"\\n💡 Format Recommendations:\")\n",
    "print(\"   • Use .keras format for new Keras projects\")\n",
    "print(\"   • Use SavedModel for TensorFlow Serving/production\")  \n",
    "print(\"   • Use .h5 only for legacy compatibility\")\n",
    "print(\"   • Use .weights.h5 for custom loading scenarios\")\n",
    "print(\"   • Note: Keras 3+ requires specific file extensions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Model Saving Formats - Choose Your Deployment Target\n",
    "\n",
    "Let's explore different ways to save models for different deployment scenarios:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Optimization for Production\n",
    "\n",
    "Let's optimize our model for faster inference and smaller size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimization Techniques:\n",
      "==================================================\n",
      "\n",
      "1. Post-Training Quantization:\n",
      "INFO:tensorflow:Assets written to: /var/folders/z6/dlcbzdks22nfwdj6w9k468180000gn/T/tmpen0jku3a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/z6/dlcbzdks22nfwdj6w9k468180000gn/T/tmpen0jku3a/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/z6/dlcbzdks22nfwdj6w9k468180000gn/T/tmpen0jku3a'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor_88')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  5320226384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5320223120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5320226576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5320225040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5506402064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5506400528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5506401872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5506401680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1756394125.600814 5607261 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1756394125.600822 5607261 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-08-28 10:15:25.601424: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/z6/dlcbzdks22nfwdj6w9k468180000gn/T/tmpen0jku3a\n",
      "2025-08-28 10:15:25.601652: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-08-28 10:15:25.601656: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/z6/dlcbzdks22nfwdj6w9k468180000gn/T/tmpen0jku3a\n",
      "I0000 00:00:1756394125.603249 5607261 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n",
      "2025-08-28 10:15:25.603493: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-08-28 10:15:25.613558: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/z6/dlcbzdks22nfwdj6w9k468180000gn/T/tmpen0jku3a\n",
      "2025-08-28 10:15:25.618209: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 16787 microseconds.\n",
      "2025-08-28 10:15:25.640442: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Quantized TFLite model saved to: digit_classifier_quantized.tflite\n",
      "   Size: 127.9 KB\n",
      "   Original Keras model: 1465.4 KB\n",
      "   Compression ratio: 11.5x smaller\n",
      "\n",
      "2. Model Pruning (Conceptual):\n",
      "   • Removes weights close to zero\n",
      "   • Can reduce model size by 80-90%\n",
      "   • Requires tensorflow_model_optimization package\n",
      "   • Best done during training (structured pruning)\n",
      "\n",
      "3. Inference Speed Benchmarking:\n",
      "Testing inference speed on different formats...\n",
      "Keras model inference: 15.94 ms per prediction\n",
      "TFLite model inference: 0.03 ms per prediction\n",
      "TFLite speedup: 610.5x faster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy retention: 100.0% (predictions match original)\n",
      "\n",
      "📊 Optimization Summary:\n",
      "   • Quantization reduces model size significantly\n",
      "   • TFLite optimizes for mobile/edge deployment\n",
      "   • Trade-off: Size/Speed vs. Accuracy\n",
      "   • Choose optimization based on deployment target\n",
      "\n",
      "💡 Production Optimization Tips:\n",
      "   1. Profile your model to find bottlenecks\n",
      "   2. Use appropriate precision (FP16, INT8)\n",
      "   3. Batch predictions when possible\n",
      "   4. Consider model distillation for complex models\n",
      "   5. Test optimized models thoroughly\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Optimization Techniques:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Model Quantization - Reduce precision for smaller size and faster inference\n",
    "print(\"\\n1. Post-Training Quantization:\")\n",
    "try:\n",
    "    # Convert to TensorFlow Lite with quantization\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(deployment_model)\n",
    "    \n",
    "    # Enable optimization (quantization)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    \n",
    "    # Convert the model\n",
    "    quantized_tflite_model = converter.convert()\n",
    "    \n",
    "    # Save the quantized model\n",
    "    tflite_path = 'digit_classifier_quantized.tflite'\n",
    "    with open(tflite_path, 'wb') as f:\n",
    "        f.write(quantized_tflite_model)\n",
    "    \n",
    "    print(f\"✅ Quantized TFLite model saved to: {tflite_path}\")\n",
    "    print(f\"   Size: {len(quantized_tflite_model) / 1024:.1f} KB\")\n",
    "    \n",
    "    # Compare with original model size\n",
    "    original_size = get_size(keras_path) * 1024  # Convert MB to KB\n",
    "    compression_ratio = original_size / (len(quantized_tflite_model) / 1024)\n",
    "    print(f\"   Original Keras model: {original_size:.1f} KB\")\n",
    "    print(f\"   Compression ratio: {compression_ratio:.1f}x smaller\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error with quantization: {e}\")\n",
    "\n",
    "# 2. Model Pruning - Remove less important weights\n",
    "print(\"\\n2. Model Pruning (Conceptual):\")\n",
    "print(\"   • Removes weights close to zero\")\n",
    "print(\"   • Can reduce model size by 80-90%\")\n",
    "print(\"   • Requires tensorflow_model_optimization package\")\n",
    "print(\"   • Best done during training (structured pruning)\")\n",
    "\n",
    "# 3. Model Benchmarking - Test inference speed\n",
    "print(\"\\n3. Inference Speed Benchmarking:\")\n",
    "print(\"Testing inference speed on different formats...\")\n",
    "\n",
    "# Benchmark original Keras model\n",
    "import time\n",
    "\n",
    "# Warm up\n",
    "for _ in range(5):\n",
    "    _ = deployment_model.predict(X_test_mnist[:1], verbose=0)\n",
    "\n",
    "# Benchmark Keras model\n",
    "start_time = time.time()\n",
    "iterations = 100\n",
    "for _ in range(iterations):\n",
    "    predictions = deployment_model.predict(X_test_mnist[:1], verbose=0)\n",
    "keras_inference_time = (time.time() - start_time) / iterations * 1000  # ms per prediction\n",
    "\n",
    "print(f\"Keras model inference: {keras_inference_time:.2f} ms per prediction\")\n",
    "\n",
    "# Test TFLite model if available\n",
    "try:\n",
    "    # Load and test TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    # Get input and output tensors\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    # Warm up TFLite\n",
    "    test_input = X_test_mnist[:1].astype(np.float32)\n",
    "    for _ in range(5):\n",
    "        interpreter.set_tensor(input_details[0]['index'], test_input)\n",
    "        interpreter.invoke()\n",
    "    \n",
    "    # Benchmark TFLite\n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        interpreter.set_tensor(input_details[0]['index'], test_input)\n",
    "        interpreter.invoke()\n",
    "        tflite_output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    tflite_inference_time = (time.time() - start_time) / iterations * 1000  # ms per prediction\n",
    "    \n",
    "    print(f\"TFLite model inference: {tflite_inference_time:.2f} ms per prediction\")\n",
    "    \n",
    "    # Speed improvement\n",
    "    speed_improvement = keras_inference_time / tflite_inference_time\n",
    "    print(f\"TFLite speedup: {speed_improvement:.1f}x faster\")\n",
    "    \n",
    "    # Test accuracy of quantized model\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 100\n",
    "    \n",
    "    for i in range(total_predictions):\n",
    "        # Get prediction from original model\n",
    "        original_pred = np.argmax(deployment_model.predict(X_test_mnist[i:i+1], verbose=0)[0])\n",
    "        \n",
    "        # Get prediction from TFLite model\n",
    "        interpreter.set_tensor(input_details[0]['index'], X_test_mnist[i:i+1])\n",
    "        interpreter.invoke()\n",
    "        tflite_pred = np.argmax(interpreter.get_tensor(output_details[0]['index'])[0])\n",
    "        \n",
    "        if original_pred == tflite_pred:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    accuracy_retention = correct_predictions / total_predictions\n",
    "    print(f\"Accuracy retention: {accuracy_retention:.1%} (predictions match original)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ TFLite benchmarking failed: {e}\")\n",
    "\n",
    "print(\"\\n📊 Optimization Summary:\")\n",
    "print(\"   • Quantization reduces model size significantly\")\n",
    "print(\"   • TFLite optimizes for mobile/edge deployment\") \n",
    "print(\"   • Trade-off: Size/Speed vs. Accuracy\")\n",
    "print(\"   • Choose optimization based on deployment target\")\n",
    "\n",
    "print(\"\\n💡 Production Optimization Tips:\")\n",
    "print(\"   1. Profile your model to find bottlenecks\")\n",
    "print(\"   2. Use appropriate precision (FP16, INT8)\")\n",
    "print(\"   3. Batch predictions when possible\")\n",
    "print(\"   4. Consider model distillation for complex models\")\n",
    "print(\"   5. Test optimized models thoroughly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Simple Model Serving API\n",
    "\n",
    "Let's create a simple prediction service that could be deployed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Simple Model Serving Interface:\n",
      "============================================================\n",
      "\n",
      "🚀 Initializing Digit Classifier Service:\n",
      "Loading model from: digit_classifier.keras\n",
      "✅ Model loaded successfully!\n",
      "\n",
      "📋 Model Information:\n",
      "   model_name: DigitClassifier\n",
      "   input_shape: (None, 28, 28, 1)\n",
      "   output_shape: (None, 10)\n",
      "   total_parameters: 121930\n",
      "   classes: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "\n",
      "🧪 Testing the Service:\n",
      "========================================\n",
      "Testing image with actual label: 7\n",
      "\n",
      "📊 Single Prediction Result:\n",
      "   Predicted digit: 7\n",
      "   Confidence: 99.99%\n",
      "   Correct: ✅\n",
      "\n",
      "🔝 Top 3 predictions:\n",
      "   1. Digit 7: 99.99%\n",
      "   2. Digit 3: 0.00%\n",
      "   3. Digit 2: 0.00%\n",
      "\n",
      "📦 Batch Prediction Test:\n",
      "Testing 5 images:\n",
      "   Image 0: Actual=7, Predicted=7, Confidence=99.99% ✅\n",
      "   Image 1: Actual=2, Predicted=2, Confidence=99.36% ✅\n",
      "   Image 2: Actual=1, Predicted=1, Confidence=99.55% ✅\n",
      "   Image 3: Actual=0, Predicted=0, Confidence=99.55% ✅\n",
      "   Image 4: Actual=4, Predicted=4, Confidence=99.96% ✅\n",
      "\n",
      "Batch accuracy: 100.0%\n",
      "\n",
      "🌐 API-Style Request/Response Example:\n",
      "==================================================\n",
      "Sample API Request:\n",
      "POST /predict\n",
      "Content-Type: application/json\n",
      "{\"image\": \"<base64_encoded_image_data>\"}\n",
      "\n",
      "API Response:\n",
      "{\n",
      "  \"status\": \"success\",\n",
      "  \"prediction\": 1,\n",
      "  \"confidence\": 0.9955,\n",
      "  \"processing_time_ms\": 12.5,\n",
      "  \"model_version\": \"1.0.0\"\n",
      "}\n",
      "\n",
      "💡 Production API Considerations:\n",
      "   • Input validation and sanitization\n",
      "   • Error handling and proper HTTP status codes\n",
      "   • Rate limiting and authentication\n",
      "   • Logging and monitoring\n",
      "   • Model versioning and A/B testing\n",
      "   • Caching for frequently requested predictions\n",
      "   • Load balancing for high traffic\n",
      "\n",
      "🔧 Deployment Options:\n",
      "   • FastAPI/Flask for Python web services\n",
      "   • TensorFlow Serving for high-performance serving\n",
      "   • Docker containers for easy deployment\n",
      "   • Kubernetes for orchestration\n",
      "   • Cloud platforms (AWS SageMaker, Google AI Platform)\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating a Simple Model Serving Interface:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a simple prediction service class\n",
    "class DigitClassifierService:\n",
    "    \"\"\"Simple model serving class for digit classification\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        \"\"\"Initialize the service with a trained model\"\"\"\n",
    "        print(f\"Loading model from: {model_path}\")\n",
    "        self.model = keras.models.load_model(model_path)\n",
    "        self.class_names = [str(i) for i in range(10)]  # Digits 0-9\n",
    "        print(\"✅ Model loaded successfully!\")\n",
    "    \n",
    "    def predict_single(self, image):\n",
    "        \"\"\"Predict a single image\"\"\"\n",
    "        # Ensure correct input shape\n",
    "        if len(image.shape) == 2:  # If 2D, add batch and channel dims\n",
    "            image = image.reshape(1, 28, 28, 1)\n",
    "        elif len(image.shape) == 3:  # If 3D, add batch dim\n",
    "            image = image.reshape(1, *image.shape)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(image, verbose=0)\n",
    "        predicted_class = np.argmax(prediction[0])\n",
    "        confidence = float(prediction[0][predicted_class])\n",
    "        \n",
    "        return {\n",
    "            'predicted_digit': int(predicted_class),\n",
    "            'confidence': confidence,\n",
    "            'all_probabilities': {\n",
    "                str(i): float(prediction[0][i]) for i in range(10)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def predict_batch(self, images):\n",
    "        \"\"\"Predict multiple images\"\"\"\n",
    "        predictions = self.model.predict(images, verbose=0)\n",
    "        results = []\n",
    "        \n",
    "        for i, prediction in enumerate(predictions):\n",
    "            predicted_class = np.argmax(prediction)\n",
    "            confidence = float(prediction[predicted_class])\n",
    "            \n",
    "            results.append({\n",
    "                'image_index': i,\n",
    "                'predicted_digit': int(predicted_class),\n",
    "                'confidence': confidence\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Get information about the loaded model\"\"\"\n",
    "        return {\n",
    "            'model_name': self.model.name,\n",
    "            'input_shape': self.model.input_shape,\n",
    "            'output_shape': self.model.output_shape,\n",
    "            'total_parameters': self.model.count_params(),\n",
    "            'classes': self.class_names\n",
    "        }\n",
    "\n",
    "# Initialize the service\n",
    "print(\"\\n🚀 Initializing Digit Classifier Service:\")\n",
    "service = DigitClassifierService(keras_path)\n",
    "\n",
    "# Get model information\n",
    "model_info = service.get_model_info()\n",
    "print(f\"\\n📋 Model Information:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Test the service with sample images\n",
    "print(\"\\n🧪 Testing the Service:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test single prediction\n",
    "test_image = X_test_mnist[0]  # First test image\n",
    "actual_label = y_test_mnist[0]\n",
    "\n",
    "print(f\"Testing image with actual label: {actual_label}\")\n",
    "result = service.predict_single(test_image)\n",
    "\n",
    "print(f\"\\n📊 Single Prediction Result:\")\n",
    "print(f\"   Predicted digit: {result['predicted_digit']}\")\n",
    "print(f\"   Confidence: {result['confidence']:.2%}\")\n",
    "print(f\"   Correct: {'✅' if result['predicted_digit'] == actual_label else '❌'}\")\n",
    "\n",
    "# Show top 3 predictions\n",
    "sorted_probs = sorted(result['all_probabilities'].items(), \n",
    "                     key=lambda x: x[1], reverse=True)\n",
    "print(f\"\\n🔝 Top 3 predictions:\")\n",
    "for i, (digit, prob) in enumerate(sorted_probs[:3]):\n",
    "    print(f\"   {i+1}. Digit {digit}: {prob:.2%}\")\n",
    "\n",
    "# Test batch prediction\n",
    "print(f\"\\n📦 Batch Prediction Test:\")\n",
    "batch_size = 5\n",
    "test_batch = X_test_mnist[:batch_size]\n",
    "actual_labels = y_test_mnist[:batch_size]\n",
    "\n",
    "batch_results = service.predict_batch(test_batch)\n",
    "\n",
    "print(f\"Testing {batch_size} images:\")\n",
    "correct = 0\n",
    "for result in batch_results:\n",
    "    actual = actual_labels[result['image_index']]\n",
    "    predicted = result['predicted_digit']\n",
    "    is_correct = predicted == actual\n",
    "    correct += is_correct\n",
    "    \n",
    "    print(f\"   Image {result['image_index']}: \"\n",
    "          f\"Actual={actual}, Predicted={predicted}, \"\n",
    "          f\"Confidence={result['confidence']:.2%} \"\n",
    "          f\"{'✅' if is_correct else '❌'}\")\n",
    "\n",
    "batch_accuracy = correct / batch_size\n",
    "print(f\"\\nBatch accuracy: {batch_accuracy:.1%}\")\n",
    "\n",
    "# Simulate API-style request/response\n",
    "print(f\"\\n🌐 API-Style Request/Response Example:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def simulate_api_request(image_data):\n",
    "    \"\"\"Simulate an API request\"\"\"\n",
    "    try:\n",
    "        # In a real API, you'd receive image data (e.g., base64 encoded)\n",
    "        # and need to preprocess it\n",
    "        \n",
    "        # Preprocess (normalize, reshape)\n",
    "        processed_image = image_data.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Make prediction\n",
    "        result = service.predict_single(processed_image)\n",
    "        \n",
    "        # Format API response\n",
    "        api_response = {\n",
    "            'status': 'success',\n",
    "            'prediction': result['predicted_digit'],\n",
    "            'confidence': round(result['confidence'], 4),\n",
    "            'processing_time_ms': 12.5,  # Simulated\n",
    "            'model_version': '1.0.0'\n",
    "        }\n",
    "        \n",
    "        return api_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'error_message': str(e),\n",
    "            'error_code': 'PREDICTION_FAILED'\n",
    "        }\n",
    "\n",
    "# Test the API simulation\n",
    "sample_image = (X_test_mnist[2] * 255).astype(np.uint8)  # Convert back to 0-255\n",
    "api_response = simulate_api_request(sample_image)\n",
    "\n",
    "print(\"Sample API Request:\")\n",
    "print(\"POST /predict\")\n",
    "print(\"Content-Type: application/json\")\n",
    "print('{\"image\": \"<base64_encoded_image_data>\"}')\n",
    "\n",
    "print(f\"\\nAPI Response:\")\n",
    "print(json.dumps(api_response, indent=2))\n",
    "\n",
    "print(f\"\\n💡 Production API Considerations:\")\n",
    "print(\"   • Input validation and sanitization\")\n",
    "print(\"   • Error handling and proper HTTP status codes\")  \n",
    "print(\"   • Rate limiting and authentication\")\n",
    "print(\"   • Logging and monitoring\")\n",
    "print(\"   • Model versioning and A/B testing\")\n",
    "print(\"   • Caching for frequently requested predictions\")\n",
    "print(\"   • Load balancing for high traffic\")\n",
    "\n",
    "print(f\"\\n🔧 Deployment Options:\")\n",
    "print(\"   • FastAPI/Flask for Python web services\")\n",
    "print(\"   • TensorFlow Serving for high-performance serving\")\n",
    "print(\"   • Docker containers for easy deployment\")\n",
    "print(\"   • Kubernetes for orchestration\")\n",
    "print(\"   • Cloud platforms (AWS SageMaker, Google AI Platform)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary: From Training to Production\n",
    "\n",
    "Congratulations! You've completed the full journey from model development to production deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎓 Deployment Journey Complete!\n",
      "============================================================\n",
      "\n",
      "📋 Model Formats Mastered:\n",
      "   ✅ Native Keras (.keras) - Recommended for new projects\n",
      "   ✅ SavedModel - Production standard for TF Serving\n",
      "   ✅ H5 Format - Legacy compatibility\n",
      "   ✅ Weights-only (.weights.h5) - Custom scenarios\n",
      "\n",
      "📋 Optimization Techniques:\n",
      "   ✅ Post-training quantization (TensorFlow Lite)\n",
      "   ✅ Model size reduction and compression\n",
      "   ✅ Inference speed benchmarking\n",
      "   ✅ Accuracy vs. performance trade-offs\n",
      "\n",
      "📋 Serving Solutions:\n",
      "   ✅ Model serving class design\n",
      "   ✅ Single and batch prediction APIs\n",
      "   ✅ Error handling and validation\n",
      "   ✅ API response formatting\n",
      "\n",
      "📋 Production Readiness:\n",
      "   ✅ Model loading and initialization\n",
      "   ✅ Performance monitoring\n",
      "   ✅ Service architecture patterns\n",
      "   ✅ Deployment considerations\n",
      "\n",
      "🏗️  Complete ML Pipeline Overview:\n",
      "==================================================\n",
      "   1. Data Collection: Gather and prepare training data\n",
      "   2. Model Development: Design, train, and validate models (Labs 4.1-4.5)\n",
      "   3. Model Optimization: Quantization, pruning, compression\n",
      "   4. Model Deployment: Save, serve, and scale models\n",
      "   5. Monitoring & Maintenance: Track performance, retrain as needed\n",
      "\n",
      "🚀 Next Steps for Production:\n",
      "========================================\n",
      "   🔧 Set up CI/CD pipelines for model updates\n",
      "   📊 Implement comprehensive monitoring and logging\n",
      "   🛡️  Add security measures (authentication, input validation)\n",
      "   ⚡ Optimize for your specific deployment environment\n",
      "   🧪 Set up A/B testing for model versions\n",
      "   📈 Plan for model retraining workflows\n",
      "   🌐 Consider edge deployment for mobile/IoT devices\n",
      "   🔄 Implement automated model validation pipelines\n",
      "\n",
      "📚 Key Takeaways:\n",
      "==============================\n",
      "   1. Model format choice depends on deployment target\n",
      "   2. Optimization is crucial for production performance\n",
      "   3. Always test optimized models thoroughly\n",
      "   4. Plan your serving architecture early\n",
      "   5. Monitor everything in production\n",
      "   6. Automate as much as possible\n",
      "   7. Security and reliability are non-negotiable\n",
      "\n",
      "📊 Your Deep Learning Journey:\n",
      "==================================================\n",
      "   ✅ Lab 4.1: TensorFlow Fundamentals\n",
      "   ✅ Lab 4.2: Deep Network Architecture\n",
      "   ✅ Lab 4.3: Convolutional Networks\n",
      "   ✅ Lab 4.4: Recurrent Networks\n",
      "   ✅ Lab 4.5: Transfer Learning\n",
      "   ✅ Lab 4.6: Model Deployment\n",
      "\n",
      "🏆 Congratulations!\n",
      "You've mastered the complete deep learning pipeline:\n",
      "   • From basic TensorFlow operations to production deployment\n",
      "   • Multiple network architectures (Dense, CNN, RNN)\n",
      "   • Advanced techniques (Transfer Learning, Fine-tuning)\n",
      "   • Production-ready model serving and optimization\n",
      "\n",
      "🎯 You're now ready to:\n",
      "   • Build and deploy real-world ML applications\n",
      "   • Optimize models for production environments\n",
      "   • Design scalable ML serving architectures\n",
      "   • Handle the full ML lifecycle professionally\n",
      "\n",
      "💪 Keep Learning:\n",
      "   • Explore MLOps tools and practices\n",
      "   • Study distributed training techniques\n",
      "   • Learn about model interpretability\n",
      "   • Dive deeper into specific domains (NLP, Computer Vision, etc.)\n",
      "\n",
      "🌟 Well done! Your deep learning journey continues...\n"
     ]
    }
   ],
   "source": [
    "print(\"🎓 Deployment Journey Complete!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Summary of what we've accomplished\n",
    "deployment_summary = {\n",
    "    \"Model Formats Mastered\": [\n",
    "        \"✅ Native Keras (.keras) - Recommended for new projects\",\n",
    "        \"✅ SavedModel - Production standard for TF Serving\",\n",
    "        \"✅ H5 Format - Legacy compatibility\",\n",
    "        \"✅ Weights-only (.weights.h5) - Custom scenarios\"\n",
    "    ],\n",
    "    \"Optimization Techniques\": [\n",
    "        \"✅ Post-training quantization (TensorFlow Lite)\",\n",
    "        \"✅ Model size reduction and compression\",\n",
    "        \"✅ Inference speed benchmarking\",\n",
    "        \"✅ Accuracy vs. performance trade-offs\"\n",
    "    ],\n",
    "    \"Serving Solutions\": [\n",
    "        \"✅ Model serving class design\",\n",
    "        \"✅ Single and batch prediction APIs\",\n",
    "        \"✅ Error handling and validation\",\n",
    "        \"✅ API response formatting\"\n",
    "    ],\n",
    "    \"Production Readiness\": [\n",
    "        \"✅ Model loading and initialization\",\n",
    "        \"✅ Performance monitoring\",\n",
    "        \"✅ Service architecture patterns\",\n",
    "        \"✅ Deployment considerations\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, achievements in deployment_summary.items():\n",
    "    print(f\"\\n📋 {category}:\")\n",
    "    for achievement in achievements:\n",
    "        print(f\"   {achievement}\")\n",
    "\n",
    "print(f\"\\n🏗️  Complete ML Pipeline Overview:\")\n",
    "print(\"=\" * 50)\n",
    "pipeline_stages = [\n",
    "    (\"1. Data Collection\", \"Gather and prepare training data\"),\n",
    "    (\"2. Model Development\", \"Design, train, and validate models (Labs 4.1-4.5)\"),\n",
    "    (\"3. Model Optimization\", \"Quantization, pruning, compression\"),\n",
    "    (\"4. Model Deployment\", \"Save, serve, and scale models\"),\n",
    "    (\"5. Monitoring & Maintenance\", \"Track performance, retrain as needed\")\n",
    "]\n",
    "\n",
    "for stage, description in pipeline_stages:\n",
    "    print(f\"   {stage}: {description}\")\n",
    "\n",
    "print(f\"\\n🚀 Next Steps for Production:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "next_steps = [\n",
    "    \"🔧 Set up CI/CD pipelines for model updates\",\n",
    "    \"📊 Implement comprehensive monitoring and logging\", \n",
    "    \"🛡️  Add security measures (authentication, input validation)\",\n",
    "    \"⚡ Optimize for your specific deployment environment\",\n",
    "    \"🧪 Set up A/B testing for model versions\",\n",
    "    \"📈 Plan for model retraining workflows\",\n",
    "    \"🌐 Consider edge deployment for mobile/IoT devices\",\n",
    "    \"🔄 Implement automated model validation pipelines\"\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(f\"\\n📚 Key Takeaways:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "takeaways = [\n",
    "    \"Model format choice depends on deployment target\",\n",
    "    \"Optimization is crucial for production performance\", \n",
    "    \"Always test optimized models thoroughly\",\n",
    "    \"Plan your serving architecture early\",\n",
    "    \"Monitor everything in production\",\n",
    "    \"Automate as much as possible\",\n",
    "    \"Security and reliability are non-negotiable\"\n",
    "]\n",
    "\n",
    "for i, takeaway in enumerate(takeaways, 1):\n",
    "    print(f\"   {i}. {takeaway}\")\n",
    "\n",
    "# Create a final visualization of the journey\n",
    "print(f\"\\n📊 Your Deep Learning Journey:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "labs_completed = [\n",
    "    (\"Lab 4.1\", \"TensorFlow Fundamentals\", \"✅\"),\n",
    "    (\"Lab 4.2\", \"Deep Network Architecture\", \"✅\"), \n",
    "    (\"Lab 4.3\", \"Convolutional Networks\", \"✅\"),\n",
    "    (\"Lab 4.4\", \"Recurrent Networks\", \"✅\"),\n",
    "    (\"Lab 4.5\", \"Transfer Learning\", \"✅\"),\n",
    "    (\"Lab 4.6\", \"Model Deployment\", \"✅\")\n",
    "]\n",
    "\n",
    "for lab, topic, status in labs_completed:\n",
    "    print(f\"   {status} {lab}: {topic}\")\n",
    "\n",
    "print(f\"\\n🏆 Congratulations!\")\n",
    "print(\"You've mastered the complete deep learning pipeline:\")\n",
    "print(\"   • From basic TensorFlow operations to production deployment\")\n",
    "print(\"   • Multiple network architectures (Dense, CNN, RNN)\")\n",
    "print(\"   • Advanced techniques (Transfer Learning, Fine-tuning)\")\n",
    "print(\"   • Production-ready model serving and optimization\")\n",
    "\n",
    "print(f\"\\n🎯 You're now ready to:\")\n",
    "print(\"   • Build and deploy real-world ML applications\")\n",
    "print(\"   • Optimize models for production environments\") \n",
    "print(\"   • Design scalable ML serving architectures\")\n",
    "print(\"   • Handle the full ML lifecycle professionally\")\n",
    "\n",
    "print(f\"\\n💪 Keep Learning:\")\n",
    "print(\"   • Explore MLOps tools and practices\")\n",
    "print(\"   • Study distributed training techniques\")\n",
    "print(\"   • Learn about model interpretability\")\n",
    "print(\"   • Dive deeper into specific domains (NLP, Computer Vision, etc.)\")\n",
    "\n",
    "print(f\"\\n🌟 Well done! Your deep learning journey continues...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
