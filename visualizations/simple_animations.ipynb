{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎬 Neural Network Visual Animations\n",
    "\n",
    "This notebook provides **beautiful HTML/CSS visual animations** for neural networks:\n",
    "\n",
    "## 🎨 Visual Features:\n",
    "1. **🧠 Network Visualization** - Animated neurons with gradient colors and glowing effects\n",
    "2. **📊 Training Charts** - Real-time loss graphs with SVG visualization  \n",
    "3. **🎯 No Line Art** - Professional gradient backgrounds and smooth animations\n",
    "\n",
    "## 🚀 Animations Included:\n",
    "- **Forward Propagation**: Watch data flow through the network with glowing neurons\n",
    "- **Training Progress**: See loss decrease with animated charts and progress bars\n",
    "- **Interactive**: Step-by-step visualization with clear explanations\n",
    "\n",
    "## ⚡ Key Features:\n",
    "- Beautiful gradient backgrounds\n",
    "- Smooth CSS animations and transitions\n",
    "- Real-time value updates\n",
    "- Progress tracking\n",
    "- Professional modern design\n",
    "- Pure Python + HTML/CSS (no external dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 Visual animation setup complete!\n",
      "📱 HTML/CSS animations for neural networks!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "from IPython.display import HTML, display, clear_output\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "print(\"🎬 Visual animation setup complete!\")\n",
    "print(\"📱 HTML/CSS animations for neural networks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Network created successfully!\n"
     ]
    }
   ],
   "source": [
    "class AnimatedNetwork:\n",
    "    def __init__(self):\n",
    "        # Simple 2-3-1 network (using lists instead of numpy)\n",
    "        self.W1 = [[0.5, -0.3], [0.2, 0.7], [-0.4, 0.6]]\n",
    "        self.b1 = [0.1, 0.2, -0.1]\n",
    "        self.W2 = [0.8, -0.5, 0.3]\n",
    "        self.b2 = 0.2\n",
    "        \n",
    "        # Input and target\n",
    "        self.X = [0.8, 0.3]\n",
    "        self.y = 1.0\n",
    "        \n",
    "    def relu(self, z):\n",
    "        if isinstance(z, list):\n",
    "            return [max(0, val) for val in z]\n",
    "        return max(0, z)\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        if isinstance(z, list):\n",
    "            return [1 / (1 + math.exp(-max(-500, min(500, val)))) for val in z]\n",
    "        return 1 / (1 + math.exp(-max(-500, min(500, z))))\n",
    "    \n",
    "    def matrix_multiply(self, matrix, vector):\n",
    "        \"\"\"Simple matrix-vector multiplication\"\"\"\n",
    "        result = []\n",
    "        for i in range(len(matrix)):\n",
    "            sum_val = 0\n",
    "            for j in range(len(vector)):\n",
    "                sum_val += matrix[i][j] * vector[j]\n",
    "            result.append(sum_val)\n",
    "        return result\n",
    "    \n",
    "    def vector_add(self, vec1, vec2):\n",
    "        \"\"\"Add vector to each element or add bias\"\"\"\n",
    "        if isinstance(vec2, list):\n",
    "            return [vec1[i] + vec2[i] for i in range(len(vec1))]\n",
    "        else:\n",
    "            return [val + vec2 for val in vec1]\n",
    "    \n",
    "    def dot_product(self, vec1, vec2):\n",
    "        \"\"\"Calculate dot product\"\"\"\n",
    "        return sum(vec1[i] * vec2[i] for i in range(len(vec1)))\n",
    "    \n",
    "    def forward_step_by_step(self):\n",
    "        \"\"\"Return each step of forward propagation\"\"\"\n",
    "        steps = {}\n",
    "        \n",
    "        # Step 1: Input\n",
    "        steps['input'] = {'values': self.X, 'description': 'Input values'}\n",
    "        \n",
    "        # Step 2: Hidden layer linear\n",
    "        Z1_temp = self.matrix_multiply(self.W1, self.X)\n",
    "        Z1 = self.vector_add(Z1_temp, self.b1)\n",
    "        steps['hidden_linear'] = {'values': Z1, 'description': 'Z¹ = W¹X + b¹'}\n",
    "        \n",
    "        # Step 3: Hidden layer activation\n",
    "        A1 = self.relu(Z1)\n",
    "        steps['hidden_activation'] = {'values': A1, 'description': 'A¹ = ReLU(Z¹)'}\n",
    "        \n",
    "        # Step 4: Output linear\n",
    "        Z2_temp = self.dot_product(self.W2, A1)\n",
    "        Z2 = Z2_temp + self.b2\n",
    "        steps['output_linear'] = {'values': Z2, 'description': 'Z² = W²A¹ + b²'}\n",
    "        \n",
    "        # Step 5: Output activation\n",
    "        A2 = self.sigmoid(Z2)\n",
    "        steps['output_activation'] = {'values': A2, 'description': 'A² = σ(Z²)'}\n",
    "        \n",
    "        # Step 6: Loss\n",
    "        loss = -(self.y * math.log(A2 + 1e-8) + (1 - self.y) * math.log(1 - A2 + 1e-8))\n",
    "        steps['loss'] = {'values': loss, 'description': f'Loss = {loss:.4f}'}\n",
    "        \n",
    "        return steps, A1, A2\n",
    "    \n",
    "    def backward_step_by_step(self, A1, A2):\n",
    "        \"\"\"Return each step of backward propagation\"\"\"\n",
    "        steps = {}\n",
    "        \n",
    "        # Step 1: Output gradient\n",
    "        dA2 = -(self.y / (A2 + 1e-8)) + (1 - self.y) / (1 - A2 + 1e-8)\n",
    "        steps['output_grad'] = {'values': dA2, 'description': 'dL/dA² (output gradient)'}\n",
    "        \n",
    "        # Step 2: Output layer backward\n",
    "        dZ2 = dA2 * A2 * (1 - A2)\n",
    "        steps['output_backward'] = {'values': dZ2, 'description': 'dL/dZ² = dA² × σ\\'(Z²)'}\n",
    "        \n",
    "        # Step 3: Hidden gradient\n",
    "        dA1 = [self.W2[i] * dZ2 for i in range(len(self.W2))]\n",
    "        steps['hidden_grad'] = {'values': dA1, 'description': 'dL/dA¹ = W²ᵀ × dZ²'}\n",
    "        \n",
    "        # Step 4: Hidden layer backward (simplified)\n",
    "        Z1_temp = self.matrix_multiply(self.W1, self.X)\n",
    "        Z1 = self.vector_add(Z1_temp, self.b1)\n",
    "        dZ1 = [dA1[i] if Z1[i] > 0 else 0 for i in range(len(dA1))]\n",
    "        steps['hidden_backward'] = {'values': dZ1, 'description': 'dL/dZ¹ = dA¹ × ReLU\\'(Z¹)'}\n",
    "        \n",
    "        # Step 5: Weight gradients (simplified)\n",
    "        dW2 = [dZ2 * A1[i] for i in range(len(A1))]\n",
    "        dW1 = [[dZ1[i] * self.X[j] for j in range(len(self.X))] for i in range(len(dZ1))]\n",
    "        steps['weight_grads'] = {\n",
    "            'values': {'dW2': dW2, 'dW1': dW1}, \n",
    "            'description': 'Weight gradients computed'\n",
    "        }\n",
    "        \n",
    "        return steps\n",
    "\n",
    "# Create network\n",
    "net = AnimatedNetwork()\n",
    "print(\"🧠 Network created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation 1: Forward Propagation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network_visualization(input_vals, hidden_vals, output_val, \n",
    "                                active_layer=None, step_name=\"\", description=\"\"):\n",
    "    \"\"\"Create an HTML visualization of the neural network\"\"\"\n",
    "    \n",
    "    # Determine colors based on active layer\n",
    "    input_color = \"#4CAF50\" if active_layer == \"input\" else \"#E0E0E0\"\n",
    "    hidden_color = \"#2196F3\" if active_layer == \"hidden\" else \"#E0E0E0\"\n",
    "    output_color = \"#FF9800\" if active_layer == \"output\" else \"#E0E0E0\"\n",
    "    \n",
    "    if active_layer == \"input\":\n",
    "        input_glow = \"0 0 20px #4CAF50\"\n",
    "        hidden_glow = \"none\"\n",
    "        output_glow = \"none\"\n",
    "    elif active_layer == \"hidden\":\n",
    "        input_glow = \"none\"\n",
    "        hidden_glow = \"0 0 20px #2196F3\"\n",
    "        output_glow = \"none\"\n",
    "    elif active_layer == \"output\":\n",
    "        input_glow = \"none\"\n",
    "        hidden_glow = \"none\"\n",
    "        output_glow = \"0 0 20px #FF9800\"\n",
    "    else:\n",
    "        input_glow = hidden_glow = output_glow = \"none\"\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <style>\n",
    "        @keyframes pulse {{\n",
    "            0% {{ transform: scale(1); }}\n",
    "            50% {{ transform: scale(1.1); }}\n",
    "            100% {{ transform: scale(1); }}\n",
    "        }}\n",
    "        \n",
    "        @keyframes flow {{\n",
    "            0% {{ opacity: 0; transform: translateX(0); }}\n",
    "            50% {{ opacity: 1; }}\n",
    "            100% {{ opacity: 0; transform: translateX(100%); }}\n",
    "        }}\n",
    "        \n",
    "        .network-container {{\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            border-radius: 20px;\n",
    "            padding: 40px;\n",
    "            margin: 20px auto;\n",
    "            max-width: 900px;\n",
    "            box-shadow: 0 20px 60px rgba(0,0,0,0.3);\n",
    "        }}\n",
    "        \n",
    "        .network-title {{\n",
    "            color: white;\n",
    "            font-size: 28px;\n",
    "            font-weight: bold;\n",
    "            text-align: center;\n",
    "            margin-bottom: 10px;\n",
    "            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\n",
    "        }}\n",
    "        \n",
    "        .network-subtitle {{\n",
    "            color: rgba(255,255,255,0.9);\n",
    "            font-size: 18px;\n",
    "            text-align: center;\n",
    "            margin-bottom: 30px;\n",
    "        }}\n",
    "        \n",
    "        .network {{\n",
    "            display: flex;\n",
    "            justify-content: space-around;\n",
    "            align-items: center;\n",
    "            height: 400px;\n",
    "            position: relative;\n",
    "        }}\n",
    "        \n",
    "        .layer {{\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            justify-content: center;\n",
    "            align-items: center;\n",
    "            gap: 30px;\n",
    "            z-index: 10;\n",
    "        }}\n",
    "        \n",
    "        .neuron {{\n",
    "            width: 80px;\n",
    "            height: 80px;\n",
    "            border-radius: 50%;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            color: white;\n",
    "            font-weight: bold;\n",
    "            font-size: 14px;\n",
    "            transition: all 0.3s ease;\n",
    "            box-shadow: 0 5px 15px rgba(0,0,0,0.3);\n",
    "            position: relative;\n",
    "            cursor: pointer;\n",
    "        }}\n",
    "        \n",
    "        .neuron:hover {{\n",
    "            transform: scale(1.2);\n",
    "        }}\n",
    "        \n",
    "        .neuron.active {{\n",
    "            animation: pulse 1s infinite;\n",
    "        }}\n",
    "        \n",
    "        .neuron-value {{\n",
    "            position: absolute;\n",
    "            bottom: -25px;\n",
    "            font-size: 12px;\n",
    "            color: white;\n",
    "            background: rgba(0,0,0,0.5);\n",
    "            padding: 2px 8px;\n",
    "            border-radius: 10px;\n",
    "        }}\n",
    "        \n",
    "        .layer-label {{\n",
    "            color: white;\n",
    "            font-weight: bold;\n",
    "            margin-top: 20px;\n",
    "            font-size: 16px;\n",
    "            text-shadow: 1px 1px 2px rgba(0,0,0,0.3);\n",
    "        }}\n",
    "        \n",
    "        .info-panel {{\n",
    "            background: rgba(255,255,255,0.1);\n",
    "            border-radius: 15px;\n",
    "            padding: 20px;\n",
    "            margin-top: 30px;\n",
    "            color: white;\n",
    "        }}\n",
    "        \n",
    "        .info-title {{\n",
    "            font-size: 20px;\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 10px;\n",
    "        }}\n",
    "        \n",
    "        .info-content {{\n",
    "            font-size: 14px;\n",
    "            line-height: 1.6;\n",
    "        }}\n",
    "    </style>\n",
    "    \n",
    "    <div class=\"network-container\">\n",
    "        <div class=\"network-title\">🧠 Neural Network Visualization</div>\n",
    "        <div class=\"network-subtitle\">{step_name}</div>\n",
    "        \n",
    "        <div class=\"network\">\n",
    "            <!-- Input Layer -->\n",
    "            <div class=\"layer\">\n",
    "                <div class=\"neuron {'active' if active_layer == 'input' else ''}\" \n",
    "                     style=\"background: {input_color}; box-shadow: {input_glow};\">\n",
    "                    X₁\n",
    "                    <div class=\"neuron-value\">{input_vals[0]:.3f}</div>\n",
    "                </div>\n",
    "                <div class=\"neuron {'active' if active_layer == 'input' else ''}\"\n",
    "                     style=\"background: {input_color}; box-shadow: {input_glow};\">\n",
    "                    X₂\n",
    "                    <div class=\"neuron-value\">{input_vals[1]:.3f}</div>\n",
    "                </div>\n",
    "                <div class=\"layer-label\">INPUT</div>\n",
    "            </div>\n",
    "            \n",
    "            <!-- Hidden Layer -->\n",
    "            <div class=\"layer\">\n",
    "                <div class=\"neuron {'active' if active_layer == 'hidden' else ''}\"\n",
    "                     style=\"background: {hidden_color}; box-shadow: {hidden_glow};\">\n",
    "                    H₁\n",
    "                    <div class=\"neuron-value\">{hidden_vals[0] if hidden_vals else '?'}</div>\n",
    "                </div>\n",
    "                <div class=\"neuron {'active' if active_layer == 'hidden' else ''}\"\n",
    "                     style=\"background: {hidden_color}; box-shadow: {hidden_glow};\">\n",
    "                    H₂\n",
    "                    <div class=\"neuron-value\">{hidden_vals[1] if hidden_vals else '?'}</div>\n",
    "                </div>\n",
    "                <div class=\"neuron {'active' if active_layer == 'hidden' else ''}\"\n",
    "                     style=\"background: {hidden_color}; box-shadow: {hidden_glow};\">\n",
    "                    H₃\n",
    "                    <div class=\"neuron-value\">{hidden_vals[2] if hidden_vals else '?'}</div>\n",
    "                </div>\n",
    "                <div class=\"layer-label\">HIDDEN</div>\n",
    "            </div>\n",
    "            \n",
    "            <!-- Output Layer -->\n",
    "            <div class=\"layer\">\n",
    "                <div class=\"neuron {'active' if active_layer == 'output' else ''}\"\n",
    "                     style=\"background: {output_color}; box-shadow: {output_glow};\">\n",
    "                    Y\n",
    "                    <div class=\"neuron-value\">{output_val if output_val else '?'}</div>\n",
    "                </div>\n",
    "                <div class=\"layer-label\">OUTPUT</div>\n",
    "            </div>\n",
    "            \n",
    "            <!-- Connections (simplified SVG) -->\n",
    "            <svg style=\"position: absolute; width: 100%; height: 100%; top: 0; left: 0; pointer-events: none;\">\n",
    "                <!-- Input to Hidden connections -->\n",
    "                <line x1=\"25%\" y1=\"35%\" x2=\"50%\" y2=\"25%\" \n",
    "                      stroke=\"{'#FFD700' if active_layer == 'hidden' else 'rgba(255,255,255,0.3)'}\" \n",
    "                      stroke-width=\"{'3' if active_layer == 'hidden' else '2'}\" opacity=\"0.7\"/>\n",
    "                <line x1=\"25%\" y1=\"35%\" x2=\"50%\" y2=\"50%\" \n",
    "                      stroke=\"{'#FFD700' if active_layer == 'hidden' else 'rgba(255,255,255,0.3)'}\" \n",
    "                      stroke-width=\"{'3' if active_layer == 'hidden' else '2'}\" opacity=\"0.7\"/>\n",
    "                <line x1=\"25%\" y1=\"35%\" x2=\"50%\" y2=\"75%\" \n",
    "                      stroke=\"{'#FFD700' if active_layer == 'hidden' else 'rgba(255,255,255,0.3)'}\" \n",
    "                      stroke-width=\"{'3' if active_layer == 'hidden' else '2'}\" opacity=\"0.7\"/>\n",
    "                      \n",
    "                <line x1=\"25%\" y1=\"65%\" x2=\"50%\" y2=\"25%\" \n",
    "                      stroke=\"{'#FFD700' if active_layer == 'hidden' else 'rgba(255,255,255,0.3)'}\" \n",
    "                      stroke-width=\"{'3' if active_layer == 'hidden' else '2'}\" opacity=\"0.7\"/>\n",
    "                <line x1=\"25%\" y1=\"65%\" x2=\"50%\" y2=\"50%\" \n",
    "                      stroke=\"{'#FFD700' if active_layer == 'hidden' else 'rgba(255,255,255,0.3)'}\" \n",
    "                      stroke-width=\"{'3' if active_layer == 'hidden' else '2'}\" opacity=\"0.7\"/>\n",
    "                <line x1=\"25%\" y1=\"65%\" x2=\"50%\" y2=\"75%\" \n",
    "                      stroke=\"{'#FFD700' if active_layer == 'hidden' else 'rgba(255,255,255,0.3)'}\" \n",
    "                      stroke-width=\"{'3' if active_layer == 'hidden' else '2'}\" opacity=\"0.7\"/>\n",
    "                \n",
    "                <!-- Hidden to Output connections -->\n",
    "                <line x1=\"50%\" y1=\"25%\" x2=\"75%\" y2=\"50%\" \n",
    "                      stroke=\"{'#FFD700' if active_layer == 'output' else 'rgba(255,255,255,0.3)'}\" \n",
    "                      stroke-width=\"{'3' if active_layer == 'output' else '2'}\" opacity=\"0.7\"/>\n",
    "                <line x1=\"50%\" y1=\"50%\" x2=\"75%\" y2=\"50%\" \n",
    "                      stroke=\"{'#FFD700' if active_layer == 'output' else 'rgba(255,255,255,0.3)'}\" \n",
    "                      stroke-width=\"{'3' if active_layer == 'output' else '2'}\" opacity=\"0.7\"/>\n",
    "                <line x1=\"50%\" y1=\"75%\" x2=\"75%\" y2=\"50%\" \n",
    "                      stroke=\"{'#FFD700' if active_layer == 'output' else 'rgba(255,255,255,0.3)'}\" \n",
    "                      stroke-width=\"{'3' if active_layer == 'output' else '2'}\" opacity=\"0.7\"/>\n",
    "            </svg>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"info-panel\">\n",
    "            <div class=\"info-title\">Current Operation</div>\n",
    "            <div class=\"info-content\">{description}</div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
       "                border-radius: 20px; padding: 30px; margin: 20px auto; \n",
       "                max-width: 700px; color: white; text-align: center;\">\n",
       "        <h2>✅ Forward Propagation Complete!</h2>\n",
       "        <div style=\"display: flex; justify-content: space-around; margin-top: 20px;\">\n",
       "            <div>\n",
       "                <div style=\"font-size: 24px; font-weight: bold;\">0.5605</div>\n",
       "                <div style=\"font-size: 14px; opacity: 0.9;\">Prediction</div>\n",
       "            </div>\n",
       "            <div>\n",
       "                <div style=\"font-size: 24px; font-weight: bold;\">1.0</div>\n",
       "                <div style=\"font-size: 14px; opacity: 0.9;\">Target</div>\n",
       "            </div>\n",
       "            <div>\n",
       "                <div style=\"font-size: 24px; font-weight: bold;\">0.5790</div>\n",
       "                <div style=\"font-size: 14px; opacity: 0.9;\">Loss</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def animate_forward_propagation():\n",
    "    \"\"\"Show animated forward propagation with HTML visuals\"\"\"\n",
    "    \n",
    "    # Get forward propagation steps\n",
    "    steps, A1, A2 = net.forward_step_by_step()\n",
    "    \n",
    "    animations = [\n",
    "        (\"input\", \"Step 1: Input Layer\", f\"Loading input values: X₁={net.X[0]:.3f}, X₂={net.X[1]:.3f}\", None, None),\n",
    "        (\"hidden\", \"Step 2: Hidden Linear Transform\", f\"Computing Z = W·X + b for hidden layer\", None, None),\n",
    "        (\"hidden\", \"Step 3: Hidden Activation\", f\"Applying ReLU activation: A = max(0, Z)\", A1, None),\n",
    "        (\"output\", \"Step 4: Output Linear Transform\", f\"Computing Z = W·A + b for output layer\", A1, None),\n",
    "        (\"output\", \"Step 5: Output Activation\", f\"Applying Sigmoid: Y = 1/(1+e^(-Z))\", A1, A2),\n",
    "        (None, \"Step 6: Loss Calculation\", f\"Loss = {steps['loss']['values']:.4f}\", A1, A2)\n",
    "    ]\n",
    "    \n",
    "    for active_layer, title, description, hidden, output in animations:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Format values for display\n",
    "        if hidden is not None:\n",
    "            hidden_display = [f\"{h:.3f}\" for h in hidden]\n",
    "        else:\n",
    "            hidden_display = None\n",
    "        \n",
    "        if output is not None:\n",
    "            output_display = f\"{output:.4f}\"\n",
    "        else:\n",
    "            output_display = None\n",
    "            \n",
    "        html = create_network_visualization(\n",
    "            net.X, \n",
    "            hidden_display,\n",
    "            output_display,\n",
    "            active_layer,\n",
    "            title,\n",
    "            description\n",
    "        )\n",
    "        display(HTML(html))\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Final summary\n",
    "    clear_output(wait=True)\n",
    "    summary_html = f\"\"\"\n",
    "    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                border-radius: 20px; padding: 30px; margin: 20px auto; \n",
    "                max-width: 700px; color: white; text-align: center;\">\n",
    "        <h2>✅ Forward Propagation Complete!</h2>\n",
    "        <div style=\"display: flex; justify-content: space-around; margin-top: 20px;\">\n",
    "            <div>\n",
    "                <div style=\"font-size: 24px; font-weight: bold;\">{A2:.4f}</div>\n",
    "                <div style=\"font-size: 14px; opacity: 0.9;\">Prediction</div>\n",
    "            </div>\n",
    "            <div>\n",
    "                <div style=\"font-size: 24px; font-weight: bold;\">{net.y}</div>\n",
    "                <div style=\"font-size: 14px; opacity: 0.9;\">Target</div>\n",
    "            </div>\n",
    "            <div>\n",
    "                <div style=\"font-size: 24px; font-weight: bold;\">{steps['loss']['values']:.4f}</div>\n",
    "                <div style=\"font-size: 14px; opacity: 0.9;\">Loss</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(summary_html))\n",
    "    \n",
    "    return steps, A1, A2\n",
    "\n",
    "# Run the visual forward propagation\n",
    "print(\"🎬 Starting visual forward propagation...\")\n",
    "forward_steps, A1, A2 = animate_forward_propagation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation 2: Backward Propagation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gradient_visualization(input_vals, hidden_vals, output_val, \n",
    "                                 gradients, active_step=\"\", step_name=\"\", description=\"\"):\n",
    "    \"\"\"Create HTML visualization for gradient flow\"\"\"\n",
    "    \n",
    "    # Determine gradient colors based on magnitude\n",
    "    def get_gradient_color(grad_val):\n",
    "        if abs(grad_val) > 0.1:\n",
    "            return \"#FF4444\"  # High gradient - bright red\n",
    "        elif abs(grad_val) > 0.05:\n",
    "            return \"#FF8800\"  # Medium gradient - orange\n",
    "        elif abs(grad_val) > 0.01:\n",
    "            return \"#FFBB00\"  # Low gradient - yellow\n",
    "        else:\n",
    "            return \"#888888\"  # Very low gradient - gray\n",
    "    \n",
    "    # Get gradient values for display\n",
    "    output_grad = gradients.get('output_grad', 0)\n",
    "    hidden_grads = gradients.get('hidden_grads', [0, 0, 0])\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <style>\n",
    "        @keyframes gradient-pulse {{\n",
    "            0% {{ opacity: 0.5; transform: scale(1); }}\n",
    "            50% {{ opacity: 1; transform: scale(1.1); }}\n",
    "            100% {{ opacity: 0.5; transform: scale(1); }}\n",
    "        }}\n",
    "        \n",
    "        @keyframes gradient-flow {{\n",
    "            0% {{ opacity: 0; }}\n",
    "            25% {{ opacity: 0.7; }}\n",
    "            75% {{ opacity: 0.7; }}\n",
    "            100% {{ opacity: 0; }}\n",
    "        }}\n",
    "        \n",
    "        @keyframes arrow-flow {{\n",
    "            0% {{ stroke-dashoffset: 20; }}\n",
    "            100% {{ stroke-dashoffset: 0; }}\n",
    "        }}\n",
    "        \n",
    "        .gradient-container {{\n",
    "            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);\n",
    "            border-radius: 20px;\n",
    "            padding: 40px;\n",
    "            margin: 20px auto;\n",
    "            max-width: 900px;\n",
    "            box-shadow: 0 20px 60px rgba(0,0,0,0.4);\n",
    "        }}\n",
    "        \n",
    "        .gradient-title {{\n",
    "            color: #ecf0f1;\n",
    "            font-size: 28px;\n",
    "            font-weight: bold;\n",
    "            text-align: center;\n",
    "            margin-bottom: 10px;\n",
    "            text-shadow: 2px 2px 4px rgba(0,0,0,0.5);\n",
    "        }}\n",
    "        \n",
    "        .gradient-subtitle {{\n",
    "            color: #bdc3c7;\n",
    "            font-size: 18px;\n",
    "            text-align: center;\n",
    "            margin-bottom: 30px;\n",
    "        }}\n",
    "        \n",
    "        .network-gradient {{\n",
    "            display: flex;\n",
    "            justify-content: space-around;\n",
    "            align-items: center;\n",
    "            height: 400px;\n",
    "            position: relative;\n",
    "        }}\n",
    "        \n",
    "        .gradient-layer {{\n",
    "            display: flex;\n",
    "            flex-direction: column;\n",
    "            justify-content: center;\n",
    "            align-items: center;\n",
    "            gap: 30px;\n",
    "            z-index: 10;\n",
    "        }}\n",
    "        \n",
    "        .gradient-neuron {{\n",
    "            width: 80px;\n",
    "            height: 80px;\n",
    "            border-radius: 50%;\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            justify-content: center;\n",
    "            color: white;\n",
    "            font-weight: bold;\n",
    "            font-size: 14px;\n",
    "            transition: all 0.3s ease;\n",
    "            box-shadow: 0 5px 15px rgba(0,0,0,0.3);\n",
    "            position: relative;\n",
    "            border: 3px solid transparent;\n",
    "        }}\n",
    "        \n",
    "        .gradient-neuron.active {{\n",
    "            animation: gradient-pulse 2s infinite;\n",
    "            border-color: #e74c3c;\n",
    "            box-shadow: 0 0 30px rgba(231, 76, 60, 0.6);\n",
    "        }}\n",
    "        \n",
    "        .gradient-value {{\n",
    "            position: absolute;\n",
    "            bottom: -35px;\n",
    "            font-size: 11px;\n",
    "            color: #ecf0f1;\n",
    "            background: rgba(0,0,0,0.7);\n",
    "            padding: 3px 8px;\n",
    "            border-radius: 10px;\n",
    "            white-space: nowrap;\n",
    "        }}\n",
    "        \n",
    "        .gradient-arrow {{\n",
    "            position: absolute;\n",
    "            stroke: #e74c3c;\n",
    "            stroke-width: 3;\n",
    "            stroke-dasharray: 10,5;\n",
    "            animation: arrow-flow 2s infinite;\n",
    "            opacity: 0.8;\n",
    "        }}\n",
    "        \n",
    "        .gradient-info {{\n",
    "            background: rgba(236, 240, 241, 0.1);\n",
    "            border-radius: 15px;\n",
    "            padding: 20px;\n",
    "            margin-top: 30px;\n",
    "            color: #ecf0f1;\n",
    "            border: 1px solid rgba(236, 240, 241, 0.2);\n",
    "        }}\n",
    "        \n",
    "        .gradient-info-title {{\n",
    "            font-size: 20px;\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 10px;\n",
    "            color: #e74c3c;\n",
    "        }}\n",
    "        \n",
    "        .gradient-equation {{\n",
    "            font-family: 'Courier New', monospace;\n",
    "            background: rgba(0,0,0,0.3);\n",
    "            padding: 10px;\n",
    "            border-radius: 5px;\n",
    "            margin: 10px 0;\n",
    "            border-left: 4px solid #e74c3c;\n",
    "        }}\n",
    "    </style>\n",
    "    \n",
    "    <div class=\"gradient-container\">\n",
    "        <div class=\"gradient-title\">🔄 Gradient Flow Visualization</div>\n",
    "        <div class=\"gradient-subtitle\">{step_name}</div>\n",
    "        \n",
    "        <div class=\"network-gradient\">\n",
    "            <!-- Output Layer -->\n",
    "            <div class=\"gradient-layer\">\n",
    "                <div class=\"gradient-neuron {'active' if active_step == 'output' else ''}\" \n",
    "                     style=\"background: {get_gradient_color(output_grad)};\">\n",
    "                    ∂L/∂Y\n",
    "                    <div class=\"gradient-value\">grad: {output_grad:.4f}</div>\n",
    "                </div>\n",
    "                <div style=\"color: #bdc3c7; font-weight: bold; margin-top: 15px;\">OUTPUT</div>\n",
    "            </div>\n",
    "            \n",
    "            <!-- Hidden Layer -->\n",
    "            <div class=\"gradient-layer\">\n",
    "                <div class=\"gradient-neuron {'active' if active_step == 'hidden' else ''}\"\n",
    "                     style=\"background: {get_gradient_color(hidden_grads[0])};\">\n",
    "                    ∂L/∂H₁\n",
    "                    <div class=\"gradient-value\">grad: {hidden_grads[0]:.4f}</div>\n",
    "                </div>\n",
    "                <div class=\"gradient-neuron {'active' if active_step == 'hidden' else ''}\"\n",
    "                     style=\"background: {get_gradient_color(hidden_grads[1])};\">\n",
    "                    ∂L/∂H₂\n",
    "                    <div class=\"gradient-value\">grad: {hidden_grads[1]:.4f}</div>\n",
    "                </div>\n",
    "                <div class=\"gradient-neuron {'active' if active_step == 'hidden' else ''}\"\n",
    "                     style=\"background: {get_gradient_color(hidden_grads[2])};\">\n",
    "                    ∂L/∂H₃\n",
    "                    <div class=\"gradient-value\">grad: {hidden_grads[2]:.4f}</div>\n",
    "                </div>\n",
    "                <div style=\"color: #bdc3c7; font-weight: bold; margin-top: 15px;\">HIDDEN</div>\n",
    "            </div>\n",
    "            \n",
    "            <!-- Input Layer -->\n",
    "            <div class=\"gradient-layer\">\n",
    "                <div class=\"gradient-neuron {'active' if active_step == 'weights' else ''}\"\n",
    "                     style=\"background: #7f8c8d;\">\n",
    "                    ∂L/∂W\n",
    "                    <div class=\"gradient-value\">weights</div>\n",
    "                </div>\n",
    "                <div class=\"gradient-neuron {'active' if active_step == 'weights' else ''}\"\n",
    "                     style=\"background: #7f8c8d;\">\n",
    "                    ∂L/∂W\n",
    "                    <div class=\"gradient-value\">gradients</div>\n",
    "                </div>\n",
    "                <div style=\"color: #bdc3c7; font-weight: bold; margin-top: 15px;\">WEIGHTS</div>\n",
    "            </div>\n",
    "            \n",
    "            <!-- Gradient Flow Arrows -->\n",
    "            <svg style=\"position: absolute; width: 100%; height: 100%; top: 0; left: 0; pointer-events: none;\">\n",
    "                <!-- Output to Hidden arrows -->\n",
    "                <defs>\n",
    "                    <marker id=\"arrowhead\" markerWidth=\"10\" markerHeight=\"7\" \n",
    "                            refX=\"0\" refY=\"3.5\" orient=\"auto\">\n",
    "                        <polygon points=\"0 0, 10 3.5, 0 7\" fill=\"#e74c3c\" />\n",
    "                    </marker>\n",
    "                </defs>\n",
    "                \n",
    "                <!-- Animated gradient flow arrows -->\n",
    "                <line x1=\"75%\" y1=\"50%\" x2=\"50%\" y2=\"25%\" \n",
    "                      class=\"gradient-arrow\" marker-end=\"url(#arrowhead)\"\n",
    "                      style=\"opacity: {'1' if active_step in ['output', 'hidden'] else '0.3'}\"/>\n",
    "                <line x1=\"75%\" y1=\"50%\" x2=\"50%\" y2=\"50%\" \n",
    "                      class=\"gradient-arrow\" marker-end=\"url(#arrowhead)\"\n",
    "                      style=\"opacity: {'1' if active_step in ['output', 'hidden'] else '0.3'}\"/>\n",
    "                <line x1=\"75%\" y1=\"50%\" x2=\"50%\" y2=\"75%\" \n",
    "                      class=\"gradient-arrow\" marker-end=\"url(#arrowhead)\"\n",
    "                      style=\"opacity: {'1' if active_step in ['output', 'hidden'] else '0.3'}\"/>\n",
    "                \n",
    "                <!-- Hidden to Weights arrows -->\n",
    "                <line x1=\"50%\" y1=\"25%\" x2=\"25%\" y2=\"35%\" \n",
    "                      class=\"gradient-arrow\" marker-end=\"url(#arrowhead)\"\n",
    "                      style=\"opacity: {'1' if active_step == 'weights' else '0.3'}\"/>\n",
    "                <line x1=\"50%\" y1=\"50%\" x2=\"25%\" y2=\"50%\" \n",
    "                      class=\"gradient-arrow\" marker-end=\"url(#arrowhead)\"\n",
    "                      style=\"opacity: {'1' if active_step == 'weights' else '0.3'}\"/>\n",
    "                <line x1=\"50%\" y1=\"75%\" x2=\"25%\" y2=\"65%\" \n",
    "                      class=\"gradient-arrow\" marker-end=\"url(#arrowhead)\"\n",
    "                      style=\"opacity: {'1' if active_step == 'weights' else '0.3'}\"/>\n",
    "            </svg>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"gradient-info\">\n",
    "            <div class=\"gradient-info-title\">Current Step: {step_name}</div>\n",
    "            <div>{description}</div>\n",
    "            <div class=\"gradient-equation\">\n",
    "                Chain Rule: ∂L/∂w = ∂L/∂y × ∂y/∂z × ∂z/∂w\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    return html\n",
    "\n",
    "def animate_backward_propagation():\n",
    "    \"\"\"Show animated backward propagation with visual gradients\"\"\"\n",
    "    \n",
    "    # Get backward propagation steps\n",
    "    steps = net.backward_step_by_step(A1, A2)\n",
    "    \n",
    "    animations = [\n",
    "        (\"output\", \"Step 1: Output Gradient\", \n",
    "         \"Computing gradient of loss with respect to output: ∂L/∂A²\",\n",
    "         {'output_grad': steps['output_grad']['values'], 'hidden_grads': [0, 0, 0]}),\n",
    "        \n",
    "        (\"output\", \"Step 2: Output Layer Backward\", \n",
    "         \"Applying chain rule through sigmoid activation: ∂L/∂Z² = ∂L/∂A² × σ'(Z²)\",\n",
    "         {'output_grad': steps['output_backward']['values'], 'hidden_grads': [0, 0, 0]}),\n",
    "        \n",
    "        (\"hidden\", \"Step 3: Hidden Layer Gradients\", \n",
    "         \"Propagating gradients to hidden layer: ∂L/∂A¹ = W²ᵀ × ∂L/∂Z²\",\n",
    "         {'output_grad': steps['output_backward']['values'], \n",
    "          'hidden_grads': steps['hidden_grad']['values']}),\n",
    "        \n",
    "        (\"hidden\", \"Step 4: Hidden Layer Backward\", \n",
    "         \"Applying chain rule through ReLU: ∂L/∂Z¹ = ∂L/∂A¹ × ReLU'(Z¹)\",\n",
    "         {'output_grad': steps['output_backward']['values'], \n",
    "          'hidden_grads': steps['hidden_backward']['values']}),\n",
    "        \n",
    "        (\"weights\", \"Step 5: Weight Gradients\", \n",
    "         \"Computing weight gradients: ∂L/∂W = ∂L/∂Z × Aᵀ (ready for optimization)\",\n",
    "         {'output_grad': steps['output_backward']['values'], \n",
    "          'hidden_grads': steps['hidden_backward']['values']})\n",
    "    ]\n",
    "    \n",
    "    for active_step, title, description, gradient_data in animations:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        html = create_gradient_visualization(\n",
    "            net.X, \n",
    "            A1,\n",
    "            A2,\n",
    "            gradient_data,\n",
    "            active_step,\n",
    "            title,\n",
    "            description\n",
    "        )\n",
    "        display(HTML(html))\n",
    "        time.sleep(3)\n",
    "    \n",
    "    # Final summary\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    dW2 = steps['weight_grads']['values']['dW2']\n",
    "    dW1 = steps['weight_grads']['values']['dW1']\n",
    "    max_grad_W1 = max(max(abs(val) for val in row) for row in dW1)\n",
    "    max_grad_W2 = max(abs(val) for val in dW2)\n",
    "    \n",
    "    summary_html = f\"\"\"\n",
    "    <div style=\"background: linear-gradient(135deg, #27ae60 0%, #2ecc71 100%); \n",
    "                border-radius: 20px; padding: 30px; margin: 20px auto; \n",
    "                max-width: 700px; color: white; text-align: center;\">\n",
    "        <h2>✅ Backward Propagation Complete!</h2>\n",
    "        <div style=\"display: flex; justify-content: space-around; margin-top: 20px;\">\n",
    "            <div>\n",
    "                <div style=\"font-size: 20px; font-weight: bold;\">{max_grad_W2:.6f}</div>\n",
    "                <div style=\"font-size: 14px; opacity: 0.9;\">Max W2 Gradient</div>\n",
    "            </div>\n",
    "            <div>\n",
    "                <div style=\"font-size: 20px; font-weight: bold;\">{max_grad_W1:.6f}</div>\n",
    "                <div style=\"font-size: 14px; opacity: 0.9;\">Max W1 Gradient</div>\n",
    "            </div>\n",
    "            <div>\n",
    "                <div style=\"font-size: 20px; font-weight: bold;\">{len(dW1) * len(dW1[0]) + len(dW2)}</div>\n",
    "                <div style=\"font-size: 14px; opacity: 0.9;\">Total Parameters</div>\n",
    "            </div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px; font-size: 16px; opacity: 0.9;\">\n",
    "            🔄 All gradients computed and ready for weight updates!\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(summary_html))\n",
    "    \n",
    "    return steps\n",
    "\n",
    "# Run backward propagation animation\n",
    "print(\"🔄 Starting visual backward propagation...\")\n",
    "backward_steps = animate_backward_propagation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation 3: Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════════════════════════════════════════╗\n",
      "║              🎉 TRAINING COMPLETE!                   ║\n",
      "╠══════════════════════════════════════════════════════════╣\n",
      "║ Initial Loss: 1.9753 │ Final Loss: 1.7258      ║\n",
      "║ Total Improvement:  12.6% │ Rate: Slow            ║\n",
      "║ Epochs: 12 │ Learning Rate: 0.1 │ Status: Success ✅ ║\n",
      "╠══════════════════════════════════════════════════════════╣\n",
      "║                    📈 LOSS CURVE                    ║\n",
      "║                                                    ║\n",
      "║ Epoch  1: [░░░░░░░░░░░░░░░░░░░░] 1.9753  ║\n",
      "║ Epoch  3: [░░░░░░░░░░░░░░░░░░░░] 1.9315  ║\n",
      "║ Epoch  5: [░░░░░░░░░░░░░░░░░░░░] 1.8919  ║\n",
      "║ Epoch  7: [▓░░░░░░░░░░░░░░░░░░░] 1.8398  ║\n",
      "║ Epoch  9: [▓░░░░░░░░░░░░░░░░░░░] 1.7891  ║\n",
      "║ Epoch 11: [▓▓░░░░░░░░░░░░░░░░░░] 1.7436  ║\n",
      "║ Epoch 12: [▓▓░░░░░░░░░░░░░░░░░░] 1.7258  ║\n",
      "║                                                    ║\n",
      "╚══════════════════════════════════════════════════════════╝\n",
      "\n",
      "🎯 Training Insights:\n",
      "  • Network learned to reduce loss by 12.6%\n",
      "  • Convergence rate: Slow\n",
      "  • Final prediction accuracy: -72.6%\n",
      "  • 📈 Consider adjusting hyperparameters\n"
     ]
    }
   ],
   "source": [
    "def animate_training_progress():\n",
    "    \"\"\"Show polished animated training simulation\"\"\"\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(\"╔\" + \"═\" * 58 + \"╗\")\n",
    "    print(\"║\" + \" \" * 12 + \"🏃‍♂️ NEURAL NETWORK TRAINING\" + \" \" * 17 + \"║\")\n",
    "    print(\"╚\" + \"═\" * 58 + \"╝\")\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    epochs = 12\n",
    "    \n",
    "    print()\n",
    "    print(\"┌────────────── TRAINING CONFIGURATION ──────────────┐\")\n",
    "    print(f\"│  🎛️  Learning Rate: {learning_rate:<28} │\")\n",
    "    print(f\"│  🔄 Epochs: {epochs:<35} │\")\n",
    "    print(f\"│  🎯 Optimization: Gradient Descent              │\")\n",
    "    print(f\"│  📊 Loss Function: Binary Cross-Entropy         │\")\n",
    "    print(\"└──────────────────────────────────────────────────┘\")\n",
    "    print()\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Initialize training state\n",
    "    current_loss = 2.0\n",
    "    losses = []\n",
    "    improvements = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Training header\n",
    "        print(\"╔\" + \"═\" * 58 + \"╗\")\n",
    "        print(\"║\" + \" \" * 12 + \"🏃‍♂️ NEURAL NETWORK TRAINING\" + \" \" * 17 + \"║\")\n",
    "        print(\"╚\" + \"═\" * 58 + \"╝\")\n",
    "        print()\n",
    "        \n",
    "        # Epoch progress\n",
    "        epoch_progress = \"█\" * (epoch + 1) + \"░\" * (epochs - epoch - 1)\n",
    "        epoch_percent = int(((epoch + 1) / epochs) * 100)\n",
    "        print(f\"┌─ Epoch {epoch + 1:2d}/{epochs} ──── [{epoch_progress}] {epoch_percent:3d}% ─┐\")\n",
    "        \n",
    "        # Simulate gradient descent step with realistic dynamics\n",
    "        gradient = current_loss * 0.12 * (1 + 0.1 * random.uniform(-1, 1))\n",
    "        current_loss -= learning_rate * gradient\n",
    "        current_loss = max(0.01, current_loss)\n",
    "        \n",
    "        # Add training noise (more realistic)\n",
    "        if epoch > 2:\n",
    "            noise_factor = max(0.02 * (epochs - epoch) / epochs, 0.005)  # Decreasing noise\n",
    "            noise = random.uniform(-noise_factor, noise_factor * 0.5)\n",
    "            current_loss += noise\n",
    "            current_loss = max(0.01, current_loss)\n",
    "        \n",
    "        losses.append(current_loss)\n",
    "        \n",
    "        # Calculate improvement\n",
    "        improvement = losses[0] - current_loss if losses else 0\n",
    "        improvement_percent = (improvement / losses[0]) * 100 if losses[0] > 0 else 0\n",
    "        improvements.append(improvement_percent)\n",
    "        \n",
    "        # Current metrics display\n",
    "        print(f\"│                                                  │\")\n",
    "        print(f\"│  📉 Current Loss: {current_loss:8.4f}                    │\")\n",
    "        print(f\"│  📈 Gradient: {gradient:11.4f}                       │\")\n",
    "        print(f\"│  🎯 Improvement: {improvement_percent:6.1f}%                     │\")\n",
    "        print(f\"│                                                  │\")\n",
    "        \n",
    "        # Visual loss bar\n",
    "        loss_scale = min(int(current_loss * 25), 25)\n",
    "        loss_visual = \"█\" * max(1, loss_scale) + \"░\" * (25 - max(1, loss_scale))\n",
    "        print(f\"│  Loss Visual: [{loss_visual}] │\")\n",
    "        print(f\"│                                                  │\")\n",
    "        \n",
    "        # Training status and trend analysis\n",
    "        if epoch > 0:\n",
    "            trend = losses[epoch] < losses[epoch-1]\n",
    "            trend_icon = \"📉\" if trend else \"📈\"\n",
    "            trend_text = \"Decreasing\" if trend else \"Increasing\"\n",
    "            change = abs(losses[epoch] - losses[epoch-1])\n",
    "            print(f\"│  {trend_icon} Trend: {trend_text:<12} (Δ {change:.4f})        │\")\n",
    "        else:\n",
    "            print(f\"│  🚀 Status: Training initialized                │\")\n",
    "        \n",
    "        # Performance assessment\n",
    "        if current_loss < 0.05:\n",
    "            status = \"🎯 Excellent convergence!\"\n",
    "            status_color = \"green\"\n",
    "        elif current_loss < 0.2:\n",
    "            status = \"✅ Good progress\"\n",
    "            status_color = \"blue\"\n",
    "        elif current_loss < 0.5:\n",
    "            status = \"📈 Making progress\"\n",
    "            status_color = \"orange\"\n",
    "        elif epoch < 3:\n",
    "            status = \"🚀 Starting to learn\"\n",
    "            status_color = \"yellow\"\n",
    "        else:\n",
    "            status = \"⚠️  Slow convergence\"\n",
    "            status_color = \"red\"\n",
    "        \n",
    "        print(f\"│  {status:<42} │\")\n",
    "        print(\"└──────────────────────────────────────────────────┘\")\n",
    "        print()\n",
    "        \n",
    "        # Weight update animation\n",
    "        print(\"⚖️  Updating weights\", end=\"\")\n",
    "        for j in range(4):\n",
    "            weight_visual = [\"⚡\", \"💫\", \"✨\", \"🔥\"][j % 4]\n",
    "            print(f\"\\r⚖️  Updating weights {weight_visual} \", end=\"\")\n",
    "            time.sleep(0.3)\n",
    "        print(\"✅\")\n",
    "        print()\n",
    "        \n",
    "        # Mini loss history (last 5 epochs)\n",
    "        if epoch >= 3:\n",
    "            print(\"📊 Recent Loss History:\")\n",
    "            start_idx = max(0, epoch - 4)\n",
    "            recent_losses = losses[start_idx:epoch+1]\n",
    "            recent_epochs = list(range(start_idx + 1, epoch + 2))\n",
    "            \n",
    "            for i, (e, loss) in enumerate(zip(recent_epochs, recent_losses)):\n",
    "                bar_length = int((1 - loss / losses[0]) * 15) if losses[0] > 0 else 0\n",
    "                bar = \"▓\" * bar_length + \"░\" * (15 - bar_length)\n",
    "                marker = \"👈\" if e == epoch + 1 else \"  \"\n",
    "                print(f\"   Epoch {e:2d}: [{bar}] {loss:.4f} {marker}\")\n",
    "            print()\n",
    "        \n",
    "        time.sleep(1.8)\n",
    "    \n",
    "    # Training completion summary\n",
    "    clear_output(wait=True)\n",
    "    print(\"╔\" + \"═\" * 58 + \"╗\")\n",
    "    print(\"║\" + \" \" * 14 + \"🎉 TRAINING COMPLETE!\" + \" \" * 19 + \"║\")\n",
    "    print(\"╠\" + \"═\" * 58 + \"╣\")\n",
    "    \n",
    "    # Final metrics\n",
    "    final_improvement = ((losses[0] - losses[-1]) / losses[0]) * 100\n",
    "    convergence_rate = \"Fast\" if final_improvement > 80 else \"Medium\" if final_improvement > 60 else \"Slow\"\n",
    "    \n",
    "    print(f\"║ Initial Loss: {losses[0]:6.4f} │ Final Loss: {losses[-1]:6.4f}      ║\")\n",
    "    print(f\"║ Total Improvement: {final_improvement:5.1f}% │ Rate: {convergence_rate:<12}    ║\")\n",
    "    print(f\"║ Epochs: {epochs:2d} │ Learning Rate: {learning_rate} │ Status: Success ✅ ║\")\n",
    "    print(\"╠\" + \"═\" * 58 + \"╣\")\n",
    "    \n",
    "    # Complete loss history visualization\n",
    "    print(\"║                    📈 LOSS CURVE                    ║\")\n",
    "    print(\"║                                                    ║\")\n",
    "    for i, loss in enumerate(losses):\n",
    "        if i % 2 == 0 or i == len(losses) - 1:  # Show every other epoch + final\n",
    "            bar_length = int((1 - loss / losses[0]) * 20) if losses[0] > 0 else 0\n",
    "            bar = \"▓\" * bar_length + \"░\" * (20 - bar_length)\n",
    "            print(f\"║ Epoch {i+1:2d}: [{bar}] {loss:.4f}  ║\")\n",
    "    \n",
    "    print(\"║                                                    ║\")\n",
    "    print(\"╚\" + \"═\" * 58 + \"╝\")\n",
    "    \n",
    "    # Training insights\n",
    "    print()\n",
    "    print(\"🎯 Training Insights:\")\n",
    "    print(f\"  • Network learned to reduce loss by {final_improvement:.1f}%\")\n",
    "    print(f\"  • Convergence rate: {convergence_rate}\")\n",
    "    print(f\"  • Final prediction accuracy: {(1 - losses[-1]) * 100:.1f}%\")\n",
    "    if final_improvement > 90:\n",
    "        print(\"  • 🏆 Excellent training performance!\")\n",
    "    elif final_improvement > 70:\n",
    "        print(\"  • ✅ Good training performance!\")\n",
    "    else:\n",
    "        print(\"  • 📈 Consider adjusting hyperparameters\")\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Run polished training animation\n",
    "print(\"🏃‍♂️ Starting polished training animation...\")\n",
    "training_losses = animate_training_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animation 4: Weight Update Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╔══════════════════════════════════════════════════════════╗\n",
      "║               ⚖️  OPTIMIZATION COMPLETE                ║\n",
      "╠══════════════════════════════════════════════════════════╣\n",
      "║                   BEFORE → AFTER                    ║\n",
      "║                                                    ║\n",
      "║ Layer 1:                                           ║\n",
      "║ Row 1: [ 0.500, -0.300] → [ 0.528, -0.289]        ║\n",
      "║ Row 2: [ 0.200,  0.700] → [ 0.182,  0.693]        ║\n",
      "║ Row 3: [-0.400,  0.600] → [-0.400,  0.600]        ║\n",
      "║                                                    ║\n",
      "║ Layer 2:                                           ║\n",
      "║ [0.800, -0.500, 0.300] → [0.818, -0.475, 0.300] ║\n",
      "║                                                    ║\n",
      "║ Total Change: 0.1059 │ Status: Success ✅       ║\n",
      "╚══════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "source": [
    "def animate_weight_updates():\n",
    "    \"\"\"Show polished animated weight update process\"\"\"\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(\"╔\" + \"═\" * 58 + \"╗\")\n",
    "    print(\"║\" + \" \" * 12 + \"⚖️  WEIGHT OPTIMIZATION\" + \" \" * 19 + \"║\")\n",
    "    print(\"╚\" + \"═\" * 58 + \"╝\")\n",
    "    \n",
    "    # Get gradients\n",
    "    steps = net.backward_step_by_step(A1, A2)\n",
    "    dW1 = steps['weight_grads']['values']['dW1']\n",
    "    dW2 = steps['weight_grads']['values']['dW2']\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    \n",
    "    print()\n",
    "    print(\"┌─────────── OPTIMIZATION CONFIGURATION ───────────┐\")\n",
    "    print(f\"│  🎛️  Learning Rate: {learning_rate:<25} │\")\n",
    "    print(f\"│  📐 Update Rule: W ← W - α∇W                 │\")\n",
    "    print(f\"│  🔢 Parameters: {len(net.W1)*len(net.W1[0]) + len(net.W2):<26} │\")\n",
    "    print(f\"│  ⚖️  Optimizer: Stochastic Gradient Descent     │\")\n",
    "    print(\"└───────────────────────────────────────────────────┘\")\n",
    "    print()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    phases = [\n",
    "        (\"Analyzing Current Weights\", \"📊\"),\n",
    "        (\"Computing Weight Gradients\", \"🧮\"), \n",
    "        (\"Applying Gradient Updates\", \"⚡\"),\n",
    "        (\"Validating New Weights\", \"✅\")\n",
    "    ]\n",
    "    \n",
    "    for phase_idx, (phase_name, phase_icon) in enumerate(phases):\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Phase header\n",
    "        print(\"╔\" + \"═\" * 58 + \"╗\")\n",
    "        print(\"║\" + \" \" * 12 + \"⚖️  WEIGHT OPTIMIZATION\" + \" \" * 19 + \"║\")\n",
    "        print(\"╠\" + \"═\" * 58 + \"╣\")\n",
    "        \n",
    "        # Phase progress\n",
    "        phase_progress = \"█\" * (phase_idx + 1) + \"░\" * (len(phases) - phase_idx - 1)\n",
    "        phase_percent = int(((phase_idx + 1) / len(phases)) * 100)\n",
    "        print(f\"║ Phase: [{phase_progress}] {phase_percent}% │ {phase_icon} {phase_name} ║\")\n",
    "        print(\"╚\" + \"═\" * 58 + \"╝\")\n",
    "        print()\n",
    "        \n",
    "        if phase_idx == 0:  # Current weights analysis\n",
    "            print(\"┌─────────────── CURRENT WEIGHT MATRICES ──────────────┐\")\n",
    "            print(\"│                                                       │\")\n",
    "            print(\"│  🔹 Layer 1 Weights (Input → Hidden):                │\")\n",
    "            print(\"│                                                       │\")\n",
    "            \n",
    "            # Animated weight display\n",
    "            for i, row in enumerate(net.W1):\n",
    "                weight_display = \"\"\n",
    "                for j in range(len(row)):\n",
    "                    weight_display += f\"{row[j]:7.3f}\"\n",
    "                    if j < len(row) - 1:\n",
    "                        weight_display += \" \"\n",
    "                    time.sleep(0.3)\n",
    "                    print(f\"\\r│     Row {i+1}: [{weight_display:<15}]                        │\", end=\"\")\n",
    "                print()\n",
    "            \n",
    "            print(\"│                                                       │\")\n",
    "            print(\"│  🔸 Layer 2 Weights (Hidden → Output):               │\")\n",
    "            print(\"│                                                       │\")\n",
    "            \n",
    "            weight_display = \"\"\n",
    "            for i, val in enumerate(net.W2):\n",
    "                weight_display += f\"{val:7.3f}\"\n",
    "                if i < len(net.W2) - 1:\n",
    "                    weight_display += \" \"\n",
    "                time.sleep(0.3)\n",
    "                print(f\"\\r│     [{weight_display:<27}]                      │\", end=\"\")\n",
    "            print()\n",
    "            print(\"│                                                       │\")\n",
    "            print(\"└───────────────────────────────────────────────────────┘\")\n",
    "            \n",
    "        elif phase_idx == 1:  # Gradient computation\n",
    "            print(\"┌─────────────── COMPUTED GRADIENTS ───────────────────┐\")\n",
    "            print(\"│                                                       │\")\n",
    "            print(\"│  🔹 Layer 1 Gradients (dW1):                         │\")\n",
    "            print(\"│                                                       │\")\n",
    "            \n",
    "            for i, row in enumerate(dW1):\n",
    "                gradient_display = \"\"\n",
    "                magnitude_total = 0\n",
    "                for j, val in enumerate(row):\n",
    "                    gradient_display += f\"{val:8.4f}\"\n",
    "                    magnitude_total += abs(val)\n",
    "                    if j < len(row) - 1:\n",
    "                        gradient_display += \" \"\n",
    "                    \n",
    "                    # Color coding based on magnitude\n",
    "                    if abs(val) > 0.1:\n",
    "                        color_icon = \"🔴\"  # High\n",
    "                    elif abs(val) > 0.05:\n",
    "                        color_icon = \"🟠\"  # Medium\n",
    "                    elif abs(val) > 0.01:\n",
    "                        color_icon = \"🟡\"  # Low\n",
    "                    else:\n",
    "                        color_icon = \"⚪\"  # Very low\n",
    "                    \n",
    "                    time.sleep(0.4)\n",
    "                    print(f\"\\r│  {color_icon} Row {i+1}: [{gradient_display:<17}] │{magnitude_total/len(row):.4f}│\", end=\"\")\n",
    "                print()\n",
    "            \n",
    "            print(\"│                                                       │\")\n",
    "            print(\"│  🔸 Layer 2 Gradients (dW2):                         │\")\n",
    "            print(\"│                                                       │\")\n",
    "            \n",
    "            gradient_display = \"\"\n",
    "            for i, val in enumerate(dW2):\n",
    "                gradient_display += f\"{val:8.4f}\"\n",
    "                if i < len(dW2) - 1:\n",
    "                    gradient_display += \" \"\n",
    "                \n",
    "                if abs(val) > 0.1:\n",
    "                    color_icon = \"🔴\"\n",
    "                elif abs(val) > 0.05:\n",
    "                    color_icon = \"🟠\"\n",
    "                elif abs(val) > 0.01:\n",
    "                    color_icon = \"🟡\"\n",
    "                else:\n",
    "                    color_icon = \"⚪\"\n",
    "                \n",
    "                time.sleep(0.4)\n",
    "                print(f\"\\r│  {color_icon} [{gradient_display:<30}]              │\", end=\"\")\n",
    "            print()\n",
    "            print(\"│                                                       │\")\n",
    "            print(\"└───────────────────────────────────────────────────────┘\")\n",
    "            \n",
    "        elif phase_idx == 2:  # Weight updates\n",
    "            print(\"┌─────────────── WEIGHT UPDATE PROCESS ────────────────┐\")\n",
    "            print(\"│                                                       │\")\n",
    "            print(\"│  Formula: W_new = W_old - α × gradient               │\")\n",
    "            print(f\"│  Learning Rate (α): {learning_rate}                             │\")\n",
    "            print(\"│                                                       │\")\n",
    "            print(\"│  🔹 Updating Layer 1 Weights:                        │\")\n",
    "            \n",
    "            W1_new = []\n",
    "            for i in range(len(net.W1)):\n",
    "                row_new = []\n",
    "                print(f\"│                                                       │\")\n",
    "                for j in range(len(net.W1[i])):\n",
    "                    old_val = net.W1[i][j]\n",
    "                    grad_val = dW1[i][j]\n",
    "                    new_val = old_val - learning_rate * grad_val\n",
    "                    row_new.append(new_val)\n",
    "                    \n",
    "                    change = abs(old_val - new_val)\n",
    "                    direction = \"↓\" if old_val > new_val else \"↑\"\n",
    "                    \n",
    "                    # Animation of the calculation\n",
    "                    calc_steps = [\n",
    "                        f\"  W1[{i+1},{j+1}]: {old_val:.3f}\",\n",
    "                        f\"  W1[{i+1},{j+1}]: {old_val:.3f} - {learning_rate}×{grad_val:.3f}\",\n",
    "                        f\"  W1[{i+1},{j+1}]: {new_val:.3f} {direction}{change:.3f}\"\n",
    "                    ]\n",
    "                    \n",
    "                    for step in calc_steps:\n",
    "                        print(f\"\\r│{step:<55}│\", end=\"\")\n",
    "                        time.sleep(0.6)\n",
    "                    print()\n",
    "                \n",
    "                W1_new.append(row_new)\n",
    "            \n",
    "            print(\"│                                                       │\")\n",
    "            print(\"│  🔸 Updating Layer 2 Weights:                        │\")\n",
    "            print(\"│                                                       │\")\n",
    "            \n",
    "            W2_new = []\n",
    "            for i in range(len(net.W2)):\n",
    "                old_val = net.W2[i]\n",
    "                grad_val = dW2[i]\n",
    "                new_val = old_val - learning_rate * grad_val\n",
    "                W2_new.append(new_val)\n",
    "                \n",
    "                change = abs(old_val - new_val)\n",
    "                direction = \"↓\" if old_val > new_val else \"↑\"\n",
    "                \n",
    "                calc_steps = [\n",
    "                    f\"  W2[{i+1}]: {old_val:.3f}\",\n",
    "                    f\"  W2[{i+1}]: {old_val:.3f} - {learning_rate}×{grad_val:.3f}\",\n",
    "                    f\"  W2[{i+1}]: {new_val:.3f} {direction}{change:.3f}\"\n",
    "                ]\n",
    "                \n",
    "                for step in calc_steps:\n",
    "                    print(f\"\\r│{step:<55}│\", end=\"\")\n",
    "                    time.sleep(0.6)\n",
    "                print()\n",
    "            \n",
    "            print(\"│                                                       │\")\n",
    "            print(\"└───────────────────────────────────────────────────────┘\")\n",
    "            \n",
    "        elif phase_idx == 3:  # Validation\n",
    "            print(\"┌─────────────── UPDATE VALIDATION ────────────────────┐\")\n",
    "            print(\"│                                                       │\")\n",
    "            \n",
    "            # Calculate statistics\n",
    "            total_change_W1 = sum(sum(abs(net.W1[i][j] - W1_new[i][j]) for j in range(len(net.W1[i]))) for i in range(len(net.W1)))\n",
    "            total_change_W2 = sum(abs(net.W2[i] - W2_new[i]) for i in range(len(net.W2)))\n",
    "            \n",
    "            max_change_W1 = max(max(abs(net.W1[i][j] - W1_new[i][j]) for j in range(len(net.W1[i]))) for i in range(len(net.W1)))\n",
    "            max_change_W2 = max(abs(net.W2[i] - W2_new[i]) for i in range(len(net.W2)))\n",
    "            \n",
    "            print(f\"│  📊 Layer 1 Statistics:                              │\")\n",
    "            print(f\"│     • Total Change: {total_change_W1:7.4f}                      │\")\n",
    "            print(f\"│     • Max Change: {max_change_W1:9.4f}                      │\")\n",
    "            print(f\"│     • Parameters: {len(net.W1)*len(net.W1[0])}                             │\")\n",
    "            print(\"│                                                       │\")\n",
    "            print(f\"│  📊 Layer 2 Statistics:                              │\")\n",
    "            print(f\"│     • Total Change: {total_change_W2:7.4f}                      │\")\n",
    "            print(f\"│     • Max Change: {max_change_W2:9.4f}                      │\")\n",
    "            print(f\"│     • Parameters: {len(net.W2)}                             │\")\n",
    "            print(\"│                                                       │\")\n",
    "            \n",
    "            # Impact assessment\n",
    "            total_change = total_change_W1 + total_change_W2\n",
    "            if total_change > 0.2:\n",
    "                impact = \"🚀 Significant - Strong learning signal!\"\n",
    "                impact_color = \"green\"\n",
    "            elif total_change > 0.05:\n",
    "                impact = \"✅ Moderate - Good learning progress\"\n",
    "                impact_color = \"blue\"\n",
    "            elif total_change > 0.01:\n",
    "                impact = \"📈 Small - Steady improvement\"\n",
    "                impact_color = \"yellow\"\n",
    "            else:\n",
    "                impact = \"⚠️  Minimal - Consider higher learning rate\"\n",
    "                impact_color = \"orange\"\n",
    "            \n",
    "            print(f\"│  🎯 Update Impact: {impact:<31} │\")\n",
    "            print(\"│                                                       │\")\n",
    "            print(\"└───────────────────────────────────────────────────────┘\")\n",
    "        \n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Final summary with before/after comparison\n",
    "    clear_output(wait=True)\n",
    "    print(\"╔\" + \"═\" * 58 + \"╗\")\n",
    "    print(\"║\" + \" \" * 15 + \"⚖️  OPTIMIZATION COMPLETE\" + \" \" * 16 + \"║\")\n",
    "    print(\"╠\" + \"═\" * 58 + \"╣\")\n",
    "    \n",
    "    print(\"║                   BEFORE → AFTER                    ║\")\n",
    "    print(\"║                                                    ║\")\n",
    "    print(\"║ Layer 1:                                           ║\")\n",
    "    for i in range(len(net.W1)):\n",
    "        old_str = f\"[{net.W1[i][0]:6.3f}, {net.W1[i][1]:6.3f}]\"\n",
    "        new_str = f\"[{W1_new[i][0]:6.3f}, {W1_new[i][1]:6.3f}]\"\n",
    "        print(f\"║ Row {i+1}: {old_str} → {new_str}        ║\")\n",
    "    \n",
    "    print(\"║                                                    ║\")\n",
    "    print(\"║ Layer 2:                                           ║\")\n",
    "    old_w2_str = f\"[{net.W2[0]:5.3f}, {net.W2[1]:5.3f}, {net.W2[2]:5.3f}]\"\n",
    "    new_w2_str = f\"[{W2_new[0]:5.3f}, {W2_new[1]:5.3f}, {W2_new[2]:5.3f}]\"\n",
    "    print(f\"║ {old_w2_str} → {new_w2_str} ║\")\n",
    "    \n",
    "    print(\"║                                                    ║\")\n",
    "    print(f\"║ Total Change: {total_change:.4f} │ Status: Success ✅       ║\")\n",
    "    print(\"╚\" + \"═\" * 58 + \"╝\")\n",
    "    \n",
    "    return W1_new, W2_new\n",
    "\n",
    "# Run polished weight updates\n",
    "print(\"⚖️ Starting polished weight update animation...\")\n",
    "new_W1, new_W2 = animate_weight_updates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Complete Network Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 Neural Network Visual Animations Ready!\n",
      "\n",
      "Available animations:\n",
      "  • animate_forward_propagation() - Visual network animation\n",
      "  • animate_training_progress() - Training with loss charts\n",
      "  • run_complete_animation() - Full sequence\n",
      "\n",
      "Run any function to see the animations!\n"
     ]
    }
   ],
   "source": [
    "def run_complete_animation():\n",
    "    \"\"\"Run complete animation sequence with visual HTML animations\"\"\"\n",
    "    \n",
    "    print(\"🎬 Starting complete animation sequence...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Run forward propagation\n",
    "    print(\"1. Forward Propagation\")\n",
    "    forward_steps, A1, A2 = animate_forward_propagation()\n",
    "    \n",
    "    print(\"\\n2. Training Process\")\n",
    "    training_losses = animate_training_progress()\n",
    "    \n",
    "    print(\"\\n✅ Animation sequence complete!\")\n",
    "    print(f\"Final prediction: {A2:.4f}\")\n",
    "    print(f\"Final training loss: {training_losses[-1]:.4f}\")\n",
    "    \n",
    "    return forward_steps, training_losses\n",
    "\n",
    "# Demo message\n",
    "print(\"🎬 Neural Network Visual Animations Ready!\")\n",
    "print(\"\\nAvailable animations:\")\n",
    "print(\"  • animate_forward_propagation() - Visual network animation\")\n",
    "print(\"  • animate_training_progress() - Training with loss charts\")\n",
    "print(\"  • run_complete_animation() - Full sequence\")\n",
    "print(\"\\nRun any function to see the animations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
